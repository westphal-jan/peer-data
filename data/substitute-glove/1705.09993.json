{"id": "1705.09993", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-May-2017", "title": "Deep Learning for User Comment Moderation", "abstract": "Experimenting with into new deduplication of april. 6M user rumors it for Greek news go.com and existing correlating while English Wikipedia announcement, we show though means RNN shriller the ending state of is examples in moderation. A thick, circumscription - specific noting methods impairs further during consecutive visual fact then RNN. We also think breaking a CNN part perfect yes - list angles, already instead yet automatic the runner - ammunition embrace.", "histories": [["v1", "Sun, 28 May 2017 21:12:56 GMT  (1433kb,D)", "https://arxiv.org/abs/1705.09993v1", null], ["v2", "Mon, 17 Jul 2017 15:25:56 GMT  (1433kb,D)", "http://arxiv.org/abs/1705.09993v2", null]], "reviews": [], "SUBJECTS": "cs.CL cs.LG", "authors": ["john pavlopoulos", "prodromos malakasiotis", "ion", "routsopoulos"], "accepted": false, "id": "1705.09993"}, "pdf": {"name": "1705.09993.pdf", "metadata": {"source": "CRF", "title": "Deep Learning for User Comment Moderation", "authors": ["John Pavlopoulos", "Prodromos Malakasiotis"], "emails": ["ip@straintek.com", "mm@straintek.com", "ion@aueb.gr"], "sections": [{"heading": "1 Introduction", "text": "User comments play a central role in social media and online discussion fora. News portals and blogs often also allow their readers to comment in order to get feedback, engage their readers, and build customer loyalty. User comments, however, and more generally user content can also be abusive (e.g., bullying, profanity, hate speech). Social media are increasingly under pressure to combat abusive content. News portals also suffer from abusive user comments, which damage their reputation and make them liable to fines, e.g., when hosting comments encouraging illegal actions. They often employ moderators, who are frequently overwhelmed by the volume of comments. Readers are disappointed when non-abusive comments do not appear quickly online because of moderation delays. Smaller news portals may be unable to employ moderators, and some are forced to shut down their comments sections entirely.1\nWe examine how deep learning (Goodfellow et al., 2016; Goldberg, 2016) can be used to moderate user comments. We experiment with a new dataset of approx. 1.6M manually moderated user\n1See, for example, http://niemanreports.org/ articles/the-future-of-comments/.\ncomments from a Greek sports portal (Gazzetta), which we make publicly available.2 Furthermore, we provide word embeddings pre-trained on 5.2M comments from the same portal. We also experiment on the datasets of Wulczyn et al. (2017), which contain English Wikipedia comments labeled for personal attacks, aggression, toxicity.\nIn a fully automatic scenario, a system directly accepts or rejects comments. Although this scenario may be the only available one, e.g., when portals cannot afford moderators, it is unrealistic to expect that fully automatic moderation will be perfect, because abusive comments may involve irony, sarcasm, harassment without profanity etc., which are particularly difficult for machines to handle. When moderators are available, it is more realistic to develop semi-automatic systems to assist rather than replace them, a scenario that has not been considered in previous work. Comments for which the system is uncertain (Fig. 1) are shown to a moderator to decide; all other comments are accepted or rejected by the system. We discuss how moderation systems can be tuned, depending on the availability and workload of moderators. We also introduce additional evaluation\n2The portal is http://www.gazzetta.gr/. Instructions to obtain the Gazzetta data will be posted at http: //nlp.cs.aueb.gr/software.html.\nar X\niv :1\n70 5.\n09 99\n3v 2\n[ cs\n.C L\n] 1\n7 Ju\nl 2 01\n7\nmeasures for the semi-automatic scenario. On both Gazzetta and Wikipedia comments and for both scenarios (automatic, semi-automatic), we show that a recursive neural network (RNN) outperforms the system of Wulczyn et al. (2017), the previous state of the art for comment moderation, which employed logistic regression (LR) or a multi-layered Perceptron (MLP). We also propose an attention mechanism that improves the overall performance of the RNN. Our attention differs from most previous ones (Bahdanau et al., 2015; Luong et al., 2015) in that it is used in text classification, where there is no previously generated output subsequence to drive the attention, unlike sequence-to-sequence models (Sutskever et al., 2014). In effect, our attention mechanism detects the words of a comment that affect mostly the classification decision (accept, reject), by examining them in the context of the particular comment.\nOur main contributions are: (i) We release a new dataset of 1.6M moderated user comments. (ii) We are among the first to apply deep learning to user comment moderation, and we show that an RNN with a novel classification-specific attention mechanism outperforms the previous state of the art. (iii) Unlike previous work, we also consider a semi-automatic scenario, along with threshold tuning and evaluation measures for it."}, {"heading": "2 Datasets", "text": "We first discuss the datasets we used, to help acquaint the reader with the problem."}, {"heading": "2.1 Gazzetta dataset", "text": "There are approx. 1.45M training comments (covering Jan. 1, 2015 to Oct. 6, 2016) in the Gazzetta dataset; we call them G-TRAIN-L (Table 1). Some experiments use only the first 100K comments of\nG-TRAIN-L, called G-TRAIN-S. An additional set of 60,900 comments (Oct. 7 to Nov. 11, 2016) was split to development (G-DEV, 29,700 comments), large test (G-TEST-L, 29,700), and small test set (G-TEST-S, 1,500). Gazzetta\u2019s moderators (2 full-time, plus journalists occasionally helping) are occasionally instructed to be stricter (e.g., during violent events). To get a more accurate view of performance in normal situations, we manually re-moderated (labeled as \u2018accept\u2019 or \u2018reject\u2019) the comments of G-TEST-S, producing G-TEST-S-R. The reject ratio is approximately 30% in all subsets, except for G-TEST-S-R where it drops to 22%, because there are no occasions where the moderators were instructed to be stricter in G-TEST-S-R.\nEach G-TEST-S-R comment was re-moderated by 5 annotators. Krippendorff\u2019s (2004) alpha was 0.4762, close to the value (0.45) reported by Wulczyn et al. (2017) for Wikipedia comments. Using Cohen\u2019s Kappa (Cohen, 1960), the mean pairwise agreement was 0.4749. The mean pairwise percentage of agreement (% of comments each pair of annotators agreed on) was 81.33%. Cohen\u2019s Kappa and Krippendorff\u2019s alpha lead to moderate scores, because they account for agreement by chance, which is high when there is class imbalance (22% reject, 78% accept in G-TEST-S-R).\nWe also provide 300-dimensional word embeddings, pre-trained on approx. 5.2M comments (268M tokens) from Gazzetta using WORD2VEC (Mikolov et al., 2013a,b).3 This larger dataset cannot be used to train classifiers, because most of its comments are from a period (before 2015) when Gazzetta did not employ moderators."}, {"heading": "2.2 Wikipedia datasets", "text": "Wulczyn et al. (2017) created three datasets containing English Wikipedia talk page comments.\nAttacks dataset: This dataset contains approx. 115K comments, which were labeled as personal attacks (reject) or not (accept) using crowdsourcing. Each comment was labeled by at least 10 annotators. Inter-annotator agreement, measured on a random sample of 1K comments using Krippendorff\u2019s (2004) alpha, was 0.45. The gold label of each comment is determined by the majority of annotators, leading to binary labels (accept, reject). Alternatively, the gold label is the percentage of annotators that labeled the comment as \u2018accept\u2019\n3We used CBOW, window size 5, min. term freq. 5, negative sampling, obtaining a vocabulary size of approx. 478K.\n(or \u2018reject\u2019), leading to probabilistic labels.4 The dataset is split in three parts (Table 1): training (WATT-TRAIN, 69,526 comments), development (WATT-DEV, 23,160), and test (W-ATT-TEST, 23,178 comments). In all three parts, the rejected comments are 12%, but this ratio is artificial (in effect, Wulczyn et al. oversampled comments posted by banned users), unlike Gazzetta subsets where the truly observed accept/reject ratios are used.\nToxicity dataset: This dataset was created like the previous one, but contains more comments (159,686), now labeled as toxic (reject) or not (accept). Inter-annotator agreement was not reported. Again, binary or probabilistic gold labels can be used. The dataset is split in three parts (Table 1): training (W-TOX-TRAIN, 95,692 comments), development (W-TOX-DEV, 32,128), and test (WTOX-TEST, 31,866). In all three parts, the rejected (toxic) comments are 10%, again an artificial ratio.\nWikipedia comments are longer (median 38 and 39 tokens for attacks, toxicity) compared to Gazzetta\u2019s (median 25). Wulczyn et al. (2017) also created an \u2018aggression\u2019 dataset containing the same comments as the personal attacks one, but now labeled as aggressive or not. The (probabilistic) labels of the two datasets are very highly correlated (0.8992 Spearman, 0.9718 Pearson) and we do not consider the aggression dataset further."}, {"heading": "3 Methods", "text": "We experimented with an RNN operating on word embeddings, the same RNN enhanced with our attention mechanism (a-RNN), several variants of a-RNN, a vanilla convolutional neural network (CNN) also operating on word embeddings, the DETOX system of Wulczyn et al. (2017), and a baseline that uses word lists with precision scores."}, {"heading": "3.1 DETOX", "text": "DETOX (Wulczyn et al., 2017) was the previous state of the art in comment moderation, in the sense that it had the best reported results on the Wikipedia datasets (Section 2.2), the largest previous publicly available datasets of moderated user comments.5 DETOX represents each comment as a\n4We also construct probabilistic gold labels (in addition to binary ones) for G-TEST-S-R, where there are 5 annotators.\n5Two of the co-authors of Wulczyn et al. (2017) are with Jigsaw, who recently announced Perspective, a system to detect \u2018toxic\u2019 comments. Perspective is not the same as DETOX (personal communication), but we were unable to obtain scientific articles describing it. We have applied for access to its\nbag of word n-grams (n \u2264 2, each comment becomes a bag containing its 1-grams and 2-grams) or a bag of character n-grams (n \u2264 5, each comment becomes a bag containing character 1-grams, . . . , 5-grams). DETOX can rely on a logistic regression (LR) or multi-layer Perceptron (MLP) classifier, and uses binary or probabilistic gold labels (Section 2.2) during training. We used the DETOX implementation of Wulczyn et al. and the same grid search to tune the hyper-parameters that select word or character n-grams, classifier (LR or MLP), and gold labels (binary or probabilistic). For Gazzetta, only binary gold labels were possible, since G-TRAIN-L and G-TRAIN-S have a single gold label per comment. Unlike Wulczyn et al., we tuned the hyper-parameters by evaluating (computing AUC and Spearman, Section 4) on a random 2% of held-out comments of W-ATTTRAIN, W-TOX-TRAIN, or G-TRAIN-S, instead of the development subsets, to be able to obtain more realistic results from the development sets while developing the methods. The tuning always preferred character n-grams, as in the work of Wulczyn et al., and LR to MLP, whereas Wulczyn et al. reported slightly higher performance for the MLP on W-ATT-DEV.6 The tuning also selected probabilistic labels when available (Wikipedia datasets), as in the work of Wulczyn et al."}, {"heading": "3.2 RNN-based methods", "text": "RNN: The RNN method is a chain of GRU cells (Cho et al., 2014) that transforms the tokens w1 . . . , wk of each comment to hidden states h1 . . . , hk, followed by an LR layer that uses hk to classify the comment (accept, reject). Formally, given the vocabulary V , a matrixE \u2208 Rd\u00d7|V | containing d-dimensional word embeddings, an initial h0, and a comment c = \u3008w1, . . . , wk\u3009, the RNN computes h1, . . . , hk as follows (ht \u2208 Rm):\nh\u0303t = tanh(Whxt + Uh(rt ht\u22121) + bh) ht = (1\u2212 zt) ht\u22121 + zt h\u0303t zt = \u03c3(Wzxt + Uzht\u22121 + bz)\nrt = \u03c3(Wrxt + Urht\u22121 + br)\nwhere h\u0303t \u2208 Rm is the proposed hidden state at position t, obtained by considering the word embedding xt of token wt and the previous hidden state\nAPI (http://www.perspectiveapi.com/). 6Wulczyn et al. (2017) report results only on W-ATT-DEV. We repeated the tuning by evaluating on W-ATT-DEV, and again character n-grams with LR were selected.\nht\u22121; denotes element-wise multiplication; rt \u2208 Rm is the reset gate (for rt all zeros, it allows the RNN to forget the previous state ht\u22121); zt \u2208 Rm is the update gate (for zt all zeros, it allows the RNN to ignore the new proposed h\u0303t, hence also xt, and copy ht\u22121 as ht); \u03c3 is the sigmoid function; Wh,Wz,Wr \u2208 Rm\u00d7d; Uh, Uz, Ur \u2208 Rm\u00d7m; bh, bz, br \u2208 Rm. Once hk has been computed, the LR layer estimates the probability that comment c should be rejected, with Wp \u2208 R1\u00d7m, bp \u2208 R:\nPRNN(reject|c) = \u03c3(Wphk + bp)\na-RNN: When the attention mechanism is added, the LR layer considers the weighted sum hsum of all the hidden states, instead of just hk (Fig. 2):\nhsum = k\u2211 t=1 atht (1)\nPa\u2212RNN(reject|c) = \u03c3(Wphsum + bp)\nThe weights at are produced by an attention mechanism, which is an MLP with l layers:\na (1) t = ReLU(W (1)ht + b (1)) (2)\n. . .\na (l\u22121) t = ReLU(W (l\u22121)a (l\u22122) t + b (l\u22121))\na (l) t = W (l)a (l\u22121) t + b (l)\nat = softmax(a (l) t ; a (l) 1 , . . . , a (l) k )\nwhere a(1)t , . . . , a (l\u22121) t \u2208 Rr, a (l) t , at \u2208 R, W (1) \u2208 Rr\u00d7m, W (2), . . . ,W (l\u22121) \u2208 Rr\u00d7r, W (l) \u2208 R1\u00d7r, b(1), . . . , b(l\u22121) \u2208 Rr, b(l) \u2208 R. The softmax operates across all the a(l)t (t = 1, . . . , k), making the attention weights at sum to 1. Our attention mechanism differs from most previous ones (Mnih et al., 2014; Bahdanau et al., 2015; Xu et al., 2015; Luong et al., 2015) in that it is used in a classification setting, where there is no previously generated output subsequence (e.g., partly generated translation) to drive the attention (e.g., assign more weight to source words to translate next), unlike seq2seq models (Sutskever et al., 2014). It assigns larger weights at to hidden states ht corresponding to positions where there is more evidence that the comment should be accepted or rejected.\nYang et al. (2016) use a similar attention mechanism, but ours is deeper. In effect they always set l = 2, whereas we allow l to be larger (tuning selects l = 4).7 On the other hand, the attention\n7Yang et al. use tanh instead of ReLU in Eq. 2, which works worse in our case, and no bias b(l) in the l-th layer.\nmechanism of Yang et al. is part of a classification method for longer texts (e.g., product reviews). Their method uses two GRU RNNs, both bidirectional (Schuster and Paliwal, 1997), one turning the word embeddings of each sentence to a sentence embedding, and one turning the sentence embeddings to a document embedding, which is then fed to an LR layer. Yang et al. use their attention mechanism in both RNNs, to assign attention scores to words and sentences. We consider shorter texts (comments), we have a single RNN, and we assign attention scores to words only.8\nda-RNN: In a variant of a-RNN, called da-RNN (direct attention), the input to the first layer of the attention mechanism is the embedding xt of word wt, rather than ht (cf. Eq. 2; W (1,x) \u2208 Rr\u00d7d):\na (1) t = ReLU(W (1,x)xt + b (1)) (3)\nIntuitively, the attention of a-RNN considers each word embedding xt in its (left) context, modelled by ht, whereas the attention of da-RNN considers directly xt without its context, but hsum is still the weighted sum of the hidden states (Eq. 1).\neq-RNN: In another variant of a-RNN, called eqRNN, we assign equal attention to all the hidden states. The feature vector of the LR layer is now the average hsum = 1k \u2211k t=1 ht (cf. Eq. 1). da-CENT: For ablation testing, we also experiment with a variant, called da-CENT, that does not use the hidden states of the RNN. The input to the attention mechanism is now directly the embedding xt instead of ht (as in da-RNN, Eq. 3), and\n8We tried a bidirectional instead of unidirectional GRU chain in our methods, also replacing the LR layer by a deeper classification MLP, but there were no improvements.\nhsum is the weighted average (centroid) of word embeddings hsum = \u2211k t=1 atxt (cf. Eq. 1). 9\neq-CENT: For further ablation, we also experiment with eq-CENT, which uses neither the RNN nor the attention mechanism. The feature vector of the LR layer is now simply the average of word embeddings hsum = 1k \u2211k t=1 xt (cf. Eq. 1).\nWe set l = 4, d = 300,m = r = 128, having tuned the hyper-parameters of RNN and a-RNN on the same 2% held-out training comments used to tune DETOX; da-RNN, eq-RNN, daCENT, and eq-CENT use the same hyper-parameter values as a-RNN, to make their results more directly comparable and save time. We use Glorot initialization (Glorot and Bengio, 2010), crossentropy loss, and Adam (Kingma and Ba, 2015).10 Early stopping evaluates on the same held-out subsets. For Gazzetta, word embeddings are initialized to the WORD2VEC embeddings we provide (Section 2.1). For the Wikipedia datasets, they are initialized to GLOVE embeddings (Pennington et al., 2014).11 In both cases, the embeddings are updated during backpropagation. Out of vocabulary (OOV) words, meaning words not encountered in the training set and/or words we have no initial embeddings for, are mapped (during training and testing) to a single randomly initialized embedding, which is also updated during training.12"}, {"heading": "3.3 CNN", "text": "We also compare against a vanilla CNN operating on word embeddings. We describe the CNN only briefly, because it is very similar to that of of Kim (2014); see also Goldberg (2016) for an introduction to CNNs, and Zhang and Wallace (2015).\nFor Wikipedia comments, we use a \u2018narrow\u2019 convolution layer, with kernels sliding (stride 1) over (entire) embeddings of word n-grams of sizes n = 1, . . . , 4. We use 300 kernels for each n value, a total of 1,200 kernels. The outputs of each kernel, obtained by applying the kernel to the different n-grams of a comment c, are then max-pooled, leading to a single output per kernel. The resulting feature vector (1,200 max-\n9We also tried tf-idf scores in the hsum of da-CENT, instead of attention scores, but preliminary results were poor.\n10We used Keras (http://keras.io/) with the TensorFlow back-end (http://www.tensorflow.org/).\n11See https://nlp.stanford.edu/projects/ glove/. We use \u2018Common Crawl\u2019 (840B tokens).\n12For Gazzetta, words encountered only once in the training set (G-TRAIN-L or G-TRAIN-S) are also treated as OOV.\npooled outputs) goes through a dropout layer (Hinton et al., 2012) (p = 0.5), and then to an LR layer, which provides PCNN(reject|c). For Gazzetta, the CNN is the same, except that n = 1, . . . , 5, leading to 1,500 features per comment. All hyperparameters were tuned on the 2% held-out training comments used to tune the other methods. Again, we use 300-dimensional word embeddings, which are now randomly initialized, since tuning indicated this was better than initializing to pretrained embeddings. OOV words are treated as in the RNN-based methods. All embeddings are updated. Early stopping evaluates on the held-out subsets. Again, we use Glorot initialization, crossentropy loss, and Adam.13"}, {"heading": "3.4 LIST baseline", "text": "A baseline, called LIST, collects every wordw that occurs in more than 10 (for W-ATT-TRAIN, WTOX-TRAIN, G-TRAIN-S) or 100 comments (for G-TRAIN-L) in the training set, along with the precision of w, i.e., the ratio of rejected training comments containing w divided by the total number of training comments containing w. The resulting lists contain 10,423, 11,360, 16,864, and 21,940 word types, when using W-ATT-TRAIN, W-TOXTRAIN, G-TRAIN-S, G-TRAIN-L, respectively. For a comment c, PLIST(reject|c) is the maximum precision of all the words in c."}, {"heading": "3.5 Tuning thresholds", "text": "All methods produce a p = P (reject|c) per comment c. In semi-automatic moderation (Fig. 1), a comment is directly rejected if its p is above a rejection threshold tr, it is directly accepted if p is below an acceptance threshold ta, and it is shown to a moderator if ta \u2264 p \u2264 tr (gray zone of Fig. 3).\nIn our experience, moderators (or their employers) can easily specify the approximate percentage of comments they can afford to check manually (e.g., 20% daily) or, equivalently, the approximate percentage of comments the system should handle automatically. We call coverage the latter percentage; hence, 1 \u2212 coverage is the approximate\n13We implemented the CNN directly in TensorFlow.\npercentage of comments to be checked manually. By contrast, moderators are baffled when asked to tune tr and ta directly. Consequently, we ask them to specify the approximate desired coverage. We then sort the comments of the development set (GDEV, W-ATT-DEV, W-TOX-DEV) by p, and slide ta from 0.0 to 1.0 (Fig. 3). For each ta value, we set tr to the value that leaves a 1 \u2212 coverage percentage of development comments in the gray zone (ta \u2264 p \u2264 tr). We then select the ta (and tr) that maximizes the weighted harmonic mean F\u03b2(Preject, Paccept) on the development set:\nF\u03b2(Preject, Paccept) = (1 + \u03b22) \u00b7 Preject \u00b7 Paccept \u03b22 \u00b7 Preject + Paccept\nwhere Preject is the rejection precision (correctly rejected comments divided by rejected comments) and Paccept is the acceptance precision (correctly accepted divided by accepted). Intuitively, coverage sets the width of the gray zone, whereas Preject and Paccept show how certain we can be that the red (reject) and green (accept) zones are free of misclassified comments. We set \u03b2 = 2, emphasizing Paccept, because moderators are more worried about wrongly accepting abusive comments than wrongly rejecting non-abusive ones.14 The selected ta, tr (tuned on development data) are then used in experiments on test data. In fully automatic moderation, coverage = 100% and ta = tr; otherwise, threshold tuning is identical."}, {"heading": "4 Experimental results", "text": "Following Wulczyn et al. (2017), we report in Tables 2\u20133 AUC scores (area under ROC curve), along with Spearman correlations between system-generated probabilities P (accept|c) and human probabilistic gold labels (Section 2.2) when probabilistic gold labels are available.15\nA first observation is that increasing the size of the Gazzetta training set (G-TRAIN-S to G-TRAINL, Table 2) significantly improves the performance of all methods; we do not report DETOX results for G-TRAIN-L, because its implementation could not handle the size of G-TRAIN-L. Tables 2\u20133\n14More precisely, when computing F\u03b2 , we reorder the development comments by time posted, and split them into batches of 100. For each ta (and tr) value, we compute F\u03b2 per batch and macro-average across batches. The resulting thresholds lead to F\u03b2 scores that are more stable over time.\n15When computing AUC, the gold label is the majority label of the annotators. When computing Spearman, the gold label is probabilistic (% of annotators that accepted the comment). The decisions of the systems are always probabilistic.\nalso show that RNN is always better than CNN and DETOX; there is no clear winner between CNN and DETOX. Furthermore, a-RNN is always better than RNN on Gazzetta comments (Table 2), but not always on Wikipedia comments (Table 3). Another observation is that da-RNN is always worse than a-RNN (Tables 2\u20133), confirming that the hidden states of the RNN are a better input to the attention mechanism than word embeddings. The performance of da-RNN deteriorates further when equal attention is assigned to the hidden states (eq-RNN), when the weighted sum of hidden states (hsum) is replaced by the weighted sum of word embeddings (da-CENT), or both (eq-CENT). Also, da-CENT outperforms eq-CENT, indicating that the attention mechanism improves the performance of simply averaging word embeddings. The Wikipedia subsets are easier (all methods perform better on Wikipedia subsets, compared to Gazzetta).\nFigure 4 shows F2(Preject, Paccept) on G-TESTL, G-TEST-S, W-ATT-TEST, W-TOX-TEST, when ta, tr are tuned on the corresponding development tests for varying coverage. For the Gazzetta datasets, we show results training on G-TRAIN-S (solid lines) and G-TRAIN-L (dashed). The differences between RNN and a-RNN are again small, but it is now easier to see that a-RNN is overall better. Again, a-RNN and RNN are better than CNN and DETOX, and the results improve with a larger training set (dashed). On W-ATT-TEST and W-\nTOX-TEST, a-RNN obtains Paccept, Preject \u2265 0.94 for all coverages (Fig. 4, call-outs). On the more difficult Gazzetta datasets, a-RNN still obtains Paccept, Preject \u2265 0.85 when tuned for 50% coverage. When tuned for 100% coverage, comments for which the system is uncertain (gray zone) cannot be avoided and there are inevitably more misclassifications; the use of F2 during threshold tuning places more emphasis on avoiding wrongly accepted comments, leading to high Paccept (\u2265 0.82), at the expense of wrongly rejected comments, i.e., sacrificing Preject (\u2265 0.56). On the re-moderated G-TEST-S-R (similar diagrams, not shown), Paccept, Preject become 0.96, 0.88 for coverage 50%, and 0.92, 0.48 for coverage 100%."}, {"heading": "5 Related work", "text": "Napoles et al. (2017b) developed an annotation scheme for online conversations, with 6 dimensions for comments (e.g., sentiment, tone, offtopic) and 3 dimensions for threads. The scheme was used to label a dataset, called YNACC, of 9.2K comments (2.4K threads) from Yahoo News and 16.6K comments (1K threads) from the Internet Argument Corpus (Walker et al., 2012; Abbott et al., 2016). Abusive comments were filtered out, hence YNACC cannot be used for our purposes, but it may be possible to extend the annotation scheme for abusive comments, to predict more fine-grained labels, instead of \u2018accept\u2019 or \u2018re-\nject\u2019. Napoles et al. also reported that up/down votes, a form of social filtering, are inappropriate proxies for comment and thread quality. Lee et al. (2014) discuss social filtering in detail and propose features (e.g., thread depth, no. of revisiting users) to assess the quality of a thread without processing the texts of its comments. Diakopoulos (2015) discusses how editors select high quality comments.\nIn further work, Napoles et al. (2017a) aimed to identify high quality threads. Their best method converts each comment to a comment embedding using DOC2VEC (Le and Mikolov, 2014). An ensemble of Conditional Random Fields (CRFs) (Lafferty et al., 2001) assigns labels (from their annotation scheme, e.g., for sentiment, off-topic) to the comments of each thread, viewing each thread as a sequence of DOC2VEC embeddings. The decisions of the CRFs are then used to convert each thread to a feature vector (total count and mean marginal probability of each label in the thread), which is passed on to an LR classifier. Further improvements were observed when additional features were added, BOW counts and POS n-grams being the most important ones. Napoles et al. (2017a) also experimented with a CNN, similar to that of Section 3.3, which was not however a topperformer, presumably because of the small size of the training set (2.1K YNACC threads).\nDjuric et al. (2015) experimented with 952K manually moderated comments from Yahoo Finance, but their dataset is not publicly available. They convert each comment to a DOC2VEC embedding, which is fed to an LR classifier. No-\nbata et al. (2016) experimented with approx. 3.3M manually moderated comments from Yahoo Finance and News; their data are also not available.16 They used Vowpal Wabbit17 with character n-grams (n = 3, . . . , 5) and word n-grams (n = 1, 2), hand-crafted features (e.g., comment length, number of capitalized or black-listed words), features based on dependency trees, averages of WORD2VEC embeddings, and DOC2VEClike embeddings. Character n-grams were the best, on their own outperforming Djuric et al. (2015). The best results, however, were obtained using all features. By contrast, we use no handcrafted features and parsers, making our methods easily portable to other domains and languages.\nWulczyn et al. (2017) experimented with character and word n-grams, based on the findings of Nobata et al. (2016). We included their dataset and moderation system (DETOX) in our experiments. Wulczyn et al. also used DETOX (trained on WATT-TRAIN) as a proxy (instead of human annotators) to automatically classify 63M Wikipedia comments, which were then used to study the problem of personal attacks (e.g., the effect of allowing anonymous comments, how often personal attacks were followed by moderation actions). Our methods could replace DETOX in studies of this kind, since they perform better.\nWaseem et al. (2016) used approx. 17K tweets annotated for hate speech. Their best method was an LR classifier with character n-grams (n = 1, . . . , 4) and a gender feature. Badjatiya et al. (2017) experimented with the same dataset using LR, SVMs (Cortes and Vapnik, 1995), Random Forests (Ho, 1995), Gradient Boosted Decision Trees (GBDT) (Friedman, 2002), CNN (similar to that of Section 3.3), LSTM (Greff et al., 2015), FastText (Joulin et al., 2017). They also considered alternative feature sets: character n-grams, tfidf vectors, word embeddings, averaged word embeddings. Their best results were obained using GBDT with averaged word embeddings learned by the LSTM, starting from random embeddings.\nWarner and Hirschberg (2012) aimed to detect anti-semitic speech, experimenting with 9K paragraphs and a linear SVM. Their features consider windows of up to 5 tokens, the tokens of each window, their order, POS tags, Brown clusters etc., following Yarowsky (1994).\n16According to Nobata et al., their clean test dataset (2K comments) would be made available, but it is currently not.\n17See http://hunch.net/\u02dcvw/.\nCheng et al. (2015) predict which users would be banned from on-line communities. Their best system uses a Random Forest or LR classifier, with features examining readability, activity (e.g., number of posts daily), community and moderator reactions (e.g., up-votes, number of deleted posts).\nLukin and Walker (2013) experimented with 5.5K utterances from the Internet Argument Corpus (Walker et al., 2012; Abbott et al., 2016) annotated with nastiness scores, and 9.9K utterances from the same corpus annotated for sarcasm.18 In a bootstrapping manner, they manually identified cue words and phrases (indicative of nastiness or sarcasm), used the cue words to obtain training comments, and extracted patterns from the training comments. Xiang et al. (2012) also employed bootstrapping to identify users whose tweets frequently or never contain profane words, and collected 381M tweets from the two user types. They trained decision tree, Random Forest, or LR classifiers to distinguish between tweets from the two user types, testing on 4K tweets manually labeled as containing profanity or not. The classifiers used topical features, obtained via LDA (Blei et al., 2003), and a feature indicating the presence of at least one of approx. 330 known profane words.\nSood et al. (2012a; 2012b) experimented with 6.5K comments from Yahoo Buzz, moderated via crowdsourcing. They showed that a linear SVM, representing each comment as a bag of word bigrams and stems, performs better than word lists. Their best results were obtained by combining the SVM with a word list and edit distance.\nYin et al. (2009) used posts from chat rooms and discussion fora (<15K posts in total) to train an SVM to detect online harassment. They used TF-IDF, sentiment, and context features (e.g., similarity to other posts in a thread).19 Our methods might also benefit by considering threads, rather than individual comments. Yin et al. point out that unlike other abusive content, spam in comments or discussion fora (Mishne et al., 2005; Niu et al., 2007) is off-topic and serves a commercial purpose. Spam is unlikely in Wikipedia discussions and extremely rare so far in Gazzetta comments.\nMihaylov and Nakov (2016) identify comments posted by opinion manipulation trolls. Dinakar et\n18For sarcasm, see Davidov et al. (2010), Gonzalez-Ibanez et al. (2011), Joshi et al. (2015), Oraby et al. (2016).\n19Sentiment features have been used by several methods, but sentiment analysis (Pang and Lee, 2008; Liu, 2015) is typically not directly concerned with abusive content.\nal. (2011) and Dadvar et al. (2013) detect cyberbullying. Chandrinos et al. (2000) detect pornographic web pages, using a Naive Bayes classifier with text and image features. Spertus (1997) flag flame messages in Web feedback forms, using decision trees and hand-crafted features. A Kaggle dataset for insult detection is also available.20 It contains 6.6K comments (3,947 train, 2,647 test) labeled as insults or not. However, abusive comments that do not directly insult other participants of the same discussion are not classified as insults, even if they contain profanity, hate speech, insults to third persons etc."}, {"heading": "6 Conclusions", "text": "We experimented with a new publicly available dataset of 1.6M moderated user comments from a Greek sports news portal and two existing datasets of English Wikipedia talk page comments. We showed that a GRU RNN operating on word embeddings outperforms the previous state of the art, which used an LR or MLP classifier with character or word n-gram features. It also outperforms a vanilla CNN operating on word embeddings, and a baseline that uses an automatically constructed word list with precision scores. A novel, deep, classification-specific attention mechanism improves further the overall results of the RNN. The attention mechanism also improves the results of a simpler method that averages word embeddings. We considered both fully automatic and semi-automatic moderation, along with threshold tuning and evaluation measures for both.\nWe plan to consider user-specific information (e.g., ratio of comments rejected in the past) and thread statistics (e.g., thread depth, number of revisiting users) (Dadvar et al., 2013; Lee et al., 2014; Cheng et al., 2015; Waseem and Hovy, 2016). We also plan to explore character-level RNNs or CNNs (Zhang et al., 2015), for example to produce embeddings of unknown or obfuscated words from characters (dos Santos and Zadrozny, 2014; Ling et al., 2015). We are also exploring how the attention scores of a-RNN can be used to highlight \u2018suspicious\u2019 words or phrases when showing gray comments to moderators.\n20See http://www.kaggle.com/, data description of the competition \u2018Detecting Insults in Social Commentary\u2019."}, {"heading": "Acknowledgments", "text": "This work was funded by Google\u2019s Digital News Initiative (project ML2P, contract 362826).21 We are grateful to Gazzetta for the data they provided. We also thank Gazzetta\u2019s moderators for their feedback, insights, and advice."}], "references": [{"title": "Internet Argument Corpus 2.0: An SQL schema for dialogic social media and the corpora to go", "author": ["R. Abbott", "B. Ecker", "P. Anand", "M.A. Walker"], "venue": null, "citeRegEx": "Abbott et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Abbott et al\\.", "year": 2016}, {"title": "Deep learning for hate speech detection in tweets", "author": ["P. Badjatiya", "S. Gupta", "M. Gupta", "V. Varma."], "venue": "WWW (Companion). Perth, Australia, pages 759\u2013 760.", "citeRegEx": "Badjatiya et al\\.,? 2017", "shortCiteRegEx": "Badjatiya et al\\.", "year": 2017}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["D. Bahdanau", "K. Cho", "Y. Bengio."], "venue": "ICLR. San Diego, CA.", "citeRegEx": "Bahdanau et al\\.,? 2015", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2015}, {"title": "Latent Dirichlet Allocation", "author": ["D.M. Blei", "A.Y. Ng", "M.I. Jordan."], "venue": "Journal of Machine Learning Research 3:993\u20131022.", "citeRegEx": "Blei et al\\.,? 2003", "shortCiteRegEx": "Blei et al\\.", "year": 2003}, {"title": "Automatic Web rating: Filtering obscene content on the Web", "author": ["K.V. Chandrinos", "I. Androutsopoulos", "G. Paliouras", "C.D. Spyropoulos."], "venue": "Proc. of the 4th European Conference on Research and Advanced Technology for Digital Libraries. Lisbon,", "citeRegEx": "Chandrinos et al\\.,? 2000", "shortCiteRegEx": "Chandrinos et al\\.", "year": 2000}, {"title": "Antisocial behavior in online discussion communities", "author": ["J. Cheng", "C. Danescu-Niculescu-Mizil", "J. Leskovec."], "venue": "Proc. of the International AAAI Conference on Web and Social Media. Oxford University, England, pages 61\u201370.", "citeRegEx": "Cheng et al\\.,? 2015", "shortCiteRegEx": "Cheng et al\\.", "year": 2015}, {"title": "Learning phrase representations using RNN encoder\u2013decoder for statistical machine translation", "author": ["K. Cho", "B. van Merrienboer", "C. Gulcehre", "D. Bahdanau", "F. Bougares", "H. Schwenk", "Y. Bengio."], "venue": "EMNLP. Doha, Qatar, pages 1724\u20131734.", "citeRegEx": "Cho et al\\.,? 2014", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "A coefficient of agreement for nominal scales", "author": ["J. Cohen."], "venue": "Educational and Psychological Measurement 20(1):37\u201346.", "citeRegEx": "Cohen.,? 1960", "shortCiteRegEx": "Cohen.", "year": 1960}, {"title": "Support-Vector Networks", "author": ["C. Cortes", "Vladimir Vapnik."], "venue": "Machine Learning 20(3):273\u2013297.", "citeRegEx": "Cortes and Vapnik.,? 1995", "shortCiteRegEx": "Cortes and Vapnik.", "year": 1995}, {"title": "Improving cyberbullying detection with user context", "author": ["M. Dadvar", "D. Trieschnigg", "R. Ordelman", "F. de Jong."], "venue": "ECIR. Moscow, Russia, pages 693\u2013696.", "citeRegEx": "Dadvar et al\\.,? 2013", "shortCiteRegEx": "Dadvar et al\\.", "year": 2013}, {"title": "Semisupervised recognition of sarcastic sentences in Twitter and Amazon", "author": ["D. Davidov", "O. Tsur", "A. Rappoport."], "venue": "CoNLL. Uppsala, Sweden, pages 107\u2013116. See https://digitalnewsinitiative.com/.", "citeRegEx": "Davidov et al\\.,? 2010", "shortCiteRegEx": "Davidov et al\\.", "year": 2010}, {"title": "Picking the NYT picks: Editorial criteria and automation in the curation of online news comments", "author": ["N. Diakopoulos."], "venue": "Journal of the International Symposium on Online Journalism 5:147\u2013166.", "citeRegEx": "Diakopoulos.,? 2015", "shortCiteRegEx": "Diakopoulos.", "year": 2015}, {"title": "Modeling the detection of textual cyberbullying", "author": ["K. Dinakar", "R. Reichart", "H. Lieberman."], "venue": "The Social Mobile Web. Barcelona, Spain, volume WS-11-02 of AAAI Workshops, pages 11\u201317.", "citeRegEx": "Dinakar et al\\.,? 2011", "shortCiteRegEx": "Dinakar et al\\.", "year": 2011}, {"title": "Hate speech detection with comment embeddings", "author": ["N. Djuric", "J. Zhou", "R. Morris", "M. Grbovic", "V. Radosavljevic", "N. Bhamidipati."], "venue": "WWW. Florence, Italy, pages 29\u201330.", "citeRegEx": "Djuric et al\\.,? 2015", "shortCiteRegEx": "Djuric et al\\.", "year": 2015}, {"title": "Learning character-level representations for part-of-speech tagging", "author": ["C.N. dos Santos", "B. Zadrozny."], "venue": "ICML. Beijing, China, pages 1818\u2013 1826.", "citeRegEx": "Santos and Zadrozny.,? 2014", "shortCiteRegEx": "Santos and Zadrozny.", "year": 2014}, {"title": "Stochastic gradient boosting", "author": ["J.H. Friedman."], "venue": "Computational Statistics and Data Analysis 38(4):367\u2013378.", "citeRegEx": "Friedman.,? 2002", "shortCiteRegEx": "Friedman.", "year": 2002}, {"title": "Understanding the difficulty of training deep feedforward neural networks", "author": ["X. Glorot", "Y. Bengio."], "venue": "Proc. of the International Conference on Artificial Intelligence and Statistics. Sardinia, Italy, pages 249\u2013256.", "citeRegEx": "Glorot and Bengio.,? 2010", "shortCiteRegEx": "Glorot and Bengio.", "year": 2010}, {"title": "A primer on neural network models for natural language processing", "author": ["Y. Goldberg."], "venue": "Journal of Artificial Intelligence Research 57:345\u2013420.", "citeRegEx": "Goldberg.,? 2016", "shortCiteRegEx": "Goldberg.", "year": 2016}, {"title": "Identifying sarcasm in Twitter: A closer look", "author": ["R.I. Gonz\u00e1lez-Ib\u00e1\u00f1ez", "S. Muresan", "N. Wacholder."], "venue": "ACL. Portland, Oregon, pages 581\u2013586.", "citeRegEx": "Gonz\u00e1lez.Ib\u00e1\u00f1ez et al\\.,? 2011", "shortCiteRegEx": "Gonz\u00e1lez.Ib\u00e1\u00f1ez et al\\.", "year": 2011}, {"title": "Deep Learning", "author": ["I. Goodfellow", "Y. Bengio", "A. Courville."], "venue": "MIT Press.", "citeRegEx": "Goodfellow et al\\.,? 2016", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2016}, {"title": "LSTM: A search space Odyssey", "author": ["K. Greff", "R.K. Srivastava", "J. Koutn\u0131\u0301k", "B.R. Steunebrink", "J. Schmidhuber"], "venue": "CoRR abs/1503.04069", "citeRegEx": "Greff et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Greff et al\\.", "year": 2015}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors", "author": ["G.E. Hinton", "N. Srivastava", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov."], "venue": "CoRR abs/1207.0580.", "citeRegEx": "Hinton et al\\.,? 2012", "shortCiteRegEx": "Hinton et al\\.", "year": 2012}, {"title": "Random Decision Forests", "author": ["T.K. Ho."], "venue": "Proc. of the 3rd International Conference on Document Analysis and Recognition. Montreal, Canada, volume 1, pages 278\u2013282.", "citeRegEx": "Ho.,? 1995", "shortCiteRegEx": "Ho.", "year": 1995}, {"title": "Harnessing context incongruity for sarcasm detection", "author": ["A. Joshi", "V. Sharma", "P. Bhattacharyya."], "venue": "ACL. Beijing, China, pages 757\u2013762.", "citeRegEx": "Joshi et al\\.,? 2015", "shortCiteRegEx": "Joshi et al\\.", "year": 2015}, {"title": "Bag of tricks for efficient text classification", "author": ["A. Joulin", "E. Grave", "P. Bojanowski", "T. Mikolov."], "venue": "EACL (short papers). Valencia, Spain, pages 427\u2013 431.", "citeRegEx": "Joulin et al\\.,? 2017", "shortCiteRegEx": "Joulin et al\\.", "year": 2017}, {"title": "Convolutional neural networks for sentence classification", "author": ["Y. Kim."], "venue": "EMNLP. Doha, Qatar, pages 1746\u20131751.", "citeRegEx": "Kim.,? 2014", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "Adam: A method for stochastic optimization", "author": ["D.P. Kingma", "J. Ba."], "venue": "ICLR. San Diego, CA.", "citeRegEx": "Kingma and Ba.,? 2015", "shortCiteRegEx": "Kingma and Ba.", "year": 2015}, {"title": "Content Analysis: An Introduction to Its Methodology (2nd edition)", "author": ["K. Krippendorff."], "venue": "Sage Publications.", "citeRegEx": "Krippendorff.,? 2004", "shortCiteRegEx": "Krippendorff.", "year": 2004}, {"title": "Conditional Random Fields: Probabilistic models for segmenting and labeling sequence data", "author": ["J.D. Lafferty", "A. McCallum", "F.C.N. Pereira."], "venue": "ICML. Williamstown, MA, pages 282\u2013289.", "citeRegEx": "Lafferty et al\\.,? 2001", "shortCiteRegEx": "Lafferty et al\\.", "year": 2001}, {"title": "Distributed representations of sentences and documents", "author": ["Q.V. Le", "T. Mikolov."], "venue": "ICML. Beijing, China, pages 1188\u20131196.", "citeRegEx": "Le and Mikolov.,? 2014", "shortCiteRegEx": "Le and Mikolov.", "year": 2014}, {"title": "Discovering high-quality threaded discussions in online forums", "author": ["J.-T. Lee", "M.-C. Yang", "H.-C. Rim."], "venue": "Journal of Computer Science and Technology 29(3):519\u2013531.", "citeRegEx": "Lee et al\\.,? 2014", "shortCiteRegEx": "Lee et al\\.", "year": 2014}, {"title": "Finding function in form: Compositional character models for open vocabulary word representation", "author": ["W. Ling", "C. Dyer", "A.W. Black", "I. Trancoso", "R. Fermandez", "S. Amir", "L. Marujo"], "venue": "Lu\u0131\u0301s", "citeRegEx": "Ling et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ling et al\\.", "year": 2015}, {"title": "Sentiment Analysis \u2013 Mining Opinions, Sentiments, and Emotions", "author": ["B. Liu."], "venue": "Cambridge University Press.", "citeRegEx": "Liu.,? 2015", "shortCiteRegEx": "Liu.", "year": 2015}, {"title": "Really? well", "author": ["S. Lukin", "M. Walker."], "venue": "apparently bootstrapping improves the performance of sarcasm and nastiness classifiers for online dialogue. In Proc. of the Workshop on Language in Social Media. Atlanta, Georgia, pages 30\u201340.", "citeRegEx": "Lukin and Walker.,? 2013", "shortCiteRegEx": "Lukin and Walker.", "year": 2013}, {"title": "Effective approaches to attention-based neural machine translation", "author": ["T. Luong", "H. Pham", "C.D. Manning."], "venue": "EMNLP. Lisbon, Portugal, pages 1412\u20131421.", "citeRegEx": "Luong et al\\.,? 2015", "shortCiteRegEx": "Luong et al\\.", "year": 2015}, {"title": "Hunting for troll comments in news community forums", "author": ["T. Mihaylov", "P. Nakov."], "venue": "ACL. Berlin, Germany, pages 399\u2013405.", "citeRegEx": "Mihaylov and Nakov.,? 2016", "shortCiteRegEx": "Mihaylov and Nakov.", "year": 2016}, {"title": "Efficient estimation of word representations in vector space", "author": ["T. Mikolov", "K. Chen", "G. Corrado", "J. Dean."], "venue": "ICLR. Scottsdale, AZ.", "citeRegEx": "Mikolov et al\\.,? 2013a", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Linguistic regularities in continuous space word representations", "author": ["T. Mikolov", "W.-t. Yih", "G. Zweig."], "venue": "NAACL-HLT . Atlanta, GA, pages 746\u2013751.", "citeRegEx": "Mikolov et al\\.,? 2013b", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Blocking blog spam with language model disagreement", "author": ["G. Mishne", "D. Carmel", "R. Lempel."], "venue": "Proc. of the International Workshop on Adversarial Information Retrieval on the Web. Chiba, Japan.", "citeRegEx": "Mishne et al\\.,? 2005", "shortCiteRegEx": "Mishne et al\\.", "year": 2005}, {"title": "Recurrent models of visual attention", "author": ["V. Mnih", "N. Heess", "A. Graves", "K. Kavukcuoglu."], "venue": "NIPS. Montreal, Canada, pages 2204\u20132212.", "citeRegEx": "Mnih et al\\.,? 2014", "shortCiteRegEx": "Mnih et al\\.", "year": 2014}, {"title": "Automatically identifying good conversations online (yes, they do exist!)", "author": ["C. Napoles", "A. Pappu", "J. Tetreault."], "venue": "Proc. of the International AAAI Conference on Web and Social Media.", "citeRegEx": "Napoles et al\\.,? 2017a", "shortCiteRegEx": "Napoles et al\\.", "year": 2017}, {"title": "Finding good conversations online: The Yahoo News annotated comments corpus", "author": ["C. Napoles", "J. Tetreault", "E. Rosato", "B. Provenzale", "A. Pappu."], "venue": "Proc. of the Linguistic Annotation Workshop. Valencia, Spain, pages 13\u201323.", "citeRegEx": "Napoles et al\\.,? 2017b", "shortCiteRegEx": "Napoles et al\\.", "year": 2017}, {"title": "A quantitative study of forum spamming using context-based analysis", "author": ["Y. Niu", "Y.-M. Wang", "H. Chen", "M. Ma", "F. Hsu."], "venue": "Proc. of the Annual Network and Distributed System Security Symposium. San Diego, CA, pages 79\u201392.", "citeRegEx": "Niu et al\\.,? 2007", "shortCiteRegEx": "Niu et al\\.", "year": 2007}, {"title": "Abusive language detection in online user content", "author": ["C. Nobata", "J. Tetreault", "A. Thomas", "Y. Mehdad", "Y. Chang."], "venue": "WWW. Montreal, Canada, pages 145\u2013153.", "citeRegEx": "Nobata et al\\.,? 2016", "shortCiteRegEx": "Nobata et al\\.", "year": 2016}, {"title": "Creating and characterizing a diverse corpus of sarcasm in dialogue", "author": ["S. Oraby", "V. Harrison", "L. Reed", "E. Hernandez", "E. Riloff", "M.A. Walker."], "venue": "SIGDial. Los Angeles, CA, pages 31\u201341.", "citeRegEx": "Oraby et al\\.,? 2016", "shortCiteRegEx": "Oraby et al\\.", "year": 2016}, {"title": "Opinion mining and sentiment analysis", "author": ["B. Pang", "L. Lee."], "venue": "Foundations and Trends in Information Retrieval 2(1-2):1\u2013135.", "citeRegEx": "Pang and Lee.,? 2008", "shortCiteRegEx": "Pang and Lee.", "year": 2008}, {"title": "GloVe: Global vectors for word representation", "author": ["J. Pennington", "R. Socher", "C. Manning."], "venue": "EMNLP. Doha, Qatar, pages 1532\u20131543.", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Bidirectional recurrent neural networks", "author": ["M. Schuster", "K.K. Paliwal."], "venue": "IEEE Transacions of Signal Processing 45(11):2673\u20132681.", "citeRegEx": "Schuster and Paliwal.,? 1997", "shortCiteRegEx": "Schuster and Paliwal.", "year": 1997}, {"title": "Profanity use in online communities", "author": ["S. Sood", "J. Antin", "E.F. Churchill."], "venue": "SIGCHI. Austin, TX, pages 1481\u20131490.", "citeRegEx": "Sood et al\\.,? 2012a", "shortCiteRegEx": "Sood et al\\.", "year": 2012}, {"title": "Using crowdsourcing to improve profanity detection", "author": ["S. Sood", "J. Antin", "E.F. Churchill."], "venue": "AAAI Spring Symposium: Wisdom of the Crowd. Stanford, CA, pages 69\u201374.", "citeRegEx": "Sood et al\\.,? 2012b", "shortCiteRegEx": "Sood et al\\.", "year": 2012}, {"title": "Smokey: Automatic recognition of hostile messages", "author": ["E. Spertus."], "venue": "Proc. of the National Conference on Artificial Intelligence and the Innovative Applications of Artificial Intelligence Conference. Providence, Rhode Island, pages 1058\u20131065.", "citeRegEx": "Spertus.,? 1997", "shortCiteRegEx": "Spertus.", "year": 1997}, {"title": "Sequence to sequence learning with neural networks", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le."], "venue": "NIPS. Montreal, Canada, pages 3104\u20133112.", "citeRegEx": "Sutskever et al\\.,? 2014", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "A corpus for research on deliberation and debate", "author": ["M.A. Walker", "J.E. Fox Tree", "P. Anand", "R. Abbott", "J. King."], "venue": "LREC. Istanbul, Turkey, pages 4445\u2013 4452.", "citeRegEx": "Walker et al\\.,? 2012", "shortCiteRegEx": "Walker et al\\.", "year": 2012}, {"title": "Detecting hate speech on the World Wide Web", "author": ["W. Warner", "J. Hirschberg."], "venue": "Proc. of the 2nd Workshop on Language in Social Media. Montreal, Canada, pages 19\u201326.", "citeRegEx": "Warner and Hirschberg.,? 2012", "shortCiteRegEx": "Warner and Hirschberg.", "year": 2012}, {"title": "Hateful symbols or hateful people? Predictive features for hate speech detection on Twitter", "author": ["Z. Waseem", "D. Hovy."], "venue": "Proc. of the NAACL Student Research Workshop. San Diego, CA, pages 88\u201393.", "citeRegEx": "Waseem and Hovy.,? 2016", "shortCiteRegEx": "Waseem and Hovy.", "year": 2016}, {"title": "Ex machina: Personal attacks seen at scale", "author": ["E. Wulczyn", "N. Thain", "L. Dixon."], "venue": "WWW. Perth, Australia, pages 1391\u20131399.", "citeRegEx": "Wulczyn et al\\.,? 2017", "shortCiteRegEx": "Wulczyn et al\\.", "year": 2017}, {"title": "Detecting offensive tweets via topical feature discovery over a large scale twitter corpus", "author": ["G. Xiang", "B. Fan", "L. Wang", "J. Hong", "C. Rose."], "venue": "CIKM. Maui, Hawaii, pages 1980\u20131984.", "citeRegEx": "Xiang et al\\.,? 2012", "shortCiteRegEx": "Xiang et al\\.", "year": 2012}, {"title": "Show, attend and tell: Neural image caption generation with visual attention", "author": ["K. Xu", "J. Ba", "J.R. Kiros", "K. Cho", "A.C. Courville", "R. Salakhutdinov", "R.S. Zemel", "Y. Bengio."], "venue": "ICML. Lille, France, pages 2048\u20132057.", "citeRegEx": "Xu et al\\.,? 2015", "shortCiteRegEx": "Xu et al\\.", "year": 2015}, {"title": "Hierarchical attention networks for document classification", "author": ["Z. Yang", "D. Yang", "C. Dyer", "X. He", "A. Smola", "E. Hovy."], "venue": "NAACL-HLT . San Diego, CA, pages 1480\u20131489.", "citeRegEx": "Yang et al\\.,? 2016", "shortCiteRegEx": "Yang et al\\.", "year": 2016}, {"title": "Decision lists for lexical ambiguity resolution: Application to accent restoration in Spanish and French", "author": ["D. Yarowsky."], "venue": "ACL. Las Cruces, NM, pages 88\u201395.", "citeRegEx": "Yarowsky.,? 1994", "shortCiteRegEx": "Yarowsky.", "year": 1994}, {"title": "Detection of harassment on Web 2.0", "author": ["D. Yin", "Z. Xue", "L. Hong", "B.D. Davison", "A. Kontostathis", "L. Edwards"], "venue": "In Proc. of the WWW workshop on Content Analysis in the Web", "citeRegEx": "Yin et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Yin et al\\.", "year": 2009}, {"title": "Characterlevel convolutional networks for text classification", "author": ["X. Zhang", "J. Zhao", "Y. LeCun."], "venue": "NIPS. Montreal, Canada, pages 649\u2013657.", "citeRegEx": "Zhang et al\\.,? 2015", "shortCiteRegEx": "Zhang et al\\.", "year": 2015}, {"title": "A sensitivity analysis of (and practitioners\u2019 guide to) convolutional neural networks for sentence classification", "author": ["Y. Zhang", "B.C. Wallace."], "venue": "CoRR abs/1510.03820.", "citeRegEx": "Zhang and Wallace.,? 2015", "shortCiteRegEx": "Zhang and Wallace.", "year": 2015}], "referenceMentions": [{"referenceID": 19, "context": "1 We examine how deep learning (Goodfellow et al., 2016; Goldberg, 2016) can be used to moderate user comments.", "startOffset": 31, "endOffset": 72}, {"referenceID": 17, "context": "1 We examine how deep learning (Goodfellow et al., 2016; Goldberg, 2016) can be used to moderate user comments.", "startOffset": 31, "endOffset": 72}, {"referenceID": 55, "context": "We also experiment on the datasets of Wulczyn et al. (2017),", "startOffset": 38, "endOffset": 60}, {"referenceID": 55, "context": "outperforms the system of Wulczyn et al. (2017), the previous state of the art for comment moderation, which employed logistic regression (LR) or a multi-layered Perceptron (MLP).", "startOffset": 26, "endOffset": 48}, {"referenceID": 2, "context": "from most previous ones (Bahdanau et al., 2015; Luong et al., 2015) in that it is used in text classification, where there is no previously generated output subsequence to drive the attention, unlike sequence-to-sequence models (Sutskever et al.", "startOffset": 24, "endOffset": 67}, {"referenceID": 34, "context": "from most previous ones (Bahdanau et al., 2015; Luong et al., 2015) in that it is used in text classification, where there is no previously generated output subsequence to drive the attention, unlike sequence-to-sequence models (Sutskever et al.", "startOffset": 24, "endOffset": 67}, {"referenceID": 7, "context": "Using Cohen\u2019s Kappa (Cohen, 1960), the mean pairwise", "startOffset": 20, "endOffset": 33}, {"referenceID": 26, "context": "Krippendorff\u2019s (2004) alpha was 0.", "startOffset": 0, "endOffset": 22}, {"referenceID": 26, "context": "Krippendorff\u2019s (2004) alpha was 0.4762, close to the value (0.45) reported by Wulczyn et al. (2017) for Wikipedia comments.", "startOffset": 0, "endOffset": 100}, {"referenceID": 27, "context": "Inter-annotator agreement, measured on a random sample of 1K comments using Krippendorff\u2019s (2004) alpha, was 0.", "startOffset": 76, "endOffset": 98}, {"referenceID": 55, "context": "Wulczyn et al. (2017)", "startOffset": 0, "endOffset": 22}, {"referenceID": 55, "context": "a-RNN, a vanilla convolutional neural network (CNN) also operating on word embeddings, the DETOX system of Wulczyn et al. (2017), and a baseline that uses word lists with precision scores.", "startOffset": 107, "endOffset": 129}, {"referenceID": 55, "context": "DETOX (Wulczyn et al., 2017) was the previous state of the art in comment moderation, in the sense that it had the best reported results on the Wikipedia datasets (Section 2.", "startOffset": 6, "endOffset": 28}, {"referenceID": 22, "context": "Two of the co-authors of Wulczyn et al. (2017) are with Jigsaw, who recently announced Perspective, a system to detect \u2018toxic\u2019 comments.", "startOffset": 17, "endOffset": 47}, {"referenceID": 6, "context": "RNN: The RNN method is a chain of GRU cells (Cho et al., 2014) that transforms the tokens w1 .", "startOffset": 44, "endOffset": 62}, {"referenceID": 55, "context": "Wulczyn et al. (2017) report results only on W-ATT-DEV.", "startOffset": 0, "endOffset": 22}, {"referenceID": 39, "context": "Our attention mechanism differs from most previous ones (Mnih et al., 2014; Bahdanau et al., 2015; Xu et al., 2015; Luong et al., 2015) in that it is used in a classification setting, where there is no previously generated output subsequence (e.", "startOffset": 56, "endOffset": 135}, {"referenceID": 2, "context": "Our attention mechanism differs from most previous ones (Mnih et al., 2014; Bahdanau et al., 2015; Xu et al., 2015; Luong et al., 2015) in that it is used in a classification setting, where there is no previously generated output subsequence (e.", "startOffset": 56, "endOffset": 135}, {"referenceID": 57, "context": "Our attention mechanism differs from most previous ones (Mnih et al., 2014; Bahdanau et al., 2015; Xu et al., 2015; Luong et al., 2015) in that it is used in a classification setting, where there is no previously generated output subsequence (e.", "startOffset": 56, "endOffset": 135}, {"referenceID": 34, "context": "Our attention mechanism differs from most previous ones (Mnih et al., 2014; Bahdanau et al., 2015; Xu et al., 2015; Luong et al., 2015) in that it is used in a classification setting, where there is no previously generated output subsequence (e.", "startOffset": 56, "endOffset": 135}, {"referenceID": 51, "context": ", assign more weight to source words to translate next), unlike seq2seq models (Sutskever et al., 2014).", "startOffset": 79, "endOffset": 103}, {"referenceID": 2, "context": ", 2014; Bahdanau et al., 2015; Xu et al., 2015; Luong et al., 2015) in that it is used in a classification setting, where there is no previously generated output subsequence (e.g., partly generated translation) to drive the attention (e.g., assign more weight to source words to translate next), unlike seq2seq models (Sutskever et al., 2014). It assigns larger weights at to hidden states ht corresponding to positions where there is more evidence that the comment should be accepted or rejected. Yang et al. (2016) use a similar attention mechanism, but ours is deeper.", "startOffset": 8, "endOffset": 517}, {"referenceID": 47, "context": "Their method uses two GRU RNNs, both bidirectional (Schuster and Paliwal, 1997), one turning the word embeddings of each sentence to a sentence embedding, and one turning the sentence embeddings to a document embedding, which is", "startOffset": 51, "endOffset": 79}, {"referenceID": 16, "context": "We use Glorot initialization (Glorot and Bengio, 2010), crossentropy loss, and Adam (Kingma and Ba, 2015).", "startOffset": 29, "endOffset": 54}, {"referenceID": 26, "context": "We use Glorot initialization (Glorot and Bengio, 2010), crossentropy loss, and Adam (Kingma and Ba, 2015).", "startOffset": 84, "endOffset": 105}, {"referenceID": 46, "context": "For the Wikipedia datasets, they are initialized to GLOVE embeddings (Pennington et al., 2014).", "startOffset": 69, "endOffset": 94}, {"referenceID": 24, "context": "We describe the CNN only briefly, because it is very similar to that of of Kim (2014); see also Goldberg (2016) for an introduction to CNNs, and Zhang and Wallace (2015).", "startOffset": 75, "endOffset": 86}, {"referenceID": 17, "context": "We describe the CNN only briefly, because it is very similar to that of of Kim (2014); see also Goldberg (2016) for an introduction to CNNs, and Zhang and Wallace (2015).", "startOffset": 96, "endOffset": 112}, {"referenceID": 17, "context": "We describe the CNN only briefly, because it is very similar to that of of Kim (2014); see also Goldberg (2016) for an introduction to CNNs, and Zhang and Wallace (2015).", "startOffset": 96, "endOffset": 170}, {"referenceID": 21, "context": "pooled outputs) goes through a dropout layer (Hinton et al., 2012) (p = 0.", "startOffset": 45, "endOffset": 66}, {"referenceID": 54, "context": "Following Wulczyn et al. (2017), we report in Tables 2\u20133 AUC scores (area under ROC curve), along with Spearman correlations between system-generated probabilities P (accept|c) and human probabilistic gold labels (Section 2.", "startOffset": 10, "endOffset": 32}, {"referenceID": 52, "context": "6K comments (1K threads) from the Internet Argument Corpus (Walker et al., 2012; Abbott et al., 2016).", "startOffset": 59, "endOffset": 101}, {"referenceID": 0, "context": "6K comments (1K threads) from the Internet Argument Corpus (Walker et al., 2012; Abbott et al., 2016).", "startOffset": 59, "endOffset": 101}, {"referenceID": 28, "context": "Lee et al. (2014) discuss social filtering in detail and propose features (e.", "startOffset": 0, "endOffset": 18}, {"referenceID": 11, "context": "Diakopoulos (2015) dis-", "startOffset": 0, "endOffset": 19}, {"referenceID": 39, "context": "In further work, Napoles et al. (2017a) aimed to identify high quality threads.", "startOffset": 17, "endOffset": 40}, {"referenceID": 29, "context": "using DOC2VEC (Le and Mikolov, 2014).", "startOffset": 14, "endOffset": 36}, {"referenceID": 28, "context": "An ensemble of Conditional Random Fields (CRFs) (Lafferty et al., 2001) assigns labels (from their annotation scheme, e.", "startOffset": 48, "endOffset": 71}, {"referenceID": 27, "context": "An ensemble of Conditional Random Fields (CRFs) (Lafferty et al., 2001) assigns labels (from their annotation scheme, e.g., for sentiment, off-topic) to the comments of each thread, viewing each thread as a sequence of DOC2VEC embeddings. The decisions of the CRFs are then used to convert each thread to a feature vector (total count and mean marginal probability of each label in the thread), which is passed on to an LR classifier. Further improvements were observed when additional features were added, BOW counts and POS n-grams being the most important ones. Napoles et al. (2017a) also experimented with a CNN, similar to that of Section 3.", "startOffset": 49, "endOffset": 588}, {"referenceID": 13, "context": "Character n-grams were the best, on their own outperforming Djuric et al. (2015). The best results, however, were obtained using all features.", "startOffset": 60, "endOffset": 81}, {"referenceID": 13, "context": "Character n-grams were the best, on their own outperforming Djuric et al. (2015). The best results, however, were obtained using all features. By contrast, we use no handcrafted features and parsers, making our methods easily portable to other domains and languages. Wulczyn et al. (2017) experimented with character and word n-grams, based on the findings of", "startOffset": 60, "endOffset": 289}, {"referenceID": 8, "context": "(2017) experimented with the same dataset using LR, SVMs (Cortes and Vapnik, 1995), Random Forests (Ho, 1995), Gradient Boosted Decision Trees (GBDT) (Friedman, 2002), CNN (similar to that of Section 3.", "startOffset": 57, "endOffset": 82}, {"referenceID": 22, "context": "(2017) experimented with the same dataset using LR, SVMs (Cortes and Vapnik, 1995), Random Forests (Ho, 1995), Gradient Boosted Decision Trees (GBDT) (Friedman, 2002), CNN (similar to that of Section 3.", "startOffset": 99, "endOffset": 109}, {"referenceID": 15, "context": "(2017) experimented with the same dataset using LR, SVMs (Cortes and Vapnik, 1995), Random Forests (Ho, 1995), Gradient Boosted Decision Trees (GBDT) (Friedman, 2002), CNN (similar to that of Section 3.", "startOffset": 150, "endOffset": 166}, {"referenceID": 20, "context": "3), LSTM (Greff et al., 2015), FastText (Joulin et al.", "startOffset": 9, "endOffset": 29}, {"referenceID": 24, "context": ", 2015), FastText (Joulin et al., 2017).", "startOffset": 18, "endOffset": 39}, {"referenceID": 1, "context": "Badjatiya et al. (2017) experimented with the same dataset using LR, SVMs (Cortes and Vapnik, 1995), Random Forests (Ho, 1995), Gradient Boosted Decision Trees (GBDT) (Friedman, 2002), CNN (similar to that of Section 3.", "startOffset": 0, "endOffset": 24}, {"referenceID": 59, "context": "lowing Yarowsky (1994).", "startOffset": 7, "endOffset": 23}, {"referenceID": 5, "context": "Cheng et al. (2015) predict which users would be banned from on-line communities.", "startOffset": 0, "endOffset": 20}, {"referenceID": 52, "context": "5K utterances from the Internet Argument Corpus (Walker et al., 2012; Abbott et al., 2016) annotated with nastiness scores, and 9.", "startOffset": 48, "endOffset": 90}, {"referenceID": 0, "context": "5K utterances from the Internet Argument Corpus (Walker et al., 2012; Abbott et al., 2016) annotated with nastiness scores, and 9.", "startOffset": 48, "endOffset": 90}, {"referenceID": 0, "context": ", 2012; Abbott et al., 2016) annotated with nastiness scores, and 9.9K utterances from the same corpus annotated for sarcasm.18 In a bootstrapping manner, they manually identified cue words and phrases (indicative of nastiness or sarcasm), used the cue words to obtain training comments, and extracted patterns from the training comments. Xiang et al. (2012) also employed bootstrapping to identify users whose tweets fre-", "startOffset": 8, "endOffset": 359}, {"referenceID": 3, "context": "The classifiers used topical features, obtained via LDA (Blei et al., 2003), and a feature indicating the presence of at least one of approx.", "startOffset": 56, "endOffset": 75}, {"referenceID": 38, "context": "point out that unlike other abusive content, spam in comments or discussion fora (Mishne et al., 2005; Niu et al., 2007) is off-topic and serves a commercial purpose.", "startOffset": 81, "endOffset": 120}, {"referenceID": 42, "context": "point out that unlike other abusive content, spam in comments or discussion fora (Mishne et al., 2005; Niu et al., 2007) is off-topic and serves a commercial purpose.", "startOffset": 81, "endOffset": 120}, {"referenceID": 45, "context": "Sentiment features have been used by several methods, but sentiment analysis (Pang and Lee, 2008; Liu, 2015) is typically not directly concerned with abusive content.", "startOffset": 77, "endOffset": 108}, {"referenceID": 32, "context": "Sentiment features have been used by several methods, but sentiment analysis (Pang and Lee, 2008; Liu, 2015) is typically not directly concerned with abusive content.", "startOffset": 77, "endOffset": 108}, {"referenceID": 10, "context": "For sarcasm, see Davidov et al. (2010), Gonzalez-Ibanez et al.", "startOffset": 17, "endOffset": 39}, {"referenceID": 10, "context": "For sarcasm, see Davidov et al. (2010), Gonzalez-Ibanez et al. (2011), Joshi et al.", "startOffset": 17, "endOffset": 70}, {"referenceID": 10, "context": "For sarcasm, see Davidov et al. (2010), Gonzalez-Ibanez et al. (2011), Joshi et al. (2015), Oraby et al.", "startOffset": 17, "endOffset": 91}, {"referenceID": 10, "context": "For sarcasm, see Davidov et al. (2010), Gonzalez-Ibanez et al. (2011), Joshi et al. (2015), Oraby et al. (2016). Sentiment features have been used by several methods, but sentiment analysis (Pang and Lee, 2008; Liu, 2015) is typically not directly concerned with abusive content.", "startOffset": 17, "endOffset": 112}, {"referenceID": 8, "context": "(2011) and Dadvar et al. (2013) detect cyberbullying.", "startOffset": 11, "endOffset": 32}, {"referenceID": 4, "context": "Chandrinos et al. (2000) detect pornographic web pages, using a Naive Bayes classifier with text and image features.", "startOffset": 0, "endOffset": 25}, {"referenceID": 4, "context": "Chandrinos et al. (2000) detect pornographic web pages, using a Naive Bayes classifier with text and image features. Spertus (1997) flag flame messages in Web feedback forms, using decision trees and hand-crafted features.", "startOffset": 0, "endOffset": 132}, {"referenceID": 61, "context": "We also plan to explore character-level RNNs or CNNs (Zhang et al., 2015), for example to produce embeddings of unknown or obfuscated words from characters (dos Santos and Zadrozny, 2014; Ling et al.", "startOffset": 53, "endOffset": 73}, {"referenceID": 31, "context": ", 2015), for example to produce embeddings of unknown or obfuscated words from characters (dos Santos and Zadrozny, 2014; Ling et al., 2015).", "startOffset": 90, "endOffset": 140}], "year": 2017, "abstractText": "Experimenting with a new dataset of 1.6M user comments from a Greek news portal and existing datasets of English Wikipedia comments, we show that an RNN outperforms the previous state of the art in moderation. A deep, classification-specific attention mechanism improves further the overall performance of the RNN. We also compare against a CNN and a word-list baseline, considering both fully automatic and semi-automatic moderation.", "creator": "LaTeX with hyperref package"}}}