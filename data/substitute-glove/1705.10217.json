{"id": "1705.10217", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-May-2017", "title": "Black-box Testing of First-Order Logic Ontologies Using WordNet", "abstract": "A through - ground wish while Artificial Intelligence (AI) not attacking be enabling portable programs with commonsense relevance mechanisms machines to how about so winning. This paper offers giving new methods perspective towards the automation of misguided calculation also 1993 - order concepts (FOL) simputer. We formulate without new woman - window testing methodology though FOL SUMO - created ontologies by exploiting WordNet had instead parameters into SUMO. Our proposal featuring a method than one (australia -) automatic significant in a we partly but more determine and a methods on with automation supervision under specific operators theorem cafepress.com (ATPs ). Applying how evaluate senate, we are supposed not latter experts came) part suitability especially several translations has SUMO into FOL in 33) entire done of notable tool ATPs. In addition, say ones may give while intend same resulting this all tests according to examples quality consistent.", "histories": [["v1", "Mon, 29 May 2017 14:41:20 GMT  (46kb)", "http://arxiv.org/abs/1705.10217v1", "53 pages"]], "COMMENTS": "53 pages", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["javier \\'alvez", "paqui lucio", "german rigau"], "accepted": false, "id": "1705.10217"}, "pdf": {"name": "1705.10217.pdf", "metadata": {"source": "CRF", "title": "Black-box Testing of First-Order Logic Ontologies Using WordNet", "authors": ["Javier \u00c1lvez", "Paqui Lucio", "German Rigau"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n70 5.\n10 21\n7v 1\n[ cs\n.A I]\n2 9\nA long-standing dream of Artificial Intelligence (AI) has pursued to enrich computer programs with commonsense knowledge enabling machines to reason about our world. This paper offers a new practical insight towards the automation of commonsense reasoning with first-order logic (FOL) ontologies. We propose a new black-box testing methodology of FOL SUMO-based ontologies by exploiting WordNet and its mapping into SUMO. Our proposal includes a method for the (semi-)automatic creation of a very large set of tests and a procedure for its automated evaluation by using automated theorem provers (ATPs). Applying our testing proposal, we are able to successfully evaluate a) the competency of several translations of SUMO into FOL and b) the performance of various automated ATPs. In addition, we are also able to evaluate the resulting set of tests according to different quality criteria.\nKeywords: Black-box testing, Automated theorem proving, Knowledge representation"}, {"heading": "1. Introduction", "text": "Recently, Artificial Intelligence (AI) has shown great advances in many different research areas, but there is one critical area where progress has shown limited progress: commonsense representation and commonsense reasoning [23, 24, 7]. The work introduced in this paper proposes to advance a step forward in this research line by providing a new black-box testing methodology of first-order logic (FOL) SUMO-based ontologies by exploiting WordNet and its mapping into SUMO.\nFormal ontology development is a discipline whose goal is to derive explicit formal specifications of the terms in a domain and relations among\nPreprint submitted to Artificial Intelligence May 30, 2017\nthem [28, 16, 36, 2]. As other software artefacts, ontologies have to fulfil some previously specified requirements. Usually both the creation of ontologies and the verification of its requirements are manual tasks that require a significant amount of human effort. In the literature, there exist some methodologies that collect the experience in ontology development [14] and, more concretely, in ontology verification [12].\nRoughly speaking, the methodologies for validating functional requirements of ontologies are based on the use of competency questions (Cs) [17]. That is, according to the requirements of a given ontology, a set of goals that the ontology is expected to answer is defined for testing the ontology. In this sense, these methods can be classified as black-box testing [25] according to the classical definition in software engineering, since the definition of tests does not depend on the particular specification of knowledge proposed by the ontology. Black-box testing strategies have some disadvantages. For example, it is hard to determine the coverage level of a set of tests, since different black-box tests can repeatedly check the same portions of software. Further, the process of obtaining CQs is not automatic but creative [11]. Depending on the size and complexity of the ontology, creating a suitable set of CQs is by itself a very challenging and costly task.\nIn this paper, we propose a new method for the (semi-)automatic creation of CQs that enables to evaluate the competency of SUMO-based ontologies. Our proposal is based on several predefined question patterns that yield to a large set of CQs by using information from WordNet [9] and its mapping into SUMO [27]. A preliminary version of our method for the automatic creation of CQs has been already presented in [3], where we also proposed an adaptation of the methodology for the evaluation of ontologies introduced in [17] to be automatically applied using automated theorem provers (ATPs). For example, the synset schedule2\nv is related to schedule1 n by the semantic\nrelation result in WordNet, as described in Figure 1.1 In the same figure, we\n1We denote WordNet synsets and relations between chevrons (angle brackets). Each synset (set of synonyms) refers to a word sense using the following format: wordsp, where\nalso provide the mapping of schedule2 v and schedule1 n into SUMO, which are respectively connected to the meaning of Planning+ and Plan+. Using the above information, we obtain a new conjecture by stating the same fact in terms of SUMO: that is, \u201cPlan is result of a process of Planning\u201d. Indeed, we can propose two different conjectures (CQs) on the basis of the knowledge in Figure 1. In the first one, the statement is assumed to be true in the ontology:2\n(exists (?X ?Y) (1)\n(and\n($instance ?X Planning)\n($instance ?Y Plan)\n(result ?X ?Y)))\nIn the second one, which is obtained by the negation of (1), we assume that the statement is false: that is, that \u201cPlan is not result of any process of Planning\u201d. By proceeding in this way, we obtain around 7,500 pairs of CQs on the basis of the information of WordNet using additional WordNet relations and question patterns.\nThe contributions of this paper are manyfold. First, we present an evolved version of our methodology for the evaluation of FOL ontologies using ATPs. As introduced in [3], our proposal is an adaptation of the methodology described in [17] for the design and evaluation of ontologies. Second, we propose a novel method for the (semi-)automatic creation of CQs that relies on a small set of question patterns. The proposed set of CQs enables the evaluation of a) the competency of ontologies derived from SUMO, b) the mapping between WordNet and SUMO, c) the knowledge in WordNet, and d) ATPs and other tools for automated reasoning. To the best of our knowledge, our proposal is the first attempt to exploit the information in WordNet and its mapping into SUMO for the automatic evaluation of knowledge-based resources using FOL ATPs. Third, we summarize the results of an automatic evaluation of the competency of several translations of SUMO into first-order logic (FOL)\ns is the sense number and p is the part-of-speech (n for nouns, v for verbs and a for adjectives). In addition, we denote the mapping information of each synset into SUMO separated by colon (:). For this purpose, SUMO concepts are denoted between square brackets and the symbol + refers to the subsumption mapping relation.\n2Assuming that the knowledge in the ontology and WordNet is correct, and also that the mapping from WordNet to the ontology is correct, we consider that statement (1) is true according to our commonsense knowledge interpretation.\nand the performance of various FOL ATPs by means of the adapted evaluation method proposed in [3]. Fourth, we also report on the evaluation of the set of resulting CQs according to different quality criteria. On one hand, we automatically check its level of coverage with respect to the evaluated ontologies by parsing the proofs provided by ATPs. On the other hand, we perform a manual evaluation of a sample of the CQs and analyse in detail its results by considering the accuracy of proposed conjectures, the mapping information of the involved synsets and the knowledge in the ontology.\nOutline of the paper. In order to make the paper self-contained, in the next section we review the state-of-the-art in automatic evaluation of SUMObased ontologies using CQs. Our revision includes the existing translations of SUMO into FOL, the most successful FOL ATPs and the previously proposed CQs. In Section 3, we describe our methodology for the automatic evaluation of ontologies using ATPs. Next, in Section 4 we introduce our proposal for the (semi-)automatic creation of CQs by exploiting the knowledge in WordNet and its mapping into SUMO with the purpose of evaluating SUMO-based ontologies. The different question patterns proposed for the creation of CQs are described in Sections 5-8. Then, we report on our experimental evaluation of the competency of some FOL translations of SUMO, the performance of FOL ATPs and the quality of the proposed CQs in Section 9. Finally, we give some conclusions and discuss future work in Section 10."}, {"heading": "2. State of the art", "text": "In this section, we review the state-of-the-art in automatic evaluation of FOL ontologies. For this purpose, we focus on the description of the resources that have been proposed and used in the literature for the evaluation of SUMO-based ontologies using CQs. First, we introduce SUMO and its translations into FOL in the following subsection. Next, we describe the most successful state-of-the-art FOL ATPs in Subsection 2.2. Finally, we review the CQs that have been previously proposed for the evaluation of SUMO-based ontologies in Subsection 2.3."}, {"heading": "2.1. SUMO and its Transformations into FOL", "text": "SUMO3 [26] has its origins in the nineties, when a group of engineers from the IEEE Standard Upper Ontology Working Group pushed for a formal\n3http://www.ontologyportal.org\nontology standard. Their goal was to develop a standard upper ontology to promote data interoperability, information search and retrieval, automated inference and natural language processing.\nSUMO is expressed in SUO-KIF (Standard Upper Ontology Knowledge Interchange Format [29]), which is a dialect of KIF (Knowledge Interchange Format [13]). Both KIF and SUO-KIF can be used to write FOL formulas, but its syntax goes beyond FOL. Consequently, SUMO cannot be directly used by FOL ATPs without a suitable transformation [2].\nThe knowledge in SUMO is organized around the notions of object and class \u2014the main SUMO concepts\u2014 by means of the meta-predicates $instance and $subclass. SUMO objects and classes are not disjoint, since every SUMO class is defined to be instance of class and, thus, every SUMO class is also a SUMO object. Additionally, SUMO also differentiates relations and attributes. In particular, SUMO distinguishes between individual relation and attributes \u2014that is, instances of the SUMO classes Relation and Attribute respectively\u2014 and classes of relations and attributes \u2014that is, subclasses of the SUMO classes Relation and Attribute respectively\u2014. SUMO provides specific predicates for dealing with relations and attributes. Some of the most important ones are the next ones:\n\u2022 subrelation, which relates two individual SUMO relations (that is, two instances of the SUMO class Relation).\n\u2022 subAttribute, which relates two individual SUMO attributes (that is, two instances of the SUMO class Attribute).\n\u2022 holdsk, which relates an individual SUMO relation (that is, an instance of the SUMO class Relation) with a k-tuple of SUMO concepts.\n\u2022 attribute, which relates a SUMO object with an individual SUMO attribute (that is, an instance of the SUMO class Attribute).\nFor simplicity, from now on we denote the nature of SUMO concepts by adding as subscript the symbols o (SUMO objects that are neither classes nor individual relations nor individual attributes), c (SUMO classes that are neither classes of relations nor classes of attributes), r (individual SUMO relations), a (individual SUMO attributes), R (classes of SUMO relations) and A (classes of SUMO attributes). For example: YearDurationo, Artifactc, customerr, HotTemperaturea, TranstiveRelationR and BreakabilityAttributeA.\nThere exist different proposals for converting large portions of SUMO into a FOL ontology. In [31], the authors report some preliminary experimental results evaluating the query timeout for different options when translating SUMO into FOL. Evolved versions of the translation described in [31] can be found in the Thousands of Problems for Theorem Provers (TPTP) problem library4 [37] (hereinafter TPTP-SUMO), but have been not longer maintained since TPTP problem library version v5.3.0 (current TPTP version is v6.4.0). Following the line of [18], in [2] we use ATPs for reengineering around 88% of SUMO, obtaining Adimen-SUMO (v2.2). Both TPTP-SUMO and Adimen-SUMO inherits information from the top and the middle levels of SUMO (from now on, the core of SUMO), thus not considering the information from the domain ontologies.\nIn Table 1, we provide some figures comparing the explicit content of SUMO, TPTP-SUMO and Adimen-SUMO. In particular, the number of objects, classes, relations (both individual relations and classes of relations) and attributes (both individual attributes and classes of attributes) that are explicitly defined. The most significant difference between TPTP-SUMO and Adimen-SUMO is the number of explicitly defined objects, which is due to the fact that during the FOL transformation many objects that are implicitly defined in SUMO are explicitly introduced in TPTP-SUMO. On the contrary, the translation from SUMO into Adimen-SUMO is based on a small set of axioms, which provide the axiomatization of SUMO meta-predicates. Besides $instancer and $subclassr for the definition of objects and classes, some of these meta-predicates are $disjointr and $partitionr. The axiomatization of these meta-predicates, which is essential for the transformation of SUMO knowledge into FOL formulas, cannot be directly inherited from SUMO (see\n4http://www.tptp.org\n[2]). The transformation also adds new axioms for a suitable characterization of SUMO types, variable-arity relations and $holdsk\nr predicates, which\nsimulate the use of variable-predicates in FOL formulas. We are continuously evolving and improving Adimen-SUMO by solving some of the defects presented in SUMO. As result of this process, we have corrected more than 100 defective axioms in the current version of Adimen-SUMO (v2.6).\nWith respect to higher-order aspects of SUMO, an additional translation is required for enabling the use of SUMO by means of pure higher-order theorem provers [30]."}, {"heading": "2.2. FOL Automated Theorems Provers", "text": "The automatic application of methodologies based on CQs requires the use of ATPs. State-of-the-art ATPs for FOL are highly sophisticated systems that have been proved to provide advanced reasoning support to expressive ontologies. Since 1993, many researchers have used the Thousands of Problems for Theorem Provers (TPTP) problem library as an appropriate and convenient basis for ATP system evaluation [37], which becomes the de facto standard set of test problems for classical FOL ATP systems. The performance of ATP systems is evaluated every year in the CADE ATP System Competition (CASC) [32, 38] in the context of a set of problems chosen from the TPTP problem library and applying a specified time limit for each individual problem. Among the systems that have ever participated in CASC, we have selected the ones that are of special interest for reasoning with FOL ontologies, which are Vampire [33], E [35] and VanHelsing [20]. Next, we describe those systems and justify our selection.\nOn one hand, we have selected two of the most successful ATP systems in the CASC competition. The first one is Vampire [33], an ATP system for first-order classical logic which has been the winner of the FOF5 and LTB6 divisions in CASC during several years. Vampire implements the calculi of ordered binary resolution and superposition for handling equality, and it also implements the Inst-gen calculus. Vampire uses various standard redundancy criteria and implements several simplification techniques for pruning the search space, such as subsumption, tautology deletion, subsumption resolution and rewriting by ordered unit equalities. The reduction ordering is the\n5First-Order Form non-propositional theorems (axioms with a provable conjecture). 6First-order form theorems from Large Theories, presented in Batches.\nKnuth-Bendix Ordering. Since 2012, four different versions of Vampire have participated in CASC: v2.6, v3.0, v4.0 and v4.1. Vampire v2.6 is the CASCJ6 (2012), CASC-24 (2013) and CASC-J7 (2014) FOF division winner, and also the CASC-J6 (2012) LTB division winner. Vampire v3.0 obtained the 2nd place in the CASC-24 (2013) FOF division, but performing faster than the winner (Vampire v2.6), and has been used for the experimentation reported in [3]. Vampire v4.0 is the CASC-25 (2015) and CASC-J8 (2016) FOF and LTB divisions winner. In addition, Vampire v4.0 is also the CASC-25 FNT7 and EPR8 divisions winner. Finally, Vampire v4.1 is the CASC-J8 (2016) FNT and TFT9 divisions winner, and also achieved the 2nd place in the CASC-J8 (2016) FOF and LTB divisions.\nThe second system that we have selected is E [35], a theorem prover for full FOL with equality which consists of a (optional) clausifier for pre-processing full first-order formulae into clausal form, and a saturation algorithm implementing an instance of the superposition calculus with negative literal selection and a number of redundancy elimination techniques. Among other awards, E has been one of the top three ATP systems in the FOF division of CASC since 2012. E has also been used as a subcomponent by some other competitors in CASC. For its evaluation, we use E v1.9, which is the last version available at http://www.eprover.org.10\nOn the other hand, we have selected an ATP system that has only participated once in CASC: VanHelsing [20], which obtained the 4th position in CASC-J7 (2014) FOF division.11 This last ATP system is a fully automated proof checker for a subset of first-order problems tailored to a class of problems that arise in compiler verification. VanHelsing accepts input problems formulated in a subset of the TPTP language and is optimized to efficiently solve expression equivalence problems formulated in FOL. It is worth to mention that VanHelsing accepts all the axioms of TPTP-SUMO and Adimen-SUMO. An interesting feature of VanHelsing is that it provides graphical debugging help which makes the visualization of problems and localization of failed proofs much easier. This feature could be very useful for the debugging and maintenance of Adimen-SUMO, its mapping from Word-\n7First-order form non-propositional Non-Theorems. 8Effectively PRopositional clause normal form theorems and non-theorems. 9Typed First-order Theorems.\n10Although E v2.0 has participated in CASC-J8 (2016). 11VanHelsing v1.0 can be downloaded from https://github.com/VanHElsing/VanHElsing.\nNet and its linking with other information resources."}, {"heading": "2.3. Available Competency Questions for SUMO", "text": "In this subsection, we review the CQs that have been proposed in the literature for the evaluation of SUMO-based ontologies. We classify those CQs into 2 sets, depending on the nature of its creation method.\nOn one hand, the first set consists of only 64 CQs that have been manually created (creative CQs). This set includes the 33 CQs belonging to the Commonsense Reasoning (CSR) domain of the TPTP problem library that are based on SUMO. For example, the next conjecture belonging to the CSR domain of the TPTP problem library\n(forall (?ORG1 ?ORG2 ?ORG3) (2)\n(=>\n(and\n(mother ?ORG1 ?ORG2)\n(sibling ?ORG1 ?ORG3))\n(mother ?ORG3 ?ORG2))\nstates that \u201cSiblings have the same mother\u201d as follows: the mother of an organism ?ORG3 is ?ORG2 whenever ?ORG2 is mother of some other organism ?ORG1 such that ?ORG1 and ?ORG3 are sibling. In the past, the CSR domain was part of the set of eligible problems for the LTB division in CASC, but is not currently used. In addition, we have proposed 5 creative CQs in [2] and 26 creative CQs in [3]. For example, the conjectures \u201cPlants do not suffer from headache\u201d [2] and \u201cHerbivores eat animals\u201d [3]:\n(=> (3)\n(attribute ?OBJ Headache)\n(not\n($instance ?OBJ Plant)))\n(exists (?HERBIVORE ?ANIMAL ?EATING) (4)\n(and\n($instance ?HERBIVORE Herbivore)\n($instance ?ANIMAL Animal)\n($instance ?EATING Eating)\n(agent ?EATING ?HERBIVORE)\n(patient ?EATING ?ANIMAL)))\nObviously, conjecture (3) is assumed to be true and conjecture (4) is assumed to be false according to commonsense knowledge.\nOn the other hand, the second set consists of the CQs that have been obtained by following a (semi-)automatized process (automatically generated CQs). To the best of our knowledge, this set exclusively consists of the 7,112 CQs proposed in [3], where we introduced a preliminary version of the method described in this paper for the exploitation of WordNet and its mapping into SUMO. Among other restrictions, we focused on synsets connected to SUMO classes, thus discarding many mapping information. The resulting set of CQs have been used for the automatic evaluation of ATP systems reported in [4]. We provide more details about this preliminary version of our proposal in Section 4."}, {"heading": "3. Automatic Evaluation of FOL Ontologies using CQs", "text": "In this section, we summarize our adaptation of the methodology for the design and evaluation of ontologies introduced in [17] to be automatically applied using state-of-the-art ATPs, as initially proposed in [3].\nIn [17], the authors propose to evaluate the expressiveness of an ontology by proving completeness theorems w.r.t. a set of CQs. The proof of completeness theorems requires to check whether a given CQ is entailed by the ontology or not: that is, given an ontology \u03a6 and a conjecture \u03c6, we have to decide if \u03a6 |= \u03c6. For this purpose, in [3] we propose to use ATPs like Vampire [33], E [35] or VanHelsing [20] that work by refutation12 within some given execution-time and memory limits. Theoretically, if the conjecture is entailed by the ontology, then ATPs will eventually find a refutation given enough time (and space). However, theorem proving in FOL is a very hard problem, so it is not reasonable to expect ATPs to find a proof for every entailed conjecture [19]. Thus, if ATPs are able to find a proof for a conjecture \u03c6 in an ontology \u03a6, then we know for sure that the corresponding CQ is entailed by \u03a6: that is, \u03a6 |= \u03c6. On the contrary, if ATPs cannot find a proof, we do not know if (a) the conjecture is not entailed by the ontology (\u03a6 6|=? \u03c6) or (b) although the conjecture is entailed, ATPs have not been able to find the proof within the provided execution-time and memory limits (\u03a6 |=? \u03c6).\n12The proof that a conjecture is entailed by an ontology consists in demonstrating that the formula resulting from the conjunction of the ontology and the negation of the conjecture is unsatisfiable.\nDue to the semi-decidability problem of FOL, increasing the execution-time and memory limits is not a solution for conjectures that are not entailed. For the same reason, using other systems that do not work by refutation (for example, by model generation) is not a general solution.\nFurther, we also propose to divide the set of CQs into two classes: truthtests and falsity-tests, depending on whether we expect the conjecture to be entailed by the ontology or not. An example of truth-test is conjecture (2) \u2014\u201cSiblings have the same mother\u201d\u2014, which belongs to the CSR domain of the TPTP problem library, because it is expected to be entailed. On the contrary, conjecture (4) \u2014\u201cHerbivores eat animals\u201d\u2014, which belongs to the set of CQs proposed in [3], is a falsity-test since it is not expected to be entailed by the ontology.\nIn order to overcome the problem of deciding whether CQs are entailed or not by the ontology using ATPs that work by refutation, we propose to classify CQs as either (i) passing, (ii) non-passing or (iii) unknown using the following criteria:\n\u2022 If ATPs find a proof, then truth-tests are classified as passing since the corresponding conjectures are expected to be entailed, while falsitytests are classified as non-passing, because the corresponding conjectures are expected not to be entailed. For example, ATPs easily prove that conjecture (2) is entailed by Adimen-SUMO v2.6, thus the truthtest is classified as passing.\n\u2022 Otherwise, if no proof is found, then we classify both truth- and falsitytests as unknown because we do not know whether the corresponding conjectures are entailed or not. For example, conjecture (4) is classified as unknown according to Adimen-SUMO v2.6.\nAs discussed for the example in Figure 1, truth- and falsity-tests can be interpreted as complementary conjectures. That is, given a truth-test \u03c6, one can propose its negation \u00ac\u03c6 as falsity-test, and vice versa. For example, the following truth-test \u2014\u201cHerbivores do not eat animals\u201d\u2014 is obtained by the negation of (4):\n(forall (?HERBIVORE ?ANIMAL ?EATING) (5)\n(=>\n(and\n($instance ?HERBIVORE Herbivore)\n($instance ?ANIMAL Animal)\n($instance ?EATING Eating))\n(not\n(and\n(agent ?EATING ?HERBIVORE)\n(patient ?EATING ?ANIMAL)))))\nConjecture (5) is classified as passing according to Adimen-SUMO v2.6. In the same way, we obtain a new falsity-test by negating conjecture (2). Hence, in general we can assume that any set of CQs that is used for the evaluation of FOL ontologies consists in complementary truth- and falsity-tests. Further, from now on we consider a truth-test \u03c6 and its negative counterpart \u00ac\u03c6 as a single problem consisting of two conjectures. For the sake of simplicity, we denote each problem by its truth-test. Thus, the truth-test of a problem \u03c6 is \u03c6 itself, and the falsity test of a problem \u03c6 is \u00ac\u03c6.\nIn Table 2, we describe the evaluation of a FOL ontology \u03a6 on the basis of a set of problems using ATPs. For each problem, we distinguish four cases. In the first cases, a problem \u03c6 is decided to be solved because ATPs find a proof for either its truth-test \u03c6 or its falsity-test \u00ac\u03c6. If ATPs are able to prove \u03a6 |= \u03c6, then we know that the knowledge in \u03c6 is already included in the ontology and, consequently, we say that the problem \u03c6 is entailed by the ontology \u03a6. Otherwise, when ATPs prove \u03a6 |= \u00ac\u03c6, this reveals the existence\nof a defect in the ontology since we assume that \u03c6 is true. Therefore, we say that the problem \u03c6 is incompatible with the ontology. In the last two cases, the problem \u03c6 remains unsolved. On one hand, if \u03a6 is inconsistent then ATPs find a proof for its truth- and falsity-test, which are respectively classified as passing and non-passing. Since falsity-tests are obtained by the negation of truth-tests and a consistent formula cannot entail a formula and its negation, then we know for sure that \u03a6 is inconsistent in this case. On the other hand, both the truth- and the falsity-test of a problem \u03c6 are classified as unknown because ATPs do not find any proof before running out of resources. Hence, we have no information for the evaluation of \u03a6 according to the problem \u03c6 and, more concretely, we do not know whether:\n\u2022 \u03c6 is new knowledge that could be included in \u03a6 for improving the knowledge in the ontology.\n\u2022 \u03c6 is either redundant \u2014that is, \u03a6 already entails \u03c6\u2014 or incompatible with \u03a6 \u2014that is, \u03a6 |= \u00ac\u03c6\u2014, since ATPs cannot find a proof within the given resources of time and memory."}, {"heading": "4. Automatic Creation of CQs Using WordNet", "text": "In this section, we introduce our proposal for the creation of problems by exploiting WordNet and its mapping into SUMO, as introduced with the example in Figure 1. Our proposal is a substantially evolved version of the method presented in [3]. Among other improvements, we now make use of the different mapping relation between WordNet and SUMO, that were equally treated in [3], and we are now able to exploit additional WordNet information. In addition, we have also improved the process of obtaining a mapping between WordNet and the core of SUMO. As a consequence, the set of CQs introduced in this work \u2014which is different from the one introduced in [3]\u2014 enables a more fruitful exploitation of the knowledge in WordNet and its mapping into SUMO. As far as we know, our proposals are the first attempts to exploit WordNet for the evaluation of SUMO and, in general, for the evaluation of knowledge-based resources of this kind. In the next subsections, we first focus on the description of the knowledge and the hypothesis that are the basis of our proposal (Subsection 4.1). Then, we describe the method for obtaining a mapping from WordNet into Adimen-SUMO in Subsection 4.2. Finally, we introduce the method for the translation of WordNet knowledge into Adimen-SUMO statements in Subsection 4.3."}, {"heading": "4.1. Exploiting WordNet and its Mapping into SUMO", "text": "WordNet [9] is a large lexical database where nouns, verbs, adjectives and adverbs are grouped into sets of synonyms (synsets), each expressing a distinct concept. Although superficially resembling a thesaurus, WordNet interlinks not just word forms but specific senses of words. Thus, the main relation in WordNet is synonymy, but synsets are interlinked by means of many conceptual-semantic and lexical relations. For example, the supersubordinate relations hyperonymy and hyponymy. We use some of those relations in WordNet as source for the creation of SUMO problems. More concretely:\n\u2022 Morphosemantic Links [10], which are semantic relations between morphologically related verbs and nouns provided in the morphosemantic database.13 From the 14 proposed semantic relations, we use agent, instrument, result and event. The first three ones relate a process (verb) with its corresponding agent/instrument/result (noun), while event relates nouns and verbs referring to the same process. For example, the synsets patent1v and patentee 1 n are related by agent, cool 1 v and cooler 1 n\nare related by instrument, schedule2 v and schedule1 n are related by result (see Figure 1), and the synsets kill10v and killing 2 n are related by event.\n\u2022 antonymy and similarity relations, which are used to organize adjectives as follows: antonymy connects pairs of adjectives with opposite semantics, and each of these adjectives in turn is linked to semantically\n13Available at http://wordnetcode.princeton.edu/standoff-files/morphosemantic-links.xls.\ncomparable adjectives \u2014called satellites\u2014 by similarity. For example, the adjectives hot1\na and cold1 a are related by antonymy, and the adjec-\ntives blistering2s, warming 2 s, torrid 3 s, heated 1 s and tropical 4 s are satellite of hot1 a (see Figure 2). In addition, antonymy is inherited by similarity, which enables to extend the set of pairs of adjectives related by antonymy. In the above example, each satellite of hot1a (resp. cold 1 a) is antonym of cold1 a (resp. hot1 a ) and, further, is also antonym of each satellite of cold1a (resp. hot 1\na), obtaining in this way a set of 36 antonym-pairs from the information in Figure 2. In addition, antonymy also relates nouns or verbs with opposite semantics. For example, natural object1\nn\nand artifact1n are related by the semantic relation antonymy.\nIn the future, we plan to exploit additional relations and knowledge provided by WordNet for the creation of CQs.\nWordNet is linked with SUMO by means of the mapping described in [27]. This mapping connects synsets of WordNet to terms of SUMO using three relations: equivalence, subsumption and instance.14 equivalence denotes that the related WordNet synset and SUMO concept are equivalent in meaning, whereas subsumption and instance indicate that the WordNet synset is subsumed by the SUMO concept or is an instance of the SUMO concept respectively. Additionally, the mapping also uses the complementaries of equivalence and instance. We denote mapping relations by concatenating the symbols \u2018=\u2019 (equivalence), \u2018+\u2019 (subsumption), \u2018@\u2019 (instance), \u2018=\u0302\u2019 (complementary of equivalence) and \u2018+\u0302\u2019 (complementary of subsumption) to the corresponding SUMO concept. For example, the synsets horse1n, education 4 n, zero 1 a, natural object1 n and dark1 a are connected to Horsec=, EducationalProcessc+, Integerc@, Artifactc=\u0302 and RadiatingLightc+\u0302 respectively. WordNet v3.0 consists of 117,659 synsets: 82,115 nouns, 13,767 verbs, 18,156 adjectives and 3,621 adverbs. From the 82,115 noun synsets, 576 synsets are connected to more than one SUMO concept. Furthermore, 1 noun synset, 1,560 adjective synsets and 179 adverb synsets are not connected to any SUMO concept. All the remaining synsets are connected to a single SUMO concept.\nThe above introduced semantic knowledge of WordNet and its SUMO mapping are exploited for the construction of CQs. Our proposal is based on\n14Note that instance denotes the relation that is used in the mapping between WordNet and SUMO (for example, in Integer@), while $instancer denotes the meta-predicate that is used in the axiomatization of SUMO.\nthe hypothesis that both WordNet statements and the mapping information are correct. Under this assumption, we propose different question patterns with two different purposes: our first purpose is to validate the mapping itself and the second purpose is the validation of the knowledge in the ontology according to the knowledge in WordNet. For the validation of the mapping information, we propose the following two problem categories:\n\u2022 Multiple mapping pattern. This category of problems focuses on synsets that are connected to multiple SUMO concepts. Assuming that the mapping is correct, the truth-tests of the proposed problems state that the SUMO concepts connected to the same synset are compatible. Hence, its negations (falsity-tests) state that those SUMO concepts are not compatible, which implies that the mapping is necessarily wrong. In Section 5, we describe the single question pattern from which we obtain the problems belonging to this category.\n\u2022 Event patterns. Verbs and nouns referring to the same process are related by event. Being the same process, we consider that both synsets should be mapped into the same SUMO concept and, if not, our hypothesis is that the mapping information is compatible. Following this hypothesis, for each pair of verb and noun related by event and connected to different SUMO concepts, we propose a new problem such that its truth-test states that those SUMO concepts are compatible (truth-test): that is, that the mapping is not necessarily wrong. Thus, the corresponding falsity-tests state that SUMO concepts connected to verbs and nouns related by event are not compatible and, thus, that the mapping is wrong. This category is divided into 3 subcategories, depending on the mapping relations that are used in event pairs. In Section 6, we describe in detail the different question patterns and provide some examples.\nIn the case of problems proposed for the validation of the knowledge in the ontology, for each WordNet statement we create a problem such that its truth-test states the same affirmation in terms of SUMO. Next, we describe the two main categories of problems with this purpose:\n\u2022 Antonym patterns. In this category, problems are obtained from question patterns based on antonymy as follows: since antonymy relates adjectives with opposite semantics in WordNet, for each pair of antonym\nadjectives we create a new problem such that its truth-test states that the SUMO concepts related to those adjectives are not compatible. Consequently, the corresponding falsity-tests state that the SUMO concepts related to antonym adjectives are compatible. Again, we propose 3 different subcategories depending on the mapping relations that are used in the pairs of antonym adjectives. This category is described in Section 7.\n\u2022 Process patterns. This category consists in question patterns that focus on verbs and nouns related by agent, instrument and result, and the truth-tests of the proposed problems state the same relation in terms of SUMO. For example, conjecture (1) states that schedule2v and schedule1\nn are related by resultr in terms of SUMO. The correspond-\ning falsity-tests state that the SUMO concepts connected to synsets in agent/instrument/result pairs of verbs and nouns are not related in the same form. We propose a subcategory of problems for each relation and, in addition, a different question pattern for each possible combination of mapping relations. We provide a complete description of this category of problems in Section 8."}, {"heading": "4.2. Obtaining a mapping between WordNet and the core of SUMO", "text": "The mapping between WordNet and SUMO uses terms from the core \u2014top and middle levels\u2014 of SUMO, but also from the domain ontologies. However, both TPTP-SUMO and Adimen-SUMO only use axioms from the core of SUMO.\nA full mapping between WordNet and the core of SUMO is obtained by means of the structural relations of SUMO: $instancer, $subclassr, subrelationr and subAttributer. Since $subclassr, subrelationr and subAttributer are transitive and, additionally, the relations $instancer, subrelationr and subAttributer are inherited through $subclassr, it is not difficult to obtain the super-concepts of each SUMO concept. By proceeding in this way, for each SUMO concept that is not defined in the core of SUMO we have obtained its set of mostspecific super-concepts that are defined in the core of SUMO. If a SUMO concept is already defined in the core of SUMO, then its set of most-specific SUMO concepts defined in the core of SUMO exclusively consists of itself. Additionally, we have manually corrected some minor errors and typos affecting to 293 SUMO concepts. To sum up, 24,906 SUMO concepts not defined in the core of SUMO are used in the WordNet-SUMO mapping, from which\n14,472 concepts are related with several (more than one) super-concepts belonging to the core of SUMO, whereas 10,434 concepts are related with a single super-concept.\nUsing the above described sets of most-specific super-concepts, we obtain the mapping between each synset ws of WordNet and the core of SUMO as follows: if ws is already mapped into a concept in the core of SUMO, we simply keep the current mapping of ws; otherwise, if ws is connected to a concept C that is not defined in the core of SUMO, then we map ws to its set of most-specific super-concepts of C in the core of SUMO. Additionally, in the latter case, the equivalence mapping relation is replaced with subsumption, since the super-concepts of C are more general than C. For example, the synset frying1n is connected to Fryingc=, which belongs to the domain ontology Food. In the same domain ontology, Fryingc is defined to be subclass of Cookingc, which is defined in the top level of SUMO. That is, Fryingc is not defined in the core of SUMO, but Cookingc is. Thus, we decide to connect frying1\nn to Cookingc in the mapping from WordNet to the core\nof SUMO. However, instead of equivalence, we connect frying1n to Cookingc using the subsumption mapping relation: that is, Cookingc+ (see Figure 3). It is worth to note that the complementaries of relations equivalence and subsumption are only used with concepts belonging to the core of SUMO in the WordNet-SUMO mapping.\nAs result of the above process, we obtain a mapping between all the synsets of WordNet and the core of SUMO except for 822 nouns, 24 verbs, 3,634 adjectives and 260 adverbs. In addition to the synsets that are not connected to any concept, this process also reveals the existence of synsets connected to concepts that were defined in older versions of SUMO but that are not longer available in the current one. For example, the synsets salmon1\nn and\narchitect2n are respectively connected to Salmonc= and Architectc=, which do not appear in the latest versions of SUMO. In total, 113 concepts that are\nused in the WordNet-SUMO mapping are not currently defined in the ontology. In order to obtain a whole mapping into the core of SUMO, all the synsets without a suitable mapping (around 4,700 synsets) are connected to the SUMO top-concept Entityc using subsumption: that is, Entityc+. In the resulting mapping, 1,104 noun synsets and 2 verb synsets are connected to multiple SUMO concepts \u2014the mapping of those synsets is used in the Multiple mapping category for the creation of CQs (see Section 5)\u2014, whereas all the remaining ones are connected to a single concept."}, {"heading": "4.3. Translating the mapping information into the language of SUMO", "text": "In order to use the WordNet-SUMO mapping for obtaining CQs, we have to characterize the mapping information using statements in the language of SUMO.\nAs described in Subsection 4.2, each WordNet synset is connect to SUMO concepts using equivalence, subsumption (or its complementaries) and instance. For example, the synsets horse1n, pony 1 n and Secretariat 2 n are respectively connected to Horsec=, Horsec+ and Horsec@. Thus, in a literal (or strict) interpretation of the WordNet-SUMO mapping, horse1\nn is exactly\nequivalent to the SUMO concept Horsec, while pony 1 n is subsumed by Horsec and Secretariat2 n is instance of Horsec. In order to translate the above interpretation of the mapping information into statements in the language of SUMO, we can simply use equality in the case of the synset horse1\nn . With\nrespect to the last two synsets, we can use the meta-predicates $subclassr and $instancer respectively. Likewise, since male horse 1 n is connected to both Malea+ and Horsec+, we have that male horse 1 n is subsumed by both Malea and Horsec. Hence, by following the same literal interpretation of the mapping information, male horse1\nn should be translated as both subclass of\nHorsec \u2014by means of $subclassr\u2014 and subattribute of Malea \u2014by means of subAttributer. However, this literal interpretation of the mapping information would lead to inconsistent SUMO statements: on one hand, subAttributer relates two individual SUMO attributes, which are therefore restricted to be instance of Attributec; on the other hand, $subclassr relates two SUMO classes, which are defined to be instance of classc. Since the SUMO classes Attributec and classc are disjoint, it is inconsistent to state that any SUMO concept is both subclass of Horsec and subattribute of Malea.\nUnlike its literal interpretation, one can propose several suitable translations of the mapping information that do not yield to inconsistent SUMO statements. Among the existing options, in this work we use two different\ntranslations of the mapping information on the basis of the following criteria. First, our main purpose is to exploit as much information as possible, in particular for obtaining the maximum amount of problems. Second, our intention is also to propose the strongest possible candidate truth-tests. It is worth to note that the above two criteria are sometimes opposite, so we need to find a trade-off between them.\nNext, we introduce two different proposals for the translation of the mapping information into SUMO statements, where the second proposal produces stronger statements than the first one. The purpose of our first proposal is to relate WordNet synsets with a set of SUMO objects, while the purpose of the second one is to relate WordNet synsets with SUMO classes. For these purposes, we consider the nature of the SUMO concept to which a synset is connected in order to choose the most suitable SUMO predicate: either equalr, $instancer, $subclassr or attributer. 15\nFirst proposal. In order to restrict the set of single SUMO objects that can be related with a given synset, we make use of a lenient interpretation of the WordNet-SUMO mapping. In the proposed SUMO statements, we use the predicate equalr with synsets connected to SUMO objects, the predicate $instancer with synsets connected to SUMO classes and $attributer with synsets connected to SUMO attributes. We use a different variable in the SUMO statement proposed for each individual synset. The quantification of the introduced variables is determined by question patterns and the mapping relation that is used for connecting the given synset (see Sections 5 and 7-8). Next, we formalize our proposal for the translation of the mapping information of synsets connected to a single SUMO concept:\n\u2022 If the given synset is connected to a SUMO object, then we simply use equality to state that the synset is exactly related with that SUMO object. For example, the synset yearlong1s is connected to the SUMO object YearDurationo, thus the statement\n(equal ?X YearDuration) (6)\n15In this work, we do not translate the mapping information of synsets connected to SUMO relations. This information should be translated using $holdskr . However, the arity of SUMO relations is greater than 1 and, consequently, $holdskr relates SUMO relations with tuples of 2 or more SUMO concepts. Therefore, it is not possible to determine which set of single SUMO concepts is related with a given synset by using $holdskr .\nis representing that the values of ?X related with yearlong1 s have to be equal to YearDurationo.\n\u2022 If the synset is connected to a SUMO class, then we use the SUMO predicate $instancer. For example, artifact 1 n is connected to the SUMO\nclass Artifactc, hence\n($instance ?X Artifact) (7)\nis stating that the values of ?X related with artifact1 n have to be instance\nof Artifactc.\n\u2022 If the given synset is connected to an individual SUMO attribute, we can stablish the properties of the SUMO objects related to that synset using the SUMO predicate attribute.16 For example, goddess1\nn is connected\nto Femalea as stated before, therefore the statement\n(attribute ?X Female) (8)\nis stating that the values of ?X related with goddess1 n have Femalea as property.\n\u2022 Finally, if the synset is connected to a class of SUMO attributes, then we have to conveniently combine the SUMO predicates attribute and $instance. For example, the synset breakableness1n is connected to BreakabilityAttributeA, which denotes a class of SUMO attributes. Hence, the statement\n(exists (?Z) (9)\n(and\n($instance ?Z BreakabilityAttribute)\n(attribute ?X ?Z))))\nis stating that the values of ?X related with breakableness1a have some instance of BreakabilityAttributeA as property.\nRegardless the nature of the SUMO concept to which a synset is connected, we negate the statements obtained for synsets connected using the\n16Due to the restrictions on arguments of predicates provided by SUMO domain axioms, we use property instead of attribute when convenient.\ncomplementary of the equivalence or the subsumption mapping relations. For example, the synset natural object1\nn is connected to Artifactc=\u0302. By proceed-\ning as described above, we would obtain statement (7). Hence, we negate statement (7) and obtain\n(not (10)\n($instance ?X Artifact))\nwhich states that the values of ?X related with natural object1 n cannot be instance of Artifactc. In addition, for the translation of the mapping information of synsets connected to more than one SUMO concept, we propose to conveniently combine the statements obtained for each single SUMO concept as stated before with conjunction. In this way, the mapping information of male horse1\nn , which is\nconnected to both Malea+ and Horsec+, is translated as follows:\n(and (11)\n(attribute ?X Male)\n($instance ?X Horse))\nSecond proposal. In this proposal for the translation of the mapping information, we obtain stronger statements by restricting the SUMO class \u2014instead of the SUMO object\u2014 that is related with a given synset. Thus, we exclusively consider those synsets connected to SUMO concepts which are classes and discard the remaining ones. In the proposed SUMO statements, we simply use the predicates equalr \u2014for synsets connected by equivalence\u2014 and $subclassr \u2014for synsets connected by subsumption or instance\u2014. Therefore, the mapping information of synsets connected by the complementary of equivalence or subsumption is also discarded by the moment.\nIn the next sections, we use the above proposed methods for the translation of the mapping information of synsets in order to obtain CQs according to different conceptual question patterns. By following our previously introduced criteria, we use the first proposal in Sections 5 and 7-8, while the second one is used in Section 6. In those sections, we also discuss on the differences of using each of the proposed translations of the mapping information."}, {"heading": "5. Multiple Mapping Pattern", "text": "In this section, we describe the problems that are obtained from synsets connected to several SUMO concepts for the validation of the mapping in-\nformation. For this purpose, we assume that both WordNet statements and the mapping information of synsets are correct. Under this assumption, from each synset connected to more than one SUMO concepts we propose a new problem such that its truth-test states that those SUMO concepts are compatible. Therefore, the corresponding falsity-tests state that the SUMO concepts connected to the same synset are not compatible, which contradicts our assumption. In both cases, we follow the first proposal for the translation of the mapping information described in Subsection 4.3. Our second proposal for the translation of the mapping information is not suitable since many synsets are connected to SUMO concepts which are not classes.\nAs described in Subsection 4.2, there are 1,106 synsets (1,104 nominal and 2 verbal) connected to more than one SUMO concepts as result of the process of obtaining a mapping from WordNet to the core of SUMO. Since equivalence is replaced with subsumption in that process, all the synsets are connected using subsumption or instance. Hence, in this category we propose a single question pattern for the creation of problems such that its truth-tests state that the SUMO concepts connected to a single synset are compatible. This simply implies to consider the variable used for the translation of the mapping information of synsets as existentially quantified.\nFor example, warhead1 n is connected to ExplosiveDevicec+ and Weaponc+ as described in Figure 4, from which we obtain the following truth-test that states that ExplosiveDevicec and Weaponc are compatible:\n(exists (?X) (12)\n(and\n($instance ?X ExplosiveDevice)\n($instance ?X Weapon)))\nThe corresponding falsity-test, which is obtained by negating (12), states that ExplosiveDevicec andWeaponc are not compatible. The mapping of warhead 1\nn\nis validated since ATPs are able to find a proof for (12) in Adimen-SUMO v2.6, but not in TPTP-SUMO and Adimen-SUMO v2.2. For example, ATPs are able to discover that Bombc is subclass of both ExplosiveDevicec and Weaponc, thus any instance of Bombc is also instance of ExplosiveDevicec and Weaponc simultaneously. Consequently, the proposed problem is decided to be solved and entailed in Adimen-SUMO v2.6, while it is unsolved in TPTPSUMO and Adimen-SUMO v2.2.\nSimilarly, coal1 n is connected to both FossilFuelc+, Mineralc+ and Rockc+ (see Figure 5). Hence, we create a new problem such that its truth-test states that FossilFuelc, Mineralc and Rockc are compatible:\n(exists (?X) (13)\n(and\n($instance ?X FossilFuel)\n($instance ?X Mineral)\n($instance ?X Rock)))\nATPs find a proof (as before, only in Adimen-SUMO v2.6) for the corresponding falsity-test, which is obtained by negating (13) and states that FossilFuelc, Mineralc and Rockc are not compatible: for example, ATPs are able to discover that every instance of FossilFuelc has Liquida as attribute 17 and every instance of Rockc has Solida as attribute, being Liquida and Solida contrary attributes. Consequently, this falsity-test enables to detect a defect in the mapping information of coal1n and the problem is decided to be solved and incompatible in Adimen-SUMO v2.6.\nBy proceeding in this way, we create 151 problems from the single question pattern proposed in this category.\n17Every instance of Solutionc, which is a super-class of FossilFuelc, has Liquida as attribute."}, {"heading": "6. Event Patterns", "text": "In this section, we describe the problems that are obtained from the question patterns based on the semantic relation event defined in the Morphosemantic Links database [10] of WordNet for the validation of the mapping information of synsets.\nFor this purpose, besides assuming that WordNet statements and the mapping information of synsets are correct, we also assume that WordNet synsets related by event should be connected to the same SUMO concept since event relates verb and noun synsets referring to the same process. Under those assumptions, for each verb and noun synsets related by event and connected to different SUMO concepts, we propose a new problem such that its truth-test states that the SUMO concepts linked to those synsets are compatible. Hence, the corresponding falsity-tests state that the SUMO concepts connected to verb and noun synsets related by event are not compatible, which contradicts our assumptions.\nIn theMorphosemantic Links database of WordNet, there are 8,158 eventpairs of synsets where the two synsets are equally mapped in 1,991 eventpairs. In addition, the synsets are connected to different SUMO concepts where at least one of them is not a SUMO class in only 499 event-pairs. Thus, we decide to apply our second proposal for the translation of the mapping information described in Subsection 4.3 in order to create problems on the basis of the remaining 5,668 event-pairs where the two synsets are connected to different SUMO classes. By proceeding in this way, we obtain stronger truth-tests than using our first proposal for the translation of the mapping information. In the next subsections, we introduce different conceptual patterns of questions depending on the used mapping relations."}, {"heading": "6.1. Event Pattern #1", "text": "The first question pattern is focused on the 26 event-pairs where both synsets are connected to two different SUMO classes using equivalence. Since the mapping of those synsets exactly denotes the SUMO class to which the synset is related, our question pattern states that those SUMO classes are completely equivalent by using equality.\nFor example, the synsets kill10v and killing 2 n are related by event and respectively connected to the SUMO classes Deathc= and Killingc=, as described in Figure 6, from which we obtain the next truth-test:\n(equal Death Killing) (14)\nThe corresponding falsity-test, which is obtained by negating (14), states that Deathc and Killingc are different. This falsity-test is classified as nonpassing only in Adimen-SUMO v2.6: the patient of Killingc is restricted to be instance of Humanc, while any instance of Organismc can be the patient of Deathc. Consequently, the proposed problem is decided to be solved and incompatible in Adimen-SUMO v2.6. It is worth to note that in order to state the equivalence of the classes Deathc and Killingc using our first proposal for the translation of the mapping information, we would have to state that the set of objects belonging to those classes are equal, which is a weaker affirmation than conjecture (14).\nUsing this first question pattern, we obtain 24 problems."}, {"heading": "6.2. Event Pattern #2", "text": "In this subsection, we describe the question pattern that focuses on the 509 event-pairs where one synset is connected using equivalence, while the other synset is connected using instance or subsumption.\nIn this case, we know the precise SUMO class to which the synset connected by equivalence is related, as in the previous subsection. However, for the synset connected by subsumption or instance, we only know the superclass of the SUMO class to which that synset is related. That is, we know that the synset is connected to some subclass of the class provided in the mapping information. Hence, in order to prove that those SUMO classes are compatible, we have to demonstrate that the class related to the synset connected by equivalence is subclass of the class related to the synset connected by subsumption or instance.\nFor example, fix1 v and fixing1 n are related by event and connected to Pretendingc+ and Repairingc= respectively, as described in Figure 7. Therefore, we create a new problem such that its truth-test states that Repairingc is subclass of Pretendingc\n($subclass Repairing Pretending)) (15)\nand the corresponding falsity-test states that Repairingc cannot be subclass of Pretendingc. Conjecture (15) and its negation are not proved to be entailed by TPTP-SUMO or Adimen-SUMO in our experimentation.\nFrom this second event pattern of questions, we obtain 350 problems."}, {"heading": "6.3. Event Pattern #3", "text": "Finally, we focus on the 5,130 event-pairs where both synsets are connected using instance or subsumption.\nIn this case, we only know the superclass of the SUMO class to which each synset is related. Therefore, in order to prove that those SUMO classes are compatible, we have to demonstrate that those SUMO classes have some subclass in common.\nFor example, appraise1v and appraisal 1 n are related by event and respectively connected to Judgingc+ and Comparingc+, as described in Figure 8.\nFrom this event pair, we create a new problem such that its truth-test states that Judgingc and Comparingc have some common subclasses:\n(exists (?X) (16)\n(and\n($subclass ?X Judging)\n($subclass ?X Comparing)))\nThus, the corresponding falsity-test states that Judgingc and Comparingc do not have any common subclass. Conjecture (16) and its negation are not proved to be entailed by TPTP-SUMO or Adimen-SUMO in our experimentation.\nUsing this third question pattern based on event, we obtain 2,011 different problems."}, {"heading": "7. Antonym Patterns", "text": "In this section, we describe the problems that are obtained from the question patterns based on antonyms for the validation of the knowledge in the ontology according to WordNet. For this purpose, we assume that both WordNet statements and its mapping into SUMO are correct. Under those assumptions, questions patterns focus on the antonymy\u2014which relates words with opposite semantics\u2014 and similarity \u2014that links semantically comparable words\u2014 relations of WordNet (see Figure 2) and propose to create new problems such that its truth-tests state that the SUMO objects related to antonym words are not compatible. Thus, the corresponding falsity-tests state that the SUMO objects related to antonym words are compatible.\nWordNet provides 7,604 antonym-pairs, from which 1,950 are noun-pairs, 1,016 are verb-pairs, 3,998 are adjective-pairs and 640 are adverb-pairs. In addition, given a synset ws in an antonym-pair that is related with other synset ws\u2032 via similarity, we can propose a new antonym-pair by simple replacing ws with ws\u2032 in the pair. By proceeding in this way, we extend the given 7,604 antonym-pairs to a set of 121,496 antonym-pairs. Since many of the synsets in those pairs are connected to SUMO concepts which are not classes, we use our first proposal for the translation of the mapping information described in Subsection 4.3. Further, in 36,934 antonym-pairs some of the two synsets are mapped into SUMO relations and, therefore, those pairs have not been considered. In the remaining 84,562 antonympairs of synsets, there are:\n\u2022 186 antonym-pairs where both synsets are connected using equivalence (or its complementary).\n\u2022 2,542 antonym-pairs where equivalence (or its complementary) is mixed with subsumption (or its complementary) or instance.\n\u2022 81,834 antonym-pairs where both synsets are connected using subsumption (or its complementary) and instance.\nIn the following subsections, we describe 3 different question patterns depending on the used mapping relations."}, {"heading": "7.1. Antonym Pattern #1", "text": "The first question pattern based on antonym is focused in the 186 antonympairs where both synsets are connected using equivalence (or its complementary). In this case, we assume that all the SUMO objects represented by the statement obtained from the first synset are incompatible with all the SUMO objects represented by the statement obtained from the second synset. Formally, this implies to consider the variables used in the SUMO statements proposed for the translation of the mapping information as universally quantified.\nFor example, the antonym-synsets birth2 n and death1 n are respectively connected to Birthc= and Deathc= (see Figure 9), from which we obtain the following statements:\n($instance ?X Birth) (17)\n($instance ?Y Death) (18)\nBy considering ?X and ?Y as universally quantified, the following truth-test results from the combination of statements (17) and (18):\n(forall (?X ?Y) (19)\n(=>\n(and\n($instance ?X Birth)\n($instance ?Y Death))\n(not\n(equal ?X ?Y))))\nThe above CQ states that any two SUMO objects that are instance of Birthc and Deathc respectively are necessarily different. The corresponding falsitytest is obtained by negating (19), which states that there exists some SUMO object which is instance of Birthc and Deathc at the same time.\nFrom this question pattern, we obtain 71 different problems."}, {"heading": "7.2. Antonym Pattern #2", "text": "The second question pattern is focused on the 2,542 antonym-pairs where equivalence (or its complementary) is mixed with subsumption (or its complementary) or instance. As in the previous case, we consider the variable in the SUMO statement proposed for the translation of equivalence mapping information as universally quantified. On the contrary, the variable in the SUMO statement translating subsumption or instance mapping information is considered as existentially quantified because the information provided by these mapping relations is weaker than the information provided by equivalence. Since we are using both universally and existentially quantified variables, there are two additional options: we may nest the universally quantified statement inside the formula obtained from the existentially quantified statement, or nest the existentially quantified statement inside the formula that is\nderived from the universally quantified statement. From these two options, we choose the one that yields stronger truth-tests, which is the first one. For example, the antonym synsets rural area1n and urban area 1 n are connected to GeographicAreac+ and Cityc= respectively (see Figure 10), from which we obtain the following statements:\n($instance ?X GeographicArea) (20)\n($instance ?Y City)) (21)\nConsequently, the SUMO statement that is obtained for the urban area1 n is nested into the SUMO statement that is obtained for rural area1 n :\n(exists (?X) (22)\n(and\n($instance ?X GeographicArea)\n(forall (?Y)\n(=>\n($instance ?Y City)\n(not\n(equal ?X ?Y))))))\nThe above CQ states that there exists some SUMO object which is instance of GeographicAreac such that it is different from any SUMO object that is instance of Cityc. It is worth to note that if the previous statement holds, it implies that every SUMO object that is instance of Cityc is different from some SUMO object that is instance of GeographicAreac: in particular, all the SUMO objects that are instance of Cityc would be different from a single SUMO object that is instance of GeographicAreac. Hence, the truth-test in (22) is stronger than the conjecture that results by nesting the existentially quantified statement into the formula obtained from the universally quantified statement. Although Cityc is subclass of GeographicAreac, the truth-test defined in (22) is classified as passing only in Adimen-SUMO v2.6 since GeographicAreac has other subclasses that are disjoint with Cityc: for example, WaterAreac. Therefore, the proposed problem is decided to be solved and entailed in Adimen-SUMO v2.6.\nTo sum up, we obtain 489 problems from this second question pattern based on antonymy."}, {"heading": "7.3. Antonym Pattern #3", "text": "In the third question pattern based on antonym, we focus on the 81,834 antonym-pairs where both synsets are connected using subsumption (or its\ncomplementary) and instance. As before, we consider the variables used in SUMO statements as existentially quantified, which implies to consider that some of the SUMO objects represented by the statements obtained from the mapping information of the antonym synsets are incompatible. For example, the antonym synsets stained1\na and unstained1 a are respectively connected to\nColoringc+ and SurfaceChangec+\u0302 (see Figure 11), from which we obtain the following statements:\n($instance ?X Coloring) (23)\n(not (24)\n($instance ?Y SurfaceChanging))\nTherefore, we propose the following truth-test\n(exists (?X ?Y) (25)\n(and\n($instance ?X Coloring)\n(not\n($instance ?Y SurfaceChanging))\n(not\n(equal ?X ?Y))))\nstating that there exist two different SUMO objects such that the first one is instance of Coloringc and the second one is not instance of SurfaceChangingc. The corresponding falsity-test that is obtained by negating (25) states that any two SUMO objects such that the first one is instance of of Coloringc and the second one is not instance of SurfaceChangingc are equal.\nUsing this third question pattern, we obtain 2,444 problems."}, {"heading": "8. Process Patterns", "text": "In this section, we describe the problems that are obtained from the Morphosemantic Links database [10] of WordNet for the validation of the\nknowledge in the ontology. As in the case of the question patterns based on antonym, we assume that both WordNet statements and its mapping into SUMO are correct.\nAmong the 14 semantics relations between morphologically related verbs and nouns provided by the Morphosemantic Links, we concentrate on agent, instrument and result, which relate a process (verb) with its corresponding agent/instrument/result (noun). For each pair of synsets connected by the above relations, we propose to create a new problem such that its truth-test states the same affirmation in terms of SUMO. For this purpose, we properly use the SUMO relations agentr, instrumentr and resultr that link SUMO processes (i.e., an instance of the SUMO class Process) to its corresponding agent, instrument and result, which are respectively restricted to be an instance of the SUMO classes Agentc, Physicalc and Entityc. That is, the SUMO relations agentr, instrumentr and resultr connect two SUMO objects. Consequently, it is not feasible to use our second proposal for the translation of the mapping information described in Subsection 4.3, since the connected concepts are not SUMO classes. Depending on the mapping relations that are used to relate the verb and noun synsets, we next introduce 4 different question patterns by means of our first proposal for the translation of the mapping information.\nIn the Morphosemantic Links database, there are 5.295 relation-pairs of synsets where some of the relations agent, instrument and result is used. Among those pairs, there are 5,098 relation-pairs such that none of the synsets are connected to a SUMO relation and, additionally, none of the synsets is connected using the complementary of equivalence or subsumption. Therefore, we use those 5,098 relation-pairs for the creation of problems.\nFor example, the synsets instruct1v and instructor 1 n are related by agent and respectively connected to EducationalProcessc= and Teachera= (see Figure 12). From the mapping information of those synsets, we obtain the following statements:\n($instance ?X EducationalProcess) (26)\n(attribute ?Y Teacher) (27)\nThus, we have to combine the above statements using the SUMO relation agentr and quantify its variables in order to create a problem. However, unlike in the case of event question patterns, we cannot consider both variables in SUMO statements as universally quantified when both synsets are connected by equivalence (see Subsection 6.1): in our example, it is not true that all the SUMO objects with Teachera as attribute are the agent of all the instances of EducationalProcessc. At most, we can state that all the instances of EducationalProcessc have a SUMO object with the attribute Teachera as agent and, at the same time, all the SUMO objects with Teachera as attribute are the agent of some instance of EducationalProcessc, as proposed in the next conjecture (truth-test):\n[ComposingMusicc+] : \u3008compose 2 v \u3009 \u3008composition 4 n\u3009 : [MusicalCompositionc=]\n[resultr ]?\n[X ]\n\u3008result\u3009\nNext, we summarize the proposed question patterns and the amount of problems that result from them. However, the resulting problems are organized into 3 categories \u2014Agent, Instrument and Result\u2014 depending on the semantic relation with the purpose of analysing the knowledge in SUMO about each of these relations:\n\u2022 The first question pattern focuses on relation-pairs where both synsets are connected by equivalence, as the example in Figure 12. From this\n[Permissiona+] : \u3008patent 1 v \u3009 \u3008patentee 1 n\u3009 : [LegalAgentc+]\n[X ] [Y ]\n\u3008agent\u3009\n[agentr ]?\nsynset have some of the SUMO objects that can be assigned to the noun synset as agent/instrument/result. From this question pattern, we obtain 1,618 problems, from which 663 problems belong to the Agent category, 287 problems to the Instrument category and 668 problems to the Result category.\nIn total, we obtain 829 problems for the Agent category, 348 problems for the Instrument category and 788 problems for the Result category."}, {"heading": "9. Experimentation", "text": "On the basis of the set of CQs proposed in the above sections, we have performed several experiments in order to evaluate the competency of SUMO based ontologies and the performance of FOL ATPs by following the methodology described in Section 3. In this experimentation, we have used an Intel R\u00a9 Xeon R\u00a9 CPU E5-2640v3@2.60GHz with 2GB of RAM memory per processor. For each CQ, we provide an ontology and the given conjecture as input to the ATP system. In the next subsections, we report on the results of these experiments.18 Additionally, we have manually analysed some of the test in order to evaluate the proposed CQs, as reported in the last subsection."}, {"heading": "9.1. Evaluating the competency of SUMO based ontologies", "text": "In this subsection, we report on the evaluation of the competency of TPTP-SUMO [31] and Adimen-SUMO [2]. In the case of Adimen-SUMO, we also evaluate the improvement between two different versions: AdimenSUMO v2.2, which is the first version we proposed, and Adimen-SUMO v2.6.\nTable 3 sums up some result figures of the ATP Vampire v3.019 [33] when evaluating TPTP-SUMO and Adimen-SUMO (v2.2 and v2.6) with an execution time limit of 600 seconds. The election of Vampire v3.0 is based on the fact that it is the most successful ATP system in the experimentation reported in [4] when using the set of CQs proposed in [3] for the evaluation of ATPs. For each ontology, we provide the number (\u25e6 column) and percentage (\u22c4 column) of CQs that have been successfully proved together with the average run time (\u22c6 column).\n18The ontology Adimen-SUMO, the set of CQs and all the execution reports are freely available at http://adimen.si.ehu.es.\n19http://www.vprover.org\nFrom the results of problems proposed for the validation of ontologies, it is clear that Adimen-SUMO v2.6 outperforms TPTP-SUMO and AdimenSUMO v2.2 in terms of competency in both the truth-test \u2014more passing tests (1,117 against 170 and 325), since conjectures are expected to be entailed\u2014 and the falsity-test categories \u2014less non-passing tests (41 against 46 and 54), since conjectures are expected not to be entailed\u2014. Further, Adimen-SUMO v2.6 is by far the most competent ontology in all the validation subcategories of the truth-test categories. At the same time, AdimenSUMO v2.2 clearly outperforms TPTP-SUMO in all the validation subcategories of the truth-test categories.\nWith respect to the validation of the mapping information, AdimenSUMO v2.6 slightly outperforms TPTP-SUMO and Adimen-SUMO v2.2 in the truth-test category\u2014more passing tests (688 against 662 and 663)\u2014 because there is almost no difference in the Event subcategories. On the\ncontrary, no proof is found for the truth-test Multiple Mapping subcategory using TPTP-SUMO or Adimen-SUMO v2.2, while 23 truth-tests can be classified as passing using Adimen-SUMO v2.6. In the case of falsity-tests, the difference is clearly larger: 786 non-passing tests using Adimen-SUMO v2.6 against 1 non-passing test using TPTP-SUMO and 31 non-passing tests using Adimen-SUMO v2.2. This result reveals that Adimen-SUMO v2.6 enables the detection of many defects in the mapping information which are not discovered using TPTP-SUMO or Adimen-SUMO v2.6.\nRegarding efficiency, the average run times of Adimen-SUMO are in general shorter than the ones of TPTP-SUMO, especially in the truth-test categories: 14.68 s. (Adimen-SUMO v2.2) and 32.25 s. (Adimen-SUMO v2.6) against 44.19 s. (TPTP-SUMO). At the same time, the average run times of Adimen-SUMO v2.6 are longer than the ones of Adimen-SUMO v2.2. This fact leads us to think that the problems that are only solved using AdimenSUMO v2.6 require complex and long proofs and, additionally, it also confirms the improvement of Adimen-SUMO v2.6 in terms of competency."}, {"heading": "9.2. Evaluating the performance of FOL ATPs", "text": "According to the results reported in the previous section, the conjectures in the truth-test subcategories for the validation of the mapping information do not enable a suitable evaluation of ATPs since most of the proofs are obtained in less than 2 seconds (all the proofs from the truth-test subcategories). At the same time, very few CQs of the falsity-test subcategories for the validation of ontologies are proved (less than 1% of CQs). Consequently, we concentrate on the truth-test subcategories for the validation of ontologies and the falsity-test subcategories for the validation of the mapping information in order to evaluate FOL ATPs.\nIn Table 4, we sum up some figures of the evaluation of the different versions of Vampire (VP), E (EP) and VanHelsing (VH) introduced in Subsection 2.2 using Adimen-SUMO v2.6. For each ATP, we provide the number of proofs (\u25e6 column) and the average run times (\u22c6 column) in each problem subcategory.20\nGlobally, Vampire v2.6 is the winner according to the total number of proofs (2,327 proofs) with a difference of 424 and 1,070 proofs to Vampire v3.0 (second place) and Vampire v4.1 (third place) respectively. This result\n20VanHelsing does not provide final run time.\nis different from our preliminary evaluation of ATPs reported in [4]. In that evaluation, Vampire v3.0 was the most successful ATP and Vampire v2.6 nearly obtained the same number of proofs for the set of CQs proposed in [3], which is different from the set of CQs introduced in this work. With respect to the remaining ATPs (Vampire v4.0, E v1.9 and VanHelsing v1.0), the number of proofs is clearly smaller.\nRegarding each problem subcategory, Vampire v2.6 is the winner in the truth-test problem category (1,556 proofs) and also in all the truth-test problem subcategories. On the contrary, Vampire v3.0 is the winner in the falsitytest problem category (786 proofs) and also in all the Antonym problem subcategories. In the case of the falsity-test problem subcategory, the differences between the two first ATPs (Vampire v3.0 and v2.6) are smaller than the differences between the two first ATPs in the truth-test problem subcategory (Vampire v2.6 and v4.1), but the difference between the two first ATPs and the remaining ones is clearly larger.\nThe analysis of efficiency is more disparate:\n\u2022 Vampire v3.0 is the ATP with the lowest average run time (39.54 s.) followed by Vampire v4.0 (81.56 s.) and Vampire v2.6 (107.86 s.). However, Vampire v4.0 proves really few CQs in comparison with Vampire v2.6, which in general outperforms Vampire v4.0 in terms of efficiency except for the third problem subcategory of Antonym (182.29 s. against 60.32 s.) and the Multiple Mapping subcategory (271.55 s. against 55.36 s.).21 Consequently, we can state that Vampire v2.6 is proving\n21The average run time in the first problem subcategory of Antonym is almost equal.\nmore complex CQs than Vampire v4.0.\n\u2022 Vampire v2.6 is the ATP with the third lowest average run time in the falsity-test problem subcategory, but outperforms Vampire v3.0 in terms of efficiency in 3 falsity-test problem subcategories (Antonym #1, Instrument and Result) while solving more CQs than the remaining ATPs.\n\u2022 Vampire v4.1 and E v1.9 are the ATPs with the two worst average run times, but performing extremely well in the first subcategory of Antonym problems (Antonym #1). It is also worth to remark that the average run time of Vampire v4.1 in the Multiple Mapping problem subcategory is clearly the lowest one.\nTo sum up, we can conclude that our set of proposed CQs is really heterogeneous, enabling to evaluate a wide range of features of state-of-the-art ATPs."}, {"heading": "9.3. Evaluating Adimen-SUMO v2.6 and its Mapping from WordNet", "text": "Finally, we evaluate the competency of Adimen-SUMO v2.6, which consists of 7,437 axioms: 4,638 unit clauses (atomic formulas) and 2,799 general clauses (non-atomic formulas). For this purpose, all the ATP systems introduced in the above subsection have been individually used to experiment with the whole set of 15,010 CQs and then the outputs obtained from them have been jointly analysed.\nIn Table 5, we report the results of this experimentation and our joint analysis. These results are organized in three main categories \u2014Proofs, Coverage and Difficulty\u2014, each of them consisting of three columns. In the first category (Proofs), we provide the number (\u25e6 column) of CQs that are proved by some of the ATPs, together with its percentage (\u22c4 column) and the average run time (\u22c6 column). In the second category (Coverage), we provide the following figures about the axioms that are used in some of the proofs provided by ATPs:\n\u2022 The number (N column) and percentage (P column) of used axioms.\n\u2022 The number of different axioms that are exclusively used in proofs of the corresponding problem subcategory (E column).\n\u2022 The number of used unit clauses (UC column) and general clauses (GC column).\nIn the last category (Difficulty), we provide a measure of how difficult is to prove each CQ by reporting the average number of different axioms (N column) that are used in each proof and, in particular, the average number of different unit clauses (UC column) and general clauses (GC column).\nFrom the results reported in Tables 4 and 5, we can conclude that ATPs are able to prove different subsets of CQs. In this sense, the number of truthtests proposed for the validation of ontologies that are proved by at least one of the ATPs (1,666 truth-tests) is 7,07% larger than the number of truthtests that are proved by Vampire v2.6 (1,556 truth-tests), which is the most successful ATP. It is in particular the case of the second Antonym truth-test subcategory, where 233 tests are proved by some of the ATPs while each ATP at most proves 204 tests. Therefore, the number of CQs entailed by Adimen-SUMO could be larger than the number of proofs reported in Table 5. In particular, we could enlarge the number of proofs in our experiments by\nincreasing the execution time and memory limit settings or by tuning ATPs to Adimen-SUMO.\nAccording to the results obtained in the problem categories proposed for the validation of the ontology and its alignment toWordNet (4,969 problems), we can conclude that:\n\u2022 The knowledge of Adimen-SUMO and WordNet is well-aligned for 33.53% of problems (1,666 truth-tests from the Antonym and Relation problem subcategories are solved). In particular, 1,822 different axioms of the ontology (24.50% of the total) are used for the validation of the ontology.\n\u2022 Only 1.19% of problems (59 falsity-tests from the Antonym and Relation problem subcategories are proved) enable to detect some failure or misalignment in the knowledge of Adimen-SUMO and WordNet, which involve a total of 199 axioms (2.68% of the total).\n\u2022 The knowledge about incompatible classes and attributes in AdimenSUMO is better covered by WordNet than the knowledge about the relations agentr, instrumentr and resultr: 48.07% of truth-tests from the Antonym subcategory (1,444 proofs from 3,004 CQs) are proved against 11.30% of truth-tests from the Relation subcategory (222 proofs from 1,965 CQs).\nBesides evaluating the competency, incompatible (its falsity-test is classified as non-passing) and unsolved problems (both tests are classified as unknown) provide useful information to improve the ontology. For example, ATPs do not find a proof for the CQ in (19) (truth-test) and its negation (falsity-test). By inspecting the ontology, it is easy to check that the SUMO classes Birthc and Deathc are not axiomatized to be disjoint, as one would naturally expect. Thus, the problem consisting of (19) (truth-test) and its negation (falsity-test) enables to detect a defect in the ontology.\nWith respect to quality, we can state that the problems proposed for the validation of the ontology are suitable for the evaluation of the competency of Adimen-SUMO on the basis of three indicators:\n\u2022 The average run time of ATPs when solving a problem is longer than 10 seconds except for the Instrument and Result problem subcategories of truth-tests and the first subcategory of Antonym problems (Antonym #1) of falsity-tests.\n\u2022 The average number of different axioms that are used in each proof (Difficulty columns in Table 5) is higher than 11 except for the case of the first Antonym subcategory (both truth- and falsity-tests) and the second Antonym subcategory of falsity-tests.\n\u2022 There is a linear relation between the number of proofs (\u25e6 column) and the number of different axioms that are used in proofs (Coverage columns). In addition, among the 921 axioms that are exclusively used in a single problem subcategory (E column), 803 axioms correspond to truth-test subcategories of problems proposed for the validation of the ontology.\nAs conclusion, the two first indicators lead us to affirm that the proofs for the problems in the Antonym and Relation subcategories are not trivial, while the last one reveals that ATPs are not repeatedly using an small subset of axioms of the ontology for constructing the proofs.\nRegarding the validation of the mapping information, we have proposed 2,536 problems, from which 1,505 have been successfully solved by ATPs (59.35%): 717 truth-tests, which validate the mapping information of synsets, and 788 falsity-tests, which enable to detect defects in the mapping information of synsets. For example, the synsets affirm3\nv and affirmation2 n are related\nby event and respectively connected to Communicationc+ and Statingc=, from which we obtain the following truth-test:\n($subclass Stating Communication) (29)\nThe above CQ is entailed by Adimen-SUMO v2.6 since Statingc is subclass of LinguisticCommunicationc, which is in turn subclass of Communicationc. Therefore, the problem is decided to be solved and entailed, and we can conclude that the mapping of the synsets in the pair event(affirm3v,affirmation 2 n) is validated according to our criteria. On the contrary, we detect some defect in the mapping information of the synsets in event(represent14\nv ,representation1 n )\nas follows. Since represent14v and representation 1 n are respectively connected to Statingc= and Imaginingc=, we propose the following falsity-test stating that its mapping is wrong:\n(not (30)\n(equal Stating Imagining))\nATPs can prove that the above CQ is entailed by Adimen-SUMO v2.6 since Statingc is subclass of IntentionalProcessc and Dreamingc is subclass of\nImaginingc, being IntentionalProcessc and Dreamingc disjoint classes. Thus, the problem is decided to be solved and incompatible and it enables to detect that the mapping of (some of) the synsets in the pair event(represent14\nv ,\nrepresentation1n) is wrong."}, {"heading": "9.4. A Complete Analysis of a Small Set of Problems", "text": "As we have already described in the above subsections, the proposed set of CQs is suitable for evaluating the competency of Adimen-SUMO and for detecting some mapping failures. Additionally, there are some good indicators of the quality of the proposed CQs. However, a more detailed analysis of the quality of the proposed CQs and the mapping between WordNet and Adimen-SUMO requires a manual inspection of the conjectures, the mapping of the involved synsets and the proofs obtained by ATPs. Thus, we have randomly selected a sample of 75 problems (1%) following a uniform distribution.\nIn Table 6, we sum up some figures of our detailed analysis of the selected set of problems in four main categories \u2014Problems, Mapping, Solutions and Missing solutions\u2014. In the first category (Problems), we provide the number of problems of each category that have been randomly chosen. In the second category (Mapping, two columns), we provide the result of our quality analysis of the mapping between WordNet and Adimen-SUMO: the number of problems where both synsets are correctly connected to Adimen-SUMO (Correct column) and the number of problems such that at least one of the synsets is incorrectly connected (Incorrect column). In addition, we also provide the number of mappings where the two synsets are both correctly\nand precisely connected (Correct column, between brackets). Our criteria for classifying a mapping as only correct or as correct and precise are the following ones: we consider a mapping as correct if the semantics associated to the Adimen-SUMO concept and to the synset are compatible, and a correct mapping is also considered as precise if the synset and the SUMO concept subsume each other. Thus, we consider a mapping as only correct (that is, correct but not precise) when the semantics of the Adimen-SUMO concept is more general than the semantics of the synset. In the third category (Solutions, six columns), we provide the number of solutions classified according to two different criteria:\n\u2022 In the first two columns (TT and FT columns), we respectively provide the number of proofs for truth-and falsity-tests.\n\u2022 In the next two columns, we provide the number of solutions for problems where the mapping is correct \u2014both only correct or correct and precise\u2014 (CM column) and incorrect (IM column).\n\u2022 In the last two columns (CK and IK columns), we respectively provide the number of solutions where the knowledge from the ontology that is used is classified as correct (CK column), and the number of solutions that are based on incorrect knowledge of the ontology (IK columns).\nFinally, in the last category (Missing solutions, two columns) we sum up the results of our analysis about unsolved problems with a correct mapping \u2014either only correct or correct and precise\u2014: the number of problems that cannot be solved because of lack of knowledge in Adimen-SUMO or due to a misalignment in the knowledge of WordNet and Adimen-SUMO (Knowledge column), and the number of problems that are entailed by the ontology although ATPs do not find a proof within the given resource limits (ATP column).\nNext, we sum up the main conclusions extracted from our complete analysis:\n\u2022 More than two thirds of the problems with an incorrect mapping (20 of 32 problems) belong to the Antonym category problem, especially to the third Antonym subcategory (19 problems). This is mainly due to the poor mapping of WordNet adjectives and satellites. More concretely, many WordNet adjectives and satellites are connected to SUMO processes instead of SUMO attributes.\n\u2022 Among the problems with a correct mapping, the number of problems with a precise mapping is very low (17 of 43 problems). However, this is not surprising because of the large difference between the amount of concepts defined in Adimen-SUMO (3,407 concepts) and WordNet (117,659 synsets).\n\u2022 Our evaluation results (i.e. number of solved problems) are penalized by the poor mapping of WordNet adjectives and satellites, especially in the third Antonym subcategory: 62.50% of problems with a correct mapping are solved (5 of 8 problems) against 47.37% of problems with an incorrect mapping (9 of 19 problems).\n\u2022 The solutions of all the problems that have been solved (33 problems) are based on correct knowledge of the ontology (CK column), for problems with both a correct and incorrect mapping. This means that we have not discovered incorrect knowledge in the ontology by inspecting the proofs provided by ATPs.\n\u2022 Most of the unsolved problems with a correct mapping (22 of 25 problems) are due to the lack of information in the ontology. However, we have also discovered 3 problems for which either the truth- or the falsity-test are entailed by Adimen-SUMO although it cannot be proved by ATPs within the given resources of time and memory."}, {"heading": "10. Conclusions and Future Work", "text": "A long-standing dream of Artificial Intelligence (AI) has pursued to enrich computer programs with commonsense knowledge enabling machines to reason about our world [22]. This work offers a new practical insight towards the automation of commonsense reasoning with SUMO-based firstorder logic (FOL) ontologies. Next, we review the main contributions and results reported in this paper and discuss future work.\nFirst of all, we have introduced a novel black-box testing methodology for FOL ontologies \u2014which is an evolved version of the methodology introduced in [3]\u2014 that exploits WordNet and its mapping into SUMO. For this purpose, we have considered different interpretations of the mapping and selected the most productive one for our purposes. By following our proposal, we have obtained more than 7,500 problems (thus, more than 15,000 CQs), as far\nas we know the largest set of problems proposed for SUMO-based ontologies. Secondly, we have experimentally evaluated the competency of various translations of SUMO into FOL ontologies \u2014TPTP-SUMO, Adimen-SUMO v.2.2 and Adimen-SUMO v2.6\u2014 and the efficiency of several FOL ATPs. In our experimentation, we have checked the coverage of our set of problems by analysing the axioms that are used in the proofs provided by ATPs. Additionally, we have also demonstrated that the proposed set of problems enables to evaluate different features of ATPs since each single system is able to solve different subsets of problems using the same time and memory resources. Finally, we have manually evaluated the quality of a subset of the proposed problems when testing Adimen-SUMO v2.6. From our manual evaluation, we have detected a) some defects in the mapping of synsets (especially in the case of adjectives) and b) some solvable problems for which ATPs find no solution. We plan to propose the inclusion of our proposed set of problems in the CSR domain of the TPTP problem library and its consideration as eligible problems for the LTB division of the CASC competition.\nAll the resources that have been used and developed during this work are available in a single package, including:22 a) the ontologies; b) tools for the creation of tests, its experimentation and the analysis of results; and c) the resulting tests for each ontology and the output obtained from different ATPs.\nRegarding future work, our plan is to enlarge the proposed set of problems by following different strategies. Among others:\n\u2022 By considering different interpretations of the WordNet-SUMO mapping.\n\u2022 By exploiting additional SUMO relations, such as meronymy, hyponymy, etc.\n\u2022 By exploiting other resources of knowledge such as EuroWordNet Top Ontology ([1]), FrameNet ([34]) or Predicate Matrix ([8]).\n\u2022 By following white-box testing strategies that focus on the particular representation of the knowledge.\nFurther, we also aim to exploit unsolved problems in order to improve AdimenSUMO. For this purpose, we have to analyse whether the classification of\n22The package is available at http://adimen.si.ehu.es.\nproblems as unsolved is due to the lack of knowledge in Adimen-SUMO. If so, we would consider the possibility of enriching Adimen-SUMO by adding knowledge from WordNet or other resources. Additionally, WordNet itself and its mapping can be evaluated. For example, by detecting synsets that are continuously involved in problems classified as incompatible. Finally, we plan to evaluate the knowledge in the Multilingual Central Repository (MCR) [15] and to check the utility of Adimen-SUMO v2.6 in tasks that involve reasoning about commonsense knowledge, such as Recognizing Textual Entailment (RTE) [6], Natural Language Inference (NLI) [5] or Interpretable Semantic Textual Similarity (ISTS) [21]."}, {"heading": "Acknowledgements", "text": "This work has been partially funded by the Spanish Projects TUNER (TIN2015-65308-C5-1-R) and COMMAS (TIN2013-46181-C2-2-R), the Basque Project LoRea (GIU15/30) and grant BAILab (UFI11/45)."}], "references": [{"title": "Complete and consistent annotation of WordNet using the Top Concept Ontology", "author": ["J. \u00c1lvez", "J. Atserias", "J. Carrera", "S. Climent", "E. Laparra", "A. Oliver", "G. Rigau"], "venue": "N. Calzolari, K. Choukri, B. Maegaard, J. Mariani, J. Odjik, S. Piperidis, and D. Tapias, editors, Proc. of the 6 Int. Conf. on Language Resources and Evaluation (LREC 2008), pages 1529\u20131534. European Language Resources Association (ELRA), may", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2008}, {"title": "Adimen-SUMO: Reengineering an ontology for first-order reasoning", "author": ["J. \u00c1lvez", "P. Lucio", "G. Rigau"], "venue": "Int. J. Semantic Web Inf. Syst., 8(4):80\u2013 116,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Improving the competency of firstorder ontologies", "author": ["J. \u00c1lvez", "P. Lucio", "G. Rigau"], "venue": "K. Barker and J. M. G\u00f3mez-P\u00e9rez, editors, Proc. of the 8 Int. Conf. on Knowledge Capture (K-CAP 2015), pages 15:1\u2013 15:8. ACM,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Evaluating automated theorem provers using Adimen-SUMO", "author": ["J. \u00c1lvez", "P. Lucio", "G. Rigau"], "venue": "L. Kov\u00e1cs and A. Voronkov, editors, Proc. of the 3 Vampire Workshop (Vampire 2016), volume 44 of EPiC Series in Computing, pages 74\u201382. EasyChair,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2017}, {"title": "A large annotated corpus for learning natural language inference", "author": ["S.R. Bowman", "G. Angeli", "C. Potts", "C.D. Manning"], "venue": "Proc. of the Conf. on Empirical Methods in Natural Language Processing (EMNLP 2015). Association for Computational Linguistics,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Recognizing textual entailment: Models and applications", "author": ["I. Dagan", "D. Roth", "M. Sammons", "F.M. Zanzotto"], "venue": "Synthesis Lectures on Human Language Technologies, 6(4):1\u2013220,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Commonsense reasoning and commonsense knowledge in artificial intelligence", "author": ["E. Davis", "G. Marcus"], "venue": "Commun. ACM, 58(9):92\u2013103, aug", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "Predicate matrix: automatically extending the semantic interoperability between predicate resources", "author": ["M.L. de Lacalle", "E. Laparra", "I. Aldabe", "G. Rigau"], "venue": "Language Resources and Evaluation,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2016}, {"title": "WordNet: An Electronic Lexical Database", "author": ["C. Fellbaum", "editor"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1998}, {"title": "Putting semantics into Word- Net\u2019s \u201cMorphosemantic\u201d Links", "author": ["C. Fellbaum", "A. Osherson", "P. Clark"], "venue": "Z. Vetulani and H. Uszkoreit, editors, Human Language Technology. Challenges of the Information Society, LNCS 5603, pages 350\u2013358. Springer,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "Methodological guidelines for reusing general ontologies", "author": ["M. Fern\u00e1ndez-L\u00f3pez", "A. G\u00f3mez-P\u00e9rez", "M.C. Su\u00e1rez-Figueroa"], "venue": "Data & Knowledge Engineering, 86:242\u2013275,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Modelling ontology evaluation and validation", "author": ["A. Gangemi", "C. Catenacci", "M. Ciaramita", "J. Lehmann"], "venue": "Y. Sure and J. Domingue, editors, The Semantic Web: Research and Applications, LNCS 4011, pages 140\u2013 154. Springer,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2006}, {"title": "Knowledge Interchange Format version 3.0 reference manual", "author": ["M.R. Genesereth", "R.E. Fikes", "D. Brobow", "R. Brachman", "T. Gruber", "P. Hayes", "R. Letsinger", "V. Lifschitz", "R. Macgregor", "J. Mccarthy", "50  P. Norvig", "R. Patil", "L. Schubert"], "venue": "Technical Report Logic-92-1,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1992}, {"title": "Ontological engineering", "author": ["A. G\u00f3mez-P\u00e9rez", "M. Fern\u00e1ndez-L\u00f3pez", "O. Corcho-Gar\u0107\u0131a"], "venue": "Computing Reviews, 45(8):478\u2013479,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2004}, {"title": "Multilingual Central Repository version 3.0", "author": ["A. Gonzalez-Agirre", "E. Laparra", "G. Rigau"], "venue": "Proc. of the 8 Int. Conf. on Language Resources and Evaluation (LREC", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Ontology", "author": ["T. Gruber"], "venue": "L. Liu and M. T. \u00d6zsu, editors, Encyclopedia of Database Systems, pages 1963\u20131965. Springer US,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "Methodology for the design and evaluation of ontologies", "author": ["M. Gr\u00fcninger", "M.S. Fox"], "venue": "Proc. of the Workshop on Basic Ontological Issues in Knowledge Sharing (IJCAI 1995),", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1995}, {"title": "Reasoning support for expressive ontology languages using a theorem prover", "author": ["I. Horrocks", "A. Voronkov"], "venue": "J. Dix et al., editor, Foundations of Information and Knowledge Systems, LNCS 3861, pages 201\u2013218. Springer,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2006}, {"title": "First-order theorem proving and Vampire", "author": ["L. Kov\u00e1cs", "A. Voronkov"], "venue": "N. Sharygina and H. Veith, editors, Computer Aided Verification, LNCS 8044, pages 1\u201335. Springer,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "vanHelsing: A fast proof checker for debuggable compiler verification", "author": ["R. Lezuo", "I. Dragan", "G. Barany", "A. Krall"], "venue": "Proc. of the 17 International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC), pages 167\u2013174. IEEE,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "Interpretable semantic textual similarity: Finding and explaining differences between sentences", "author": ["I. Lopez-Gazpio", "M. Maritxalar", "A. Gonzalez-Agirre", "G. Rigau", "L. Uria", "E. Agirre"], "venue": "Knowledge-Based Systems, 119:186 \u2013 199,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2017}, {"title": "Applications of circumscription to formalizing commonsense knowledge", "author": ["J. McCarthy"], "venue": "Artificial Intelligence, 28(1):89\u2013116,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1986}, {"title": "Artificial intelligence, logic and formalizing common sense", "author": ["J. McCarthy"], "venue": "R. H. Thomason, editor, Philosophical Logic and Artificial Intelligence, pages 161\u2013190. Springer,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1989}, {"title": "The Emotion Machine: Commonsense Thinking, Artificial Intelligence, and the Future of the Human Mind", "author": ["M. Minsky"], "venue": "Simon & Schuster,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2007}, {"title": "The art of software testing", "author": ["G.J. Myers", "C. Sandler", "T. Badgett"], "venue": "John Wiley & Sons, Inc., Hoboken, N.J.,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "Towards a standard upper ontology", "author": ["I. Niles", "A. Pease"], "venue": "Guarino N. et al., editor, Proc. of the 2 Int. Conf. on Formal Ontology in Information Systems (FOIS 2001), pages 2\u20139. ACM,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2001}, {"title": "Linking lexicons and ontologies: Mapping Word- Net to the Suggested Upper Merged Ontology", "author": ["I. Niles", "A. Pease"], "venue": "H. R. Arabnia, editor, Proc. of the IEEE Int. Conf. on Inf. and Knowledge Engin. (IKE 2003), volume 2, pages 412\u2013416. CSREA Press,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2003}, {"title": "Ontology development 101: A guide to creating your first ontology", "author": ["N.F. Noy", "D.L. McGuinness"], "venue": "Technical Report KSL-01-05 and SMI-2001- 0880, Stanford Knowledge Systems Laboratory and Stanford Medical Informatics,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2001}, {"title": "Standard Upper Ontology Knowledge Interchange Format", "author": ["A. Pease"], "venue": " Retrieved June 18, 2009, from http://sigmakee.cvs.sourceforge.net/sigmakee/sigma/suo-kif.pdf,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2009}, {"title": "Sigma: An integrated development environment for formal ontology", "author": ["A. Pease", "C. Benzm\u00fcller"], "venue": "AI Communications (Special Issue on Intelligent Engineering Techniques for Knowledge Bases), 26(1):79\u201397,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2013}, {"title": "First-order reasoning on a large ontology", "author": ["A. Pease", "G. Sutcliffe"], "venue": "Sutcliffe G. et al., editor, Proc. of the Workshop on Empirically Successful Automated Reasoning in Large Theories (CADE-21), CEUR Workshop Proceedings 257. CEUR-WS.org,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2007}, {"title": "The Development of CASC", "author": ["F. Pelletier", "G. Sutcliffe", "C. Suttner"], "venue": "AI Communications, 15(2-3):79\u201390,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2002}, {"title": "The design and implementation of Vampire", "author": ["A. Riazanov", "A. Voronkov"], "venue": "AI Communications, 15(2-3):91\u2013110,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2002}, {"title": "FrameNet II: Extended Theory and Practice", "author": ["J. Ruppenhofer", "M. Ellsworth", "M.R.L. Petruck", "C.R. Johnson", "J. Scheffczyk"], "venue": "International Computer Science Institute, Berkeley, California,", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2006}, {"title": "E - A brainiac theorem prover", "author": ["S. Schulz"], "venue": "AI Communications, 15(2- 3):111\u2013126,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2002}, {"title": "Handbook on Ontologies", "author": ["S. Staab", "R. Studer"], "venue": "Springer Publishing Company, Incorporated, 2 edition,", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2009}, {"title": "The TPTP problem library and associated infrastructure", "author": ["G. Sutcliffe"], "venue": "J. Automated Reasoning, 43(4):337\u2013362,", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2009}, {"title": "The State of CASC", "author": ["G. Sutcliffe", "C. Suttner"], "venue": "AI Communications, 19(1):35\u201348,", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2006}], "referenceMentions": [{"referenceID": 22, "context": "Recently, Artificial Intelligence (AI) has shown great advances in many different research areas, but there is one critical area where progress has shown limited progress: commonsense representation and commonsense reasoning [23, 24, 7].", "startOffset": 225, "endOffset": 236}, {"referenceID": 23, "context": "Recently, Artificial Intelligence (AI) has shown great advances in many different research areas, but there is one critical area where progress has shown limited progress: commonsense representation and commonsense reasoning [23, 24, 7].", "startOffset": 225, "endOffset": 236}, {"referenceID": 6, "context": "Recently, Artificial Intelligence (AI) has shown great advances in many different research areas, but there is one critical area where progress has shown limited progress: commonsense representation and commonsense reasoning [23, 24, 7].", "startOffset": 225, "endOffset": 236}, {"referenceID": 27, "context": "them [28, 16, 36, 2].", "startOffset": 5, "endOffset": 20}, {"referenceID": 15, "context": "them [28, 16, 36, 2].", "startOffset": 5, "endOffset": 20}, {"referenceID": 35, "context": "them [28, 16, 36, 2].", "startOffset": 5, "endOffset": 20}, {"referenceID": 1, "context": "them [28, 16, 36, 2].", "startOffset": 5, "endOffset": 20}, {"referenceID": 13, "context": "In the literature, there exist some methodologies that collect the experience in ontology development [14] and, more concretely, in ontology verification [12].", "startOffset": 102, "endOffset": 106}, {"referenceID": 11, "context": "In the literature, there exist some methodologies that collect the experience in ontology development [14] and, more concretely, in ontology verification [12].", "startOffset": 154, "endOffset": 158}, {"referenceID": 16, "context": "Roughly speaking, the methodologies for validating functional requirements of ontologies are based on the use of competency questions (Cs) [17].", "startOffset": 139, "endOffset": 143}, {"referenceID": 24, "context": "In this sense, these methods can be classified as black-box testing [25] according to the classical definition in software engineering, since the definition of tests does not depend on the particular specification of knowledge proposed by the ontology.", "startOffset": 68, "endOffset": 72}, {"referenceID": 10, "context": "Further, the process of obtaining CQs is not automatic but creative [11].", "startOffset": 68, "endOffset": 72}, {"referenceID": 8, "context": "Our proposal is based on several predefined question patterns that yield to a large set of CQs by using information from WordNet [9] and its mapping into SUMO [27].", "startOffset": 129, "endOffset": 132}, {"referenceID": 26, "context": "Our proposal is based on several predefined question patterns that yield to a large set of CQs by using information from WordNet [9] and its mapping into SUMO [27].", "startOffset": 159, "endOffset": 163}, {"referenceID": 2, "context": "A preliminary version of our method for the automatic creation of CQs has been already presented in [3], where we also proposed an adaptation of the methodology for the evaluation of ontologies introduced in [17] to be automatically applied using automated theorem provers (ATPs).", "startOffset": 100, "endOffset": 103}, {"referenceID": 16, "context": "A preliminary version of our method for the automatic creation of CQs has been already presented in [3], where we also proposed an adaptation of the methodology for the evaluation of ontologies introduced in [17] to be automatically applied using automated theorem provers (ATPs).", "startOffset": 208, "endOffset": 212}, {"referenceID": 2, "context": "As introduced in [3], our proposal is an adaptation of the methodology described in [17] for the design and evaluation of ontologies.", "startOffset": 17, "endOffset": 20}, {"referenceID": 16, "context": "As introduced in [3], our proposal is an adaptation of the methodology described in [17] for the design and evaluation of ontologies.", "startOffset": 84, "endOffset": 88}, {"referenceID": 2, "context": "and the performance of various FOL ATPs by means of the adapted evaluation method proposed in [3].", "startOffset": 94, "endOffset": 97}, {"referenceID": 25, "context": "SUMO and its Transformations into FOL SUMO [26] has its origins in the nineties, when a group of engineers from the IEEE Standard Upper Ontology Working Group pushed for a formal", "startOffset": 43, "endOffset": 47}, {"referenceID": 28, "context": "SUMO is expressed in SUO-KIF (Standard Upper Ontology Knowledge Interchange Format [29]), which is a dialect of KIF (Knowledge Interchange Format [13]).", "startOffset": 83, "endOffset": 87}, {"referenceID": 12, "context": "SUMO is expressed in SUO-KIF (Standard Upper Ontology Knowledge Interchange Format [29]), which is a dialect of KIF (Knowledge Interchange Format [13]).", "startOffset": 146, "endOffset": 150}, {"referenceID": 1, "context": "Consequently, SUMO cannot be directly used by FOL ATPs without a suitable transformation [2].", "startOffset": 89, "endOffset": 92}, {"referenceID": 30, "context": "In [31], the authors report some preliminary experimental results evaluating the query timeout for different options when translating SUMO into FOL.", "startOffset": 3, "endOffset": 7}, {"referenceID": 30, "context": "Evolved versions of the translation described in [31] can be found in the Thousands of Problems for Theorem Provers (TPTP) problem library [37] (hereinafter TPTP-SUMO), but have been not longer maintained since TPTP problem library version v5.", "startOffset": 49, "endOffset": 53}, {"referenceID": 36, "context": "Evolved versions of the translation described in [31] can be found in the Thousands of Problems for Theorem Provers (TPTP) problem library [37] (hereinafter TPTP-SUMO), but have been not longer maintained since TPTP problem library version v5.", "startOffset": 139, "endOffset": 143}, {"referenceID": 17, "context": "Following the line of [18], in [2] we use ATPs for reengineering around 88% of SUMO, obtaining Adimen-SUMO (v2.", "startOffset": 22, "endOffset": 26}, {"referenceID": 1, "context": "Following the line of [18], in [2] we use ATPs for reengineering around 88% of SUMO, obtaining Adimen-SUMO (v2.", "startOffset": 31, "endOffset": 34}, {"referenceID": 1, "context": "[2]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 29, "context": "With respect to higher-order aspects of SUMO, an additional translation is required for enabling the use of SUMO by means of pure higher-order theorem provers [30].", "startOffset": 159, "endOffset": 163}, {"referenceID": 36, "context": "Since 1993, many researchers have used the Thousands of Problems for Theorem Provers (TPTP) problem library as an appropriate and convenient basis for ATP system evaluation [37], which becomes the de facto standard set of test problems for classical FOL ATP systems.", "startOffset": 173, "endOffset": 177}, {"referenceID": 31, "context": "The performance of ATP systems is evaluated every year in the CADE ATP System Competition (CASC) [32, 38] in the context of a set of problems chosen from the TPTP problem library and applying a specified time limit for each individual problem.", "startOffset": 97, "endOffset": 105}, {"referenceID": 37, "context": "The performance of ATP systems is evaluated every year in the CADE ATP System Competition (CASC) [32, 38] in the context of a set of problems chosen from the TPTP problem library and applying a specified time limit for each individual problem.", "startOffset": 97, "endOffset": 105}, {"referenceID": 32, "context": "Among the systems that have ever participated in CASC, we have selected the ones that are of special interest for reasoning with FOL ontologies, which are Vampire [33], E [35] and VanHelsing [20].", "startOffset": 163, "endOffset": 167}, {"referenceID": 34, "context": "Among the systems that have ever participated in CASC, we have selected the ones that are of special interest for reasoning with FOL ontologies, which are Vampire [33], E [35] and VanHelsing [20].", "startOffset": 171, "endOffset": 175}, {"referenceID": 19, "context": "Among the systems that have ever participated in CASC, we have selected the ones that are of special interest for reasoning with FOL ontologies, which are Vampire [33], E [35] and VanHelsing [20].", "startOffset": 191, "endOffset": 195}, {"referenceID": 32, "context": "The first one is Vampire [33], an ATP system for first-order classical logic which has been the winner of the FOF and LTB divisions in CASC during several years.", "startOffset": 25, "endOffset": 29}, {"referenceID": 2, "context": "6), and has been used for the experimentation reported in [3].", "startOffset": 58, "endOffset": 61}, {"referenceID": 34, "context": "The second system that we have selected is E [35], a theorem prover for full FOL with equality which consists of a (optional) clausifier for pre-processing full first-order formulae into clausal form, and a saturation algorithm implementing an instance of the superposition calculus with negative literal selection and a number of redundancy elimination techniques.", "startOffset": 45, "endOffset": 49}, {"referenceID": 19, "context": "On the other hand, we have selected an ATP system that has only participated once in CASC: VanHelsing [20], which obtained the 4 position in CASC-J7 (2014) FOF division.", "startOffset": 102, "endOffset": 106}, {"referenceID": 1, "context": "In addition, we have proposed 5 creative CQs in [2] and 26 creative CQs in [3].", "startOffset": 48, "endOffset": 51}, {"referenceID": 2, "context": "In addition, we have proposed 5 creative CQs in [2] and 26 creative CQs in [3].", "startOffset": 75, "endOffset": 78}, {"referenceID": 1, "context": "For example, the conjectures \u201cPlants do not suffer from headache\u201d [2] and \u201cHerbivores eat animals\u201d [3]:", "startOffset": 66, "endOffset": 69}, {"referenceID": 2, "context": "For example, the conjectures \u201cPlants do not suffer from headache\u201d [2] and \u201cHerbivores eat animals\u201d [3]:", "startOffset": 99, "endOffset": 102}, {"referenceID": 2, "context": "To the best of our knowledge, this set exclusively consists of the 7,112 CQs proposed in [3], where we introduced a preliminary version of the method described in this paper for the exploitation of WordNet and its mapping into SUMO.", "startOffset": 89, "endOffset": 92}, {"referenceID": 3, "context": "The resulting set of CQs have been used for the automatic evaluation of ATP systems reported in [4].", "startOffset": 96, "endOffset": 99}, {"referenceID": 16, "context": "In this section, we summarize our adaptation of the methodology for the design and evaluation of ontologies introduced in [17] to be automatically applied using state-of-the-art ATPs, as initially proposed in [3].", "startOffset": 122, "endOffset": 126}, {"referenceID": 2, "context": "In this section, we summarize our adaptation of the methodology for the design and evaluation of ontologies introduced in [17] to be automatically applied using state-of-the-art ATPs, as initially proposed in [3].", "startOffset": 209, "endOffset": 212}, {"referenceID": 16, "context": "In [17], the authors propose to evaluate the expressiveness of an ontology by proving completeness theorems w.", "startOffset": 3, "endOffset": 7}, {"referenceID": 2, "context": "For this purpose, in [3] we propose to use ATPs like Vampire [33], E [35] or VanHelsing [20] that work by refutation within some given execution-time and memory limits.", "startOffset": 21, "endOffset": 24}, {"referenceID": 32, "context": "For this purpose, in [3] we propose to use ATPs like Vampire [33], E [35] or VanHelsing [20] that work by refutation within some given execution-time and memory limits.", "startOffset": 61, "endOffset": 65}, {"referenceID": 34, "context": "For this purpose, in [3] we propose to use ATPs like Vampire [33], E [35] or VanHelsing [20] that work by refutation within some given execution-time and memory limits.", "startOffset": 69, "endOffset": 73}, {"referenceID": 19, "context": "For this purpose, in [3] we propose to use ATPs like Vampire [33], E [35] or VanHelsing [20] that work by refutation within some given execution-time and memory limits.", "startOffset": 88, "endOffset": 92}, {"referenceID": 18, "context": "However, theorem proving in FOL is a very hard problem, so it is not reasonable to expect ATPs to find a proof for every entailed conjecture [19].", "startOffset": 141, "endOffset": 145}, {"referenceID": 2, "context": "On the contrary, conjecture (4) \u2014\u201cHerbivores eat animals\u201d\u2014, which belongs to the set of CQs proposed in [3], is a falsity-test since it is not expected to be entailed by the ontology.", "startOffset": 104, "endOffset": 107}, {"referenceID": 2, "context": "Our proposal is a substantially evolved version of the method presented in [3].", "startOffset": 75, "endOffset": 78}, {"referenceID": 2, "context": "Among other improvements, we now make use of the different mapping relation between WordNet and SUMO, that were equally treated in [3], and we are now able to exploit additional WordNet information.", "startOffset": 131, "endOffset": 134}, {"referenceID": 2, "context": "As a consequence, the set of CQs introduced in this work \u2014which is different from the one introduced in [3]\u2014 enables a more fruitful exploitation of the knowledge in WordNet and its mapping into SUMO.", "startOffset": 104, "endOffset": 107}, {"referenceID": 8, "context": "Exploiting WordNet and its Mapping into SUMO WordNet [9] is a large lexical database where nouns, verbs, adjectives and adverbs are grouped into sets of synonyms (synsets), each expressing a distinct concept.", "startOffset": 53, "endOffset": 56}, {"referenceID": 9, "context": "\u2022 Morphosemantic Links [10], which are semantic relations between morphologically related verbs and nouns provided in the morphosemantic database.", "startOffset": 23, "endOffset": 27}, {"referenceID": 26, "context": "WordNet is linked with SUMO by means of the mapping described in [27].", "startOffset": 65, "endOffset": 69}, {"referenceID": 9, "context": "In this section, we describe the problems that are obtained from the question patterns based on the semantic relation event defined in the Morphosemantic Links database [10] of WordNet for the validation of the mapping information of synsets.", "startOffset": 169, "endOffset": 173}, {"referenceID": 9, "context": "In this section, we describe the problems that are obtained from the Morphosemantic Links database [10] of WordNet for the validation of the", "startOffset": 99, "endOffset": 103}, {"referenceID": 30, "context": "Evaluating the competency of SUMO based ontologies In this subsection, we report on the evaluation of the competency of TPTP-SUMO [31] and Adimen-SUMO [2].", "startOffset": 130, "endOffset": 134}, {"referenceID": 1, "context": "Evaluating the competency of SUMO based ontologies In this subsection, we report on the evaluation of the competency of TPTP-SUMO [31] and Adimen-SUMO [2].", "startOffset": 151, "endOffset": 154}, {"referenceID": 32, "context": "0 [33] when evaluating TPTP-SUMO and Adimen-SUMO (v2.", "startOffset": 2, "endOffset": 6}, {"referenceID": 3, "context": "0 is based on the fact that it is the most successful ATP system in the experimentation reported in [4] when using the set of CQs proposed in [3] for the evaluation of ATPs.", "startOffset": 100, "endOffset": 103}, {"referenceID": 2, "context": "0 is based on the fact that it is the most successful ATP system in the experimentation reported in [4] when using the set of CQs proposed in [3] for the evaluation of ATPs.", "startOffset": 142, "endOffset": 145}, {"referenceID": 3, "context": "is different from our preliminary evaluation of ATPs reported in [4].", "startOffset": 65, "endOffset": 68}, {"referenceID": 2, "context": "6 nearly obtained the same number of proofs for the set of CQs proposed in [3], which is different from the set of CQs introduced in this work.", "startOffset": 75, "endOffset": 78}, {"referenceID": 21, "context": "A long-standing dream of Artificial Intelligence (AI) has pursued to enrich computer programs with commonsense knowledge enabling machines to reason about our world [22].", "startOffset": 165, "endOffset": 169}, {"referenceID": 2, "context": "First of all, we have introduced a novel black-box testing methodology for FOL ontologies \u2014which is an evolved version of the methodology introduced in [3]\u2014 that exploits WordNet and its mapping into SUMO.", "startOffset": 152, "endOffset": 155}, {"referenceID": 0, "context": "\u2022 By exploiting other resources of knowledge such as EuroWordNet Top Ontology ([1]), FrameNet ([34]) or Predicate Matrix ([8]).", "startOffset": 79, "endOffset": 82}, {"referenceID": 33, "context": "\u2022 By exploiting other resources of knowledge such as EuroWordNet Top Ontology ([1]), FrameNet ([34]) or Predicate Matrix ([8]).", "startOffset": 95, "endOffset": 99}, {"referenceID": 7, "context": "\u2022 By exploiting other resources of knowledge such as EuroWordNet Top Ontology ([1]), FrameNet ([34]) or Predicate Matrix ([8]).", "startOffset": 122, "endOffset": 125}, {"referenceID": 14, "context": "Finally, we plan to evaluate the knowledge in the Multilingual Central Repository (MCR) [15] and to check the utility of Adimen-SUMO v2.", "startOffset": 88, "endOffset": 92}, {"referenceID": 5, "context": "6 in tasks that involve reasoning about commonsense knowledge, such as Recognizing Textual Entailment (RTE) [6], Natural Language Inference (NLI) [5] or Interpretable Semantic Textual Similarity (ISTS) [21].", "startOffset": 108, "endOffset": 111}, {"referenceID": 4, "context": "6 in tasks that involve reasoning about commonsense knowledge, such as Recognizing Textual Entailment (RTE) [6], Natural Language Inference (NLI) [5] or Interpretable Semantic Textual Similarity (ISTS) [21].", "startOffset": 146, "endOffset": 149}, {"referenceID": 20, "context": "6 in tasks that involve reasoning about commonsense knowledge, such as Recognizing Textual Entailment (RTE) [6], Natural Language Inference (NLI) [5] or Interpretable Semantic Textual Similarity (ISTS) [21].", "startOffset": 202, "endOffset": 206}], "year": 2017, "abstractText": "A long-standing dream of Artificial Intelligence (AI) has pursued to enrich computer programs with commonsense knowledge enabling machines to reason about our world. This paper offers a new practical insight towards the automation of commonsense reasoning with first-order logic (FOL) ontologies. We propose a new black-box testing methodology of FOL SUMO-based ontologies by exploiting WordNet and its mapping into SUMO. Our proposal includes a method for the (semi-)automatic creation of a very large set of tests and a procedure for its automated evaluation by using automated theorem provers (ATPs). Applying our testing proposal, we are able to successfully evaluate a) the competency of several translations of SUMO into FOL and b) the performance of various automated ATPs. In addition, we are also able to evaluate the resulting set of tests according to different quality criteria.", "creator": "LaTeX with hyperref package"}}}