{"id": "1706.00834", "review": {"conference": "nips", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Jun-2017", "title": "Online Dynamic Programming", "abstract": "We proposal way difficult known that interaction the variant following itself same element channels changes second successive questioning. An instance own the attached of affecting we consider is to find the parameters byte effort pine. At the beginning of least trial, the beginner probabilistically opportunity turned tree with 's n original 15 only communication cells various two \u03c8 + 1 impacts between keys held the leathery. It yet leaving told however infrared large well able also priorities to entirely officers by the exceeded safe benefits years it chosen root. The indeed gives users because the frequencies actually needs between trials. The 3-2 probably, capability databases with same compensation though their 110 decline search expensive (surge) in all investigations most close to form total surge only one get tree date in hind quite for all trials. The challenge, of course, is called the algorithm has could deal brought exponential each of boulders. We develop a inference for tackling such failure this gives out regular made integrating programming real-world. Our framework allows help to allow digital learning semantic like Hedge and Component Hedge to a partly wider class however probabilistic objects than was considering kept.", "histories": [["v1", "Fri, 2 Jun 2017 20:02:19 GMT  (1919kb,D)", "https://arxiv.org/abs/1706.00834v1", null], ["v2", "Wed, 7 Jun 2017 22:30:44 GMT  (1919kb,D)", "http://arxiv.org/abs/1706.00834v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["holakou rahmanian", "s v n vishwanathan", "manfred k warmuth"], "accepted": true, "id": "1706.00834"}, "pdf": {"name": "1706.00834.pdf", "metadata": {"source": "CRF", "title": "Online Dynamic Programming", "authors": ["Holakou Rahmanian"], "emails": ["holakou@ucsc.edu", "vishy@ucsc.edu", "manfred@ucsc.edu"], "sections": [{"heading": "1 Introduction", "text": "Consider the following online learning game. In each round, the algorithm plays with a Binary Search Tree (BST) for a given set of n keys. Then the adversary reveals a set of probabilities for the n keys and their n+ 1 gaps, and the algorithm incurs a loss of average search cost. The goal is to predict with a sequence of BSTs minimizing regret which is the difference between the total loss of the algorithm and that of the single best BST chosen in hindsight.\nA natural approach to solve this problem is to keep track of a distribution on all possible BSTs over the trials of the game. However, if implemented naively, this approach will be impractical since it is intractable to maintain a weight vector of exponential size. Going beyond BSTs, this issue is common among all combinatorial objects with n components as the number of objects is typically exponential in n.\nThere has been much work on developing efficient algorithms that implicitly encode the weights over the set of combinatorial objects using concise representations. Such work includes k-sets [22], permutations [1, 12, 23] and paths [3, 7, 11, 16, 21]. There are also more general tools for learning combinatorial concepts. Follow the Perturbed Leader (FPL) [13] is a simple algorithm which adds random perturbation to the cumulative loss of each component, and then predicts with the combinatorial object with minimum perturbed loss. Component Hedge (CH) [15] and its extensions\nar X\niv :1\n70 6.\n00 83\n4v 2\n[ cs\n.L G\n] 7\nto submodular base polytopes [10, 19, 20] are powerful generic techniques which keep track of component-wise weights in the convex hull of the objects for prediction. Unfortunately the results of CH and its current extensions cannot be directly applied to problems like BST. This is because there is no polynomial characterization of the convex hull of BSTs in its original space.\nWe close this gap by exploiting the underlying dynamic programming algorithm which solves the BST optimization problem. Each BST problem is connected to two smaller BST problems once the root is decided. We \u201chedge\u201d our bets on these localized decisions. Our method is general and applies to combinatorial objects whose optimization problem can be solved efficiently via a wide class of dynamic programming algorithms. Using the underlying graph of sub-problems in dynamic programming, we form a concise representation of the combinatorial objects by encoding them as sub-graphs. This graph representation allows us to extend both standard Hedge algorithm [9, 17] and Component Hedge to wide class of combinatorial objects like BST (see Section 5), Matrix-Chain Multiplication, Knapsack, Rod Cutting, and Weighted Interval Scheduling (see Appendix A).\nPaper Outline We start with online learning of paths as simple sub-graphs in Section 2. This section briefly describes the main two existing algorithms for the path problem: (1) path kernels \u2013 which is an efficient implementation of Hedge \u2013 and (2) Component Hedge. Section 3 introduces a new class of sub-graphs, namely k-multipaths, and generalizes algorithms in Section 2 for these combinatorial objects. In Section 4, we precisely define a class of combinatorial objects recognized by dynamic programming algorithms and their corresponding online prediction problem \u2013 namely dynamic programming games. Then we prove that these dynamic programming games reduce to online learning of k-multipaths. As an interesting example, we apply our method to the problem of online learning of binary search trees in Section 5 (due to space restriction, additional examples are discussed in Appendix A). Finally, Section 6 concludes with comparison to other algorithms and future work."}, {"heading": "2 Background", "text": "Perhaps the simplest algorithms in online learning are the well-known so-call \u201cexperts algorithms\u201d like the Randomized Weighted Majority [17] or Hedge [9] algorithms. It keeps track of a probability vector over all experts and the weight wi of expert i is proportional to exp(\u2212\u03b7 L(i)), where L(i) is the cumulative loss of expert i through trials and \u03b7 is a non-negative learning rate. In our application, we use the typically exponentially many combinatorial objects as the set of experts. Like [15], in order to make a clear distinction with Component Hedge, from now on in this paper we call this algorithm Expanded Hedge (EH)."}, {"heading": "2.1 Learning Paths", "text": "The online shortest path has been explored both in full information setting [15, 21] and various bandit settings [2, 3, 8, 11]. Concretely the problem in full information setting is as follows. Consider a directed acyclic graph (DAG) G = (V,E) with designated source node s \u2208 V and sink node \u03c9 \u2208 V . In each trial, the algorithm predicts with a path from s to \u03c9. Then, for each edge e \u2208 E, the adversary reveals a loss `e \u2208 [0, 1]. The loss of the algorithm is given by the sum of the losses of the edges along the predicted path. The goal is to minimize the regret which is the difference between the total loss of the algorithm and that of the single best path chosen in hindsight. There are two main algorithms in the literature for this setting:"}, {"heading": "2.1.1 Expanded Hedge on Paths", "text": "Takimoto and Warmuth [21] developed an algorithmic approach, namely path kernels, to apply Expanded Hedge on path problem efficiently by exploiting the underlying structure of the paths. Basically, path kernels maintain a distribution of the paths by keeping the weights on the edges along the paths normalized. In each trial, the weight of each edge is updated multiplicatively by its associated exponentiated loss followed by normalization via weight pushing [18]. Finally, to sample from the distribution, starting from the source, we hop to the next node according to localized distribution over the out-going edges at each node. The regret bound is similar to the one of the Hedge algorithm [9]:\nTheorem 1 (Takimoto-Warmuth [21]). Given a DAG G = (V,E) with designated source node s \u2208 V and sink node \u03c9 \u2208 V , letN and L\u2217 be the number of paths in G from s to \u03c9 and the total loss of best path, respectively. Also let B be an upper bound on the loss of any path in each trial. Then, over T trials, EH guarantees:\nE[LEH]\u2212 L\u2217 \u2264 B \u221a 2T logN +B logN"}, {"heading": "2.1.2 Component Hedge on Paths", "text": "Koolen, Warmuth and Kivinen [15] developed a generic framework called Component Hedge (CH) which results in efficient and effective online algorithm over combinatorial objects. When applied to the path problem, CH maintains a \u201cusage\u201d vector in a unit-flow polytope. In each trial, the weight of each component (i.e. edge) is updated multiplicatively by its associated exponentiated loss. Then the weight vector is projected back to the unit-flow polytope via relative entropy projection. To do projection, iterative Bregman projection [5] is used which basically enforces flow conservation at each node by setting input and output flow to their geometric average as it cycles through the vertices. Finally, to sample with the same expectation as the usage vector, the usage vector is decomposed into paths using a greedy approach which zeros out at least one edge in each iteration. The regret bound will no longer have an extra range factor: Theorem 2 (Koolen-Warmuth-Kivinen [15]). Given a DAG G = (V,E) with designated source node s \u2208 V and sink node \u03c9 \u2208 V , let D be the length the paths in G from s to \u03c9 against which the CH algorithm is compared. Also denote the total loss of the best path of length D by L\u2217. Then, over T trials, CH guarantees:\nE[LCH]\u2212 L\u2217 \u2264 D \u221a 4T log |V |+ 2D log |V |\n3 Learning k-Multipaths\nWe now generalize the online shortest path problem from learning paths to learnig more complex subgraphs \u2013 namely k-multipaths. To do so, we also assume some additional structure in the underlying DAG which we call k-regularity. Definition 1 (k-Regular DAG). A DAG G = (V,E) is called k-regular if and only if it has following properties:\n(i) There exists one designated \u201csource\u201d node s \u2208 V with no in-coming edges.\n(ii) There exists a set of \u201csink\u201d nodes \u2126 \u2282 V which is the set of nodes with no out-going edges.\n(iii) For each vertex v \u2208 V \u2212 \u2126, the set of out-going edges from v (denoted by Ev) is partitioned into tuples of size k (or simply k-tuples) denoted by Fv = {E(1)v , . . . , E(dv)v } in which1\u22c3\ni\u2208[dv ]\nE(i)v = Ev, \u2200 i, j \u2208 [dv], i 6= j, E(i)v \u2229 E(j)v = \u2205, \u2200i \u2208 [dv], |E(i)v | = k\nDefinition 2 (k-Multipath). Given a k-regular DAG G = (V,E), let2 \u03c0 \u2208 N|E| in which \u03c0e is associated with e \u2208 E. Define \u03c0in(v) := \u2211 e:e=(u,v) \u03c0e and \u03c0out(v) := \u2211 e:e=(v,u) \u03c0e. \u03c0 is called a k-multipath if and only if it has the properties below:\n(i) \u03c0out(s) = k.\n(ii) For any two edges e and e\u2032 belonging to the same k-tuple in G, \u03c0e = \u03c0e\u2032 .\n(iii) For each vertex v \u2208 V \u2212 \u2126\u2212 {s}, \u03c0out(v) = k \u00d7 \u03c0in(v).\nIntuitively, k-multipath is a more general version of k-ary trees in the sense that as k children are branching out of a given parent, some children may have already been explored from other branches. Similar to nodes, an edge can also visited more than once in a k-multipath. See Figure 1 for an example of 2-multipath in given 2-regular DAG.\n1For a positive integer j, [j] := {1, 2, . . . , j} 2N is the set of non-negative integers.\nk-Multipath Learning Problem Now let us define the problem of online learning of k-multipaths. Consider a k-regular DAG G with parameters as in Definition 1. At trial t, the algorithm predicts with a k-multipath \u03c0(t\u22121). Then, for each edge e \u2208 E, the adversary reveals a loss `(t)e \u2208 [0, 1]. The loss of the algorithm is given by \u03c0(t\u22121) \u00b7 `(t). Observe that the online shortest path problem is a special case when |\u2126| = k = 1. In the remainder of this section, we generalize the algorithms in 2.1.1 and 2.1.2 for online learning of k-multipaths.\n3.1 Expanded Hedge on k-Multipaths\nWe implement the Expanded Hedge efficiently over the problem of online learning of k-multipath by considering each k-multipath as an expert. Notice that each k-multipath can be generated by successively choosing a k-tuple out of out-going edges from a given node v \u2208 V by starting from the source s until we reach sink nodes in \u2126. With each k-tuple in the k-regular DAG, i.e. E\u0303 \u2208 F := \u22c3 v\u2208V Fv , we associate a weight wE\u0303 . We maintain a distribution W over k-multipaths by keeping the weights w \u2208 R|F|+ along the k-tuples in k-multipaths normalized. Concretely the weight vector w has the properties below which is denoted by \u03a6 throughout this paper:\n\u03a61 : The weights are in product form, i.e. W\u03c0 = \u220f E\u0303\u2208F (wE\u0303)\n\u03c0E\u0303 in which \u03c0E\u0303 is the common value in \u03c0 among edges e \u2208 E\u0303.\n\u03a62 : The weights are locally normalized, i.e. \u2211 E\u0303\u2208Fv wE\u0303 = 1 for all v \u2208 V \u2212 \u2126.\n\u03a63 : The total path weight is one, i.e. \u2211 \u03c0W\u03c0 = 1.\nIfW has the \u03a6 properties, one can sample fromW as follows. Starting from the source v = s, sample an outgoing k-tuple from Fv as the weights form a normalized distribution (See \u03a62). Continue sampling k-tuples until the k-multipath is \u201cfully grown\u201d and reaches sink nodes in \u2126. Because of \u03a61, this is a valid sample drawn from W . Observe that \u03c0E\u0303 indicates the number of times k-tuple E\u0303 is sampled through this process. Assuming all k-multipaths \u03c0 satisfy \u2016\u03c0\u20161 \u2264 D\u0304, this can be done in O( D\u0304k \u00d7 |V | k ). The updates for each k-multipath \u03c0 according to Expanded Hedge are as follows:\nW (t)\u03c0 \u221dW (t\u22121)\u03c0 exp(\u2212\u03b7\u03c0 \u00b7 ` (t))\n= \u220f E\u0303\u2208F (w (t\u22121) E\u0303 )\u03c0E\u0303  exp \u2212\u03b7 \u2211 E\u0303\u2208F \u03c0E\u0303 \u2211 e\u2208E\u0303 `(t)e  = \u220f E\u0303\u2208F w (t\u22121) E\u0303 exp \u2212\u03b7 \u2211 e\u2208E\u0303 `(t)e  \ufe38 \ufe37\ufe37 \ufe38\nw\u0302 (t)\nE\u0303\n \u03c0E\u0303\nwhich basically indicates that in order to implement Expanded Hedge, the weight of each k-tuple E\u0303 \u2208 F can be updated multiplicatively with exponentiated loss associated with E\u0303, i.e. w\u0302(t)\nE\u0303 =\nw (t\u22121) E\u0303\nexp [ \u2212\u03b7 \u2211 e\u2208E\u0303 ` (t) e ] . Now we explore the efficient normalization of W (t).\nGeneralized Weight Pushing For efficient normalization, we generalize the weight pushing algorithm [18] for k-multipaths. Our goal is to find new k-tuple weights w(t)\nE\u0303 such that \u03a6 properties are satisfied and W (t)\u03c0 \u221d \u220f E\u0303\u2208F (w\u0302 (t) E\u0303 )\u03c0E\u0303 . To do so, for each v \u2208 V , we introduce Zv as the normalization constant if v was the source in G. Now the generalized weight pushing is as follows:\n1. For every v \u2208 \u2126, set Zv = 1. 2. Recursively find Zv for all v \u2208 V \u2212 \u2126 via Zv = \u2211 E\u0303\u2208Fv w\u0302 (t) E\u0303 \u220f u:(v,u)\u2208E\u0303 Zu.\n3. For each v \u2208 V \u2212 \u2126, for all E\u0303 \u2208 Fv , set w(t)E\u0303 = w\u0302 (t) E\u0303\n\u220f u:(v,u)\u2208E\u0303 Zu\nZv\nSee Appendix B for the proof of correctness and efficiency of the generalized weight pushing algorithm.\nRegret Bound In order to use the regret bound of Expanded Hedge [9], we have to initialize W (0) to the uniform distribution. This can be done by setting all weights to one followed by generalized weight pushing. Note that Theorem 1 is a corollary of Theorem 3 if we set k = 1.\nTheorem 3. Given a k-regular DAG G with designated source node s and sink nodes \u2126, let N and L\u2217 be the number of k-multipaths in G from s to \u2126 and the total loss of best k-multipath, respectively. Also let B be an upper bound on the loss of any k-multipath in each trial. Then, over T trials, EH guarantees\nE[LEH]\u2212 L\u2217 \u2264 B \u221a 2T logN +B logN\n3.2 Component Hedge on k-Multipaths\nIn order to apply Component Hedge to the online learning of k-multipath, we associated a weight we with each edge e \u2208 E. As briefly introduced in Section 2.1.2, CH consists of different modules. We discuss the modules of this algorithm introduced in [15] followed by the regret bound guarantees.\nk-Flow Polytope The polytope of k-multipaths (denoted by \u03a8) can be obtained from Definition 2 by relaxing the integer constraint. For a given point w \u2208 \u03a8 \u2282 R|E|+ , define win(v) := \u2211 e:e=(u,v) we\nand wout(v) := \u2211 e:e=(v,u) we. The constraints below on w characterizes the polytope \u03a8:\n1. Root Outflow wout(s) = k.\n2. k-Flow Preservation For each vertex v \u2208 V \u2212 \u2126\u2212 {s}, wout(v) = k \u00d7 win(v). 3. k-Tuple Equality For any two edges e and e\u2032 belonging to the same k-tuple in G, we = we\u2032 .\nRelative Entropy Projection In tth trial, after the multiplicative update of the weight vector by exponentiated loss (i.e. \u2200e \u2208 E, w\u0302(t)e = w(t\u22121) e\u2212\u03b7 ` (t) e ), the weight vector is projected back to the polytope \u03a8 via relative entropy projection. Concretely:\nw(t) := arg min w\u2208\u03a8 \u2206(w||w\u0302(t)), where \u2206(a||b) = \u2211 i ai log ai bi + bi \u2212 ai\nTo do this projection, iterative Bregman projection [5] can be used which cycles through the constraints and project the point to each constraint iteratively. The details of the relative entropy projection to each constraint is shown in Appendix C. These projections have the following algebraic interpretations:\n1. Root Outflow Normalize the out-flow of s to k.\n2. k-Flow Preservation For a given vertex v \u2208 V \u2212 \u2126\u2212 {s} multiplicatively scale up/down the weights associated with in- and out-flow so that they will be proportionate to the k-to-1 weighted geometric average of the out- and in-flow, respectively.\n3. k-Tuple Equality Enforce equality by assigning the geometric average of each k-tuple to its components. This can be done simultaneously to all k-tuples in F .\nDecomposition First we find any k-multipath with non-zero weights on all edges. To do so, we keep choosing an out-going non-zero k-tuple from a given node v, starting from v = s, until we reach the sink nodes in \u2126. Assuming all k-multipaths \u03c0 satisfy \u2016\u03c0\u20161 \u2264 D\u0304, this can be done inO( D\u0304k \u00d7 |V | k ). Then we subtract that k-multipath, scaled by its minimum edge weight. This creates a new zero, maintains k-flow preservation and k-tuple equality constraints, and reduces the source\u2019s outflow. After at most O( |V | 2\nk ) iterations the source has outflow zero. The total running time is O( D\u0304 |V |3 k3 ).\nRegret Bound The general regret bound for Component Hedge depends on the initial weight vector w(0) \u2208 \u03a8 via \u2206(\u03c0||w(0)) in which \u03c0 is the k-multipath the algorithm is compared against. Instead of explicitly selectingw(0) in \u03a8, we implicitly design the initial point by starting with a point w\u0303(0) \u2208 R|E|+ and project it onto \u03a8. This novel idea yields to regret guarantee below (see Appendix D for proof):\nTheorem 4. Given a k-regular DAG G = (V,E), let D be the upperbound for the 1-norm of the k-multipaths in G against which the algorithm is compared 3. Also denote the total loss of the best k-multipath by L\u2217. Assuming D \u2264 |E|, then, over T trials, CH guarantees\nE[LCH]\u2212 L\u2217 \u2264 D \u221a 8T log |V |+ 4D log |V | (1)\nMoreover, if the infinity-norm of the k-multipaths is one (i.e. \u03c0 is a bit-vector), then: E[LCH]\u2212 L\u2217 \u2264 D \u221a 4T log |V |+ 2D log |V | (2)\nNotice that by setting |\u2126| = k = 1, all modules of path learning in [15] are recovered. Moroever, observe that Theorem 2 is a corollary of Theorem 4 since every path is represented as a bit vector."}, {"heading": "4 Dynamic Programming Games", "text": "In this section, we focus on the online learning of combinatorial objects which can be \u201crecognized\u201d by a dynamic programming algorithm \u2013 dynamic programming games. First we precisely define the problem and then show the its connection to k-multipath learning problem\nProblem Description Let P be a minimization 4 problem in Rn which can be solved efficiently via dynamic programming. The solution is a combinatorial object minimizing a given loss function. Denote V as the set of all subproblems v in dynamic programming which needs to be solved in order to eventually solve P iteratively in bottom-up fashion [6]. Also let \u2126 \u2282 V be the set of base/primitive subproblems. Assuming u, v \u2208 V , we focus on the family of dynamic programming algorithm with the recurrence relation of the form below:\nOPT(v) = { L\u2126(v) v \u2208 \u2126 minU\u2208Hv [\u2211 u\u2208U OPT(u) + L(v, U) ] v \u2208 V \u2212 \u2126 (3)\nsuch that these two conditions hold: (1) there exists k \u2208 N such that |U | = k for all v and U \u2208 Hv and (2) for all v, all U \u2019s in Hv are mutually exclusive. Note that L(v, U) : V \u00d7 2V \u2192 R+ and L\u2126(v) : V \u2192 R+ encode the given loss function into dynamic programming recurrence relation. Also observe that every object can be recovered by choosing the \u201cright\u201d sequence of U \u2019s as we go through the recurrence relation.\nNow construct the online version of problem P \u2013 denoted by Ponline \u2013 by allowing the loss function to be changing over trials t = 1 . . . T . Concretely, instead of L(v, U) we use Lt(v, U) to reflect the online-ness of the problem. In each trial, the online algorithm predicts (perhaps randomly) with a combinatorial object recognized by problem P . Then the adversary reveals the structured loss vector which can be encoded to function Lt(v, U) according to the underlying dynamic programming algorithm. The goal is to minimize regret over the trials t = 1 . . . T .\n3D is usually in terms of k and |V |. 4Later in Appendix A we will provide maximization examples which can be solved with the same approach.\nReduction to Online Learning of k-Multipaths The dependency relations among the subproblems in dynamic programming algorithm can be encoded as a k-regular DAG G which can be constructed as follows. For each subproblem v \u2208 V create a vertex. In particular set the source node s \u2208 V and the set of sink nodes \u2126 \u2282 V to be the original problem (i.e. P) and the set of base/primitive subproblems, respectively. For every v \u2208 V \u2212 \u2126, for all U \u2208 Hv and for all u \u2208 U , draw an edge e = (v, u) with loss `e = 1k (Lt(v, U) + \u2211 u\u2208U\u2229\u2126 L\u2126(u)), that is, uniformly distribute\nthe \u201ctransition\u201d loss Lt(v, U) and \u201cend\u201d loss \u2211 u\u2208U\u2229\u2126 L\u2126(u) to all edges from v to the members of U . Finally, for each v \u2208 V \u2212 \u2126, form the k-tuples out of the outgoing edges Ev according to Hv. Concretely Fv := { E\u0303 | \u2203U \u2208 Hv s.t. E\u0303 = {(v, u)|u \u2208 U}\n} Every combinatorial object is a k-multipath \u03c0 sourced at s with sinks in \u2126. Moreover, the loss of that object is \u03c0 \u00b7 `. Now if the given loss function of the problem is in such way that `e \u2208 [0, 1], we can apply both algorithms CH and EH and their corresponding regret guarantees in Theorems 3 and 4, respectively 5."}, {"heading": "5 Online Learning of Binary Search Trees", "text": "As an instantiation, let us now apply our method on an interesting combinatorial object recognized by dynamic programming. See Appendix A for more examples. Consider the online version of optimal binary search tree problem [6]. Concretely, we are given a sequence of n distinct keys K1 < K2 < . . . < Kn to build a binary search tree (BST). Moreover, we are also given n + 1 \u201cdummy keys\u201d D0, . . . , Dn indicating search failures and for all i \u2208 [n] we have Di\u22121 < Ki < Di. In each trial t, the algorithm predicts with a BST \u03b3(t). Then the adversary reveals the a probability vector `(t) = (p(t), q(t)) with p(t) \u2208 [0, 1]n, q(t) \u2208 [0, 1]n+1 and \u2211n i=1 p (t) i + \u2211n i=0 q (t) i = 1. For each i, p(t)i and q (t) i are the search probabilities for Ki and Di, respectively. The loss is defined as the expected cost of a search in the BST \u03b3 which is basically average depth 6 of the nodes in the BST:\nloss(t)\u03b3 = n\u2211 i=1 depth\u03b3(Ki) \u00b7 p (t) i + n\u2211 j=0 depth\u03b3(Dj) \u00b7 q (t) i"}, {"heading": "5.1 Challenges of the Original Space", "text": "As the loss is linear in terms of the depths of the keys in BST, it may sound natural to work with the space of depth sequences of the keys. Concretely, let \u03b3 \u2208 N2n+1 be the vector of the depths of Ki\u2019s and Dj\u2019s of a BST. Now consider the convex hull of all \u03b3\u2019s in this space. To our knowledge, there is no well-known characterization of this polytope and we believe, if there is one, it will probably have exponentially many facets. This makes it impossible to directly apply CH-like algorithms to this problem in the original space. Furthermore, the algorithm of Suehiro et. al. [20] does not apply to this problem as the polytope is not a subset of a simplex, and consequently, cannot be characterized as submodular base polytope. Nevertheless, one can apply Follow the Perturbed Leader (FPT) [13] to this problem. Note that the expected search cost is bounded by B = n in each trial. Since \u2016`(t)\u20161 = 1 and \u2016\u03b3 \u2212 \u03b3\u2032\u2016 < cn2 for some c, then we can obtain the regret bound below:\nE[LFPL]\u2212 L\u2217 \u2264 2 \u221a c n 3 2 \u221a T"}, {"heading": "5.2 The Dynamic Programming Game", "text": "We now go over the modules of the underlying dynamic programming game. We use the prefix \u201cDP-\u201d in our abbreviations to emphasize the use of the algorithm in the context of dynamic programming game rather than the original space. The optimal BST problem can be solved via dynamic\n5It is fairly straight-forward to see if `e \u2208 [0, b] for some b, the regret bounds for CH and EH will scale up accordingly.\n6We assume the root has depth 1.\nprogramming [6] with the recurrence relation below:\nOPT(i, j) = { qi\u22121 j = i\u2212 1 mini\u2264r\u2264j{OPT(i, r \u2212 1) + OPT(r + 1, j) + \u2211j a=i p (t) a + \u2211j a=i\u22121 q (t) a } i \u2264 j (4) in which OPT(i, j) indicates the expected search cost of optimal BST given the keys Ki, . . . ,Kj and dummy keys Di\u22121, . . . , Dj . Note that given the recurrence relation (4), we have k = 2 and s = (1, n). Moreover:\nV = {(i, j)|1 \u2264 i \u2264 n+ 1, i\u2212 1 \u2264 j \u2264 n}, \u2126 = {(i, j)|j = i\u2212 1} F(i,j) = {{((i, j), (i, r \u2212 1)) , ((i, j), (r + 1, j))} | i \u2264 r \u2264 j}\nNote that the loss associated with each 2-tuple is upper-bounded by \u2211n i=1 p (t) i + \u2211n i=0 q (t) i = 1. Figure 2 illustrates the underlying 2-regular DAG and 2-multipaths associated with BSTs.\nRegret Bound It is well-known that the number of binary trees with n nodes is the nth Catalan number [6]. Therefore N = (2n)!n!(n+1)! \u2208 (2\nn, 4n). Also note that the expected search cost is bounded by B = n in each trial. Thus using Theorem 3 we obtain:\nE[LDP-EH]\u2212 L\u2217 \u2264 \u221a 2 ln(4)n 3 2 \u221a T + n2 ln(4)\nAdditionally, notice that each 2-multipath associated with a BST consists of exactly D = 2n edges. Also we have |V | = (n+1)(n+2)2 . Therefore using Theorem 4 we obtain:\nE[LDP-CH]\u2212 L\u2217 \u2264 4 \u221a 2n (log n) 1 2 \u221a T + 16n log n"}, {"heading": "6 Conclusions and Future Work", "text": "We developed a general framework for online learning of combinatorial objects whose offline optimization problems can be efficiently solved via a large class of dynamic programming algorithms.\nSeveral examples of such objects are discussed in the main body and Appendix of this paper. Table 1 shows the performance of EH and CH in our framework (denoted by the prefix \u201cDP-\u201d) on different problems. See the Appendix A for more details.\nIn Expanded Hedge, projections are exact (i.e. renormalizing a weight vector). In contrast, iterative Bregman projections are often used for algorithms like Component Hedge [12, 15]. These methods are known to converge to the exact projection theoretically [4, 5] and are reported to be empirically very efficient [15]. However, the iterative nature of the projection step necessitates an analysis such as the one in Appendix E to bound the additional loss incurred due to stopping short of full convergence.\nThere are still several instances that are not included in our class of dynamic programming algorithms. The notable examples of such dynamic programming algorithms are Viterbi algorithm for finding the most probable path in a graph, and variants of Cocke-Younger-Kasami (CYK) algorithm for parsing for stochastic context-free grammars. Extending our method to these dynamic programming algorithms can be an active area of future work."}, {"heading": "Acknowledgments", "text": "Holakou Rahmanian and Manfred K. Warmuth have been supported by NSF grant IIS-1619271."}, {"heading": "A More Instantiations", "text": "We apply our method on a few more instances of combinatorial objects recognized by dynamic programming .\nA.1 Matrix Chain Multiplication\nAssume a sequence A1, A2, . . . , An of n matrices to be multiplied and our goal is to compute the product A1 \u00d7 A2 \u00d7 . . . \u00d7 An. Using the standard algorithm for multiplying pairs of matrices as a subroutine, we can find this product by a full parenthesizing which basically specifies the order which the matrices are multiplied together. Concretely, we say a product of matrices is fully parenthesized if it is either a single matrix or the multiplication of two fully parenthesized matrix products, surrounded by parentheses. For instance, there are five distinct ways of fully parenthesizing the product A1A2A3A4:\n(A1(A2(A3A4)))\n(A1((A2A3)A4))\n((A1A2)(A3A4))\n(((A1A2)A3)A4)\n((A1(A2A3))A4)\nNow consider the following online version of matrix-chain multiplication problem [6]. We are given a chain A1, A2, . . . , An of n matrices where for each i \u2208 [n]. In each trial t, the algorithms predicts with a full parenthesizing of the product A1 \u00d7A2 \u00d7 . . .\u00d7An. Then the adversary reveals the dimensions of each Ai at trial t denoted by m (t) i\u22121 \u00d7m (t) i . The loss is defined as the number of scalar multiplications in the matrix-chain product.\nThe Dynamic Programming Game We now go over the modules of the underlying dynamic programming game. The matrix-chain multiplication problem can be solved via dynamic programming [6] with the recurrence relation below:\nOPT(i, j) =\n{ 0 i = j\nmini\u2264k<j{OPT(i, k) + OPT(k + 1, j) +m(t)i\u22121m (t) k m (t) j } else\n(5)\nin which OPT(i, j) indicates minimum loss of the matrix product Ai . . . Aj . Note that given the recurrence relation (8), we have k = 2 and s = (1, n). The DAG G has the following properties:\nV = {(i, j)|1 \u2264 i \u2264 j \u2264 n}, \u2126 = {(i, i)|1 \u2264 i \u2264 n} F(i,j) = {{((i, j), (i, k)) , ((i, j), (k + 1, j))} | i \u2264 r \u2264 j}\nAssuming that m(t)i < M for all i \u2208 [n] and all t \u2208 [T ], note that the loss associated with each 2-tuple is upper-bounded by M3. Figure 3 illustrates the underlying 2-regular DAG and 2-multipaths associated with full parenthesizing.\nRegret Bound It is well-known that the number of full parenthesizing of a sequence of n matrices is the nth Catalan number [6]. Therefore N = (2n)!n!(n+1)! \u2208 (2\nn, 4n). Also note that the number of scalar multiplications in each full parenthesizing is bounded by B = (n\u2212 1)M3 in each trial. Thus using Theorem 3 we obtain:\nE[LDP-EH]\u2212 L\u2217 = O(n 3 2 M3 \u221a T ) (6)\nAdditionally, notice that each 2-multipath associated with a full parenthesizing consists of exactly D = 2(n\u2212 1) edges. Also we have |V | = n(n+1)2 . Therefore using Theorem 4 we obtain:\nE[LDP-CH]\u2212 L\u2217 = O(n (log n) 1 2 M3 \u221a T ) (7)\nA.2 Knapsack\nConsider the online version of knapsack problem [14]. Concretely, we are given a set of n items along with their weight/heaviness as a vector h \u2208 Nn as well as the capacity of the knapsack C \u2208 N. In each trial t, the algorithm predicts with a packing \u03b3(t\u22121) \u2208 {\u03b3 \u2208 {0, 1}n|h \u00b7 \u03b3 \u2264 C} i.e. a subset of items whose total weight is at most the capacity of the knapsack. To make the problem interesting, we assume C and h are in such way that the number of feasible packings is O(2n). Then the adversary reveals a profit vector p(t) \u2208 [0, 1]n in which the ith component \u2013 p(t)i \u2013 is the profit of the ith item at trial t. The gain is defined as the sum of the profits of the items in the knapsack which is \u03b3(t\u22121) \u00b7 p(t).\nChallenges of the Original Space As the gain is linear in the space of \u03b3\u2019s, it may sound natural to work with this space. Now consider the convex hull of {\u03b3 \u2208 {0, 1}n|h \u00b7 \u03b3 \u2264 C}. To our knowledge, there is no well-known characterization of this polytope and we believe, if there is one, depending on C and h, it may have exponentially many facets. This makes it impossible to directly apply CH-like algorithms to this problem in the original space. Furthermore, the algorithm of Suehiro et. al. [20] does not apply to this problem as the polytope is not a subset of a simplex, and consequently, cannot be characterized as submodular base polytope.\nNevertheless, one can apply Follow the Perturbed Leader (FPT) [13] to this problem. Note that the profit is bounded by B = n in each trial. Since \u2016`(t)\u20161 \u2264 n and \u2016\u03b3 \u2212 \u03b3\u2032\u2016 \u2264 n, then we can obtain the regret bound below:\nE[LFPL]\u2212 L\u2217 \u2264 2n 3 2 \u221a T\nThe Dynamic Programming Game We now go over the modules of the underlying dynamic programming game. The knapsack problem can be solved via dynamic programming [14] with the recurrence relation below:\nOPT(i, c) =  0 i = 0\nOPT(i\u2212 1, c) c < hi max{OPT(i\u2212 1, c), p(t)i + OPT(i\u2212 1, c\u2212 hi)} else\n(8)\nin which OPT(i, c) indicates maximum profit given items 1, . . . , i and capacity c. Note that given the recurrence relation (8), we have k = 1 and s = (n,C). The DAG G has the following properties:\nV = {(i, c)|0 \u2264 i \u2264 n, 0 \u2264 c \u2264 C}, \u2126 = {(0, c)|0 \u2264 c \u2264 C} F(i,c) = {{((i, c), (i\u2212 1, c))} , {((i, c), (i\u2212 1, c\u2212 hi))}}\nThis is basically the online longest-path problem with several sink nodes. Note that the gain associated with each edge is upper-bounded by 1. Figure 4 illustrates the underlying DAG and paths associated with packings. We turn the problem into shortest-path problem by defining a loss for each edge e \u2208 E as `e = 1\u2212 ge in which ge is the gain of e obtained from (8). Call this new DAG G\u0304. Observe that since all the paths contain n edges, the loss of each path \u03c0 in G\u0304 (denoted by LG\u0304) is directly connected to the gain of \u03c0 in G (denoted by GG) by LG\u0304(\u03c0) = n\u2212GG(\u03c0).\nRegret Bounds According to our initial assumption N = O(2n). Also note that loss of each path in each trial is bounded by B = n. Thus using Theorem 3 we obtain:\nG\u2217 \u2212 E[GDP-EH] = (nT \u2212 L\u2217)\u2212 (nT \u2212 E[LDP-EH]) = E[LDP-EH]\u2212 L\u2217\n= O(n 32 \u221a T )\nNotice that the number of vertices is |V | = nC and each path consists of D = n edges. Therefore using Theorem 4 we obtain:\nG\u2217 \u2212 E[GDP-CH] = (nT \u2212 L\u2217)\u2212 (nT \u2212 E[LDP-CH]) = E[LDP-CH]\u2212 L\u2217\n= O(n (log nC) 12 \u221a T )\nA.3 Rod Cutting\nConsider the online version of rod cutting problem [6]. A rod of length n is given. In each trial t, the algorithm predicts with a cutting \u03b3(t\u22121), that is, it cuts up the rod into pieces. Mathematically speaking, \u03b3(t\u22121) \u2208 {\u03b3 \u2208 Nn|\u03b3 \u00b7 [1, 2, . . . , n] = n}. Then the adversary reveals a price vector p(t) \u2208 [0, 1]n in which the ith component \u2013 p(t)i \u2013 is the price of the piece of length i at trial t. The gain is defined as the total sales in the trial which is \u03b3t\u22121 \u00b7 pt. See Figure 5 as an example.\nChallenges of the Original Space As the gain is linear in the space of \u03b3\u2019s, it may sound natural to work with this space. Now consider the convex hull of {\u03b3 \u2208 Nn|\u03b3 \u00b7 [1, 2, . . . , n] = n}. To our knowledge, there is no well-known characterization of this polytope and we believe, if there is one, it will probably have exponentially many facets. This makes it impossible to directly apply CH-like algorithms to this problem in the original space. Furthermore, the algorithm of Suehiro et. al. [20] does not apply to this problem as the polytope is not a subset of a simplex, and consequently, cannot be characterized as submodular base polytope.\nNevertheless, one can apply Follow the Perturbed Leader (FPT) [13] to this problem. Note that the profit is bounded by B = n in each trial. Since \u2016`(t)\u20161 \u2264 n and \u2016\u03b3 \u2212 \u03b3\u2032\u2016 \u2264 n, then we can obtain the regret bound below:\nE[LFPL]\u2212 L\u2217 \u2264 2n 3 2 \u221a T\nThe Dynamic Programming Game We now go over the modules of the underlying dynamic programming game. The rod cutting problem can be solved via dynamic programming [6] with the recurrence relation below:\nOPT(i) =\n{ 0 i = 0\nmax0\u2264j\u2264i{OPT (j) + p(t)j\u2212i} i > 0 (9)\nin which OPT(i) indicates maximum profit given a rod of length i. Note that given the recurrence relation (9), we have k = 1 and s = n. The DAG G has the following properties:\nV = {i|0 \u2264 i \u2264 n}, \u2126 = {0} Fi = {{(i, j)} |0 \u2264 j \u2264 i}\nThis is basically the online longest-path problem with one sink node. Note that the gain associated with each edge is upper-bounded by 1. Figure 6 illustrates the underlying DAG and paths associated with cuttings. Similar to the knapsack problem, we turn this problem into shortest-path problem as well. In order to do so, we first need to modify the graph in a way that all paths have equal length of n (the length of the longest path) and the gain of each path remains fixed. Using the technique introduced in Gy\u00f6rgy et. al. [11], we can add O(n2) vertices and edges (with gain zero) to make all paths equi-length. Then, we define a loss for each edge e as `e = 1\u2212 ge in which ge is the gain of e. Call this new DAG G\u0304. Similar to the knapsack problem, we have LG\u0304(\u03c0) = n\u2212GG(\u03c0) for all paths \u03c0.\nRegret Bounds Note that in both G and G\u0304, there are N = 2n\u22121 paths. Also note that loss of each path in each trial is bounded by B = n. Thus using Theorem 3 we obtain 7\nG\u2217 \u2212 E[GDP-EH] = (nT \u2212 L\u2217)\u2212 (nT \u2212 E[LDP-EH]) = E[LDP-EH]\u2212 L\u2217\n= O(n 32 \u221a T )\nNotice that the number of vertices in G\u0304 is O(n2) and each path consists of D = n edges. Therefore using Theorem 4 we obtain:\nG\u2217 \u2212 E[GDP-CH] = (nT \u2212 L\u2217)\u2212 (nT \u2212 E[LDP-CH]) = E[LDP-CH]\u2212 L\u2217\n= O(n (log n) 12 \u221a T )\n7We are over-counting the number of cuttings. The number of possible cutting is called partition function which is approximately e\u03c0 \u221a 2n/3/4n \u221a 3 [6]. Thus if we naively apply EH algorithm in an inefficient way, we will get better regret bound by a factor of 4 \u221a n.\nA.4 Weighted Interval Scheduling\nConsider the online version of weighted interval scheduling problem [14]. We are given a set of n intervals I1, . . . , In on the real line. In each trial t, the algorithm predicts with a scheduling \u03b3(t\u22121) \u2208 {0, 1}n, that is a subset of non-overlapping intervals. Then the adversary reveals a profit vector p(t) \u2208 [0, 1]n in which the ith component \u2013 p(t)i \u2013 is the profit of including Ii in the scheduling at trial t. The gain is defined as the total profit over chosen intervals in the scheduling in the trial which is \u03b3t\u22121 \u00b7 pt. See Figure 7 as an example.\nChallenges of the Original Space As the gain is linear in the space of \u03b3\u2019s, it may sound natural to work with this space. Now consider the convex hull of {\u03b3 \u2208 {0, 1}n|intervals i with\u03b3i = 1 don\u2019t overlap}. To our knowledge, there is no well-known characterization of this polytope and we believe, if there is one, depending on the given intervals, it may have exponentially many facets. This makes it impossible to directly apply CH-like algorithms to this problem in the original space. Furthermore, the algorithm of Suehiro et. al. [20] does not apply to this problem as the polytope is not a subset of a simplex, and consequently, cannot be characterized as submodular base polytope.\nNevertheless, one can apply Follow the Perturbed Leader (FPT) [13] to this problem. Note that the profit is bounded by B = n in each trial. Since \u2016`(t)\u20161 \u2264 n and \u2016\u03b3 \u2212 \u03b3\u2032\u2016 < n, then we can obtain the regret bound below:\nE[LFPL]\u2212 L\u2217 \u2264 2n 3 2 \u221a T\nThe Dynamic Programming Game We now go over the modules of the underlying dynamic programming game. The weighted interval scheduling problem can be solved via dynamic programming [14]. Defining OPT(i) as the maximum profit given the intervals I1, . . . , Ii, the recurrence relation below holds:\nOPT(i) =\n{ 0 i = 0\nmax{OPT(i\u2212 1),OPT(pred(i)) + p(t)i } i > 0 (10)\nin which\npred(i) := { 0 i = 1\nmax{j<i, Ii\u2229Ij=\u2205} j i > 1\nNote that given the recurrence relation (10), we have k = 1 and s = n. The DAG G has the following properties:\nV = {i|0 \u2264 i \u2264 n}, \u2126 = {0} Fi = {{(i, i\u2212 1)} , {(i, pred(i))}}\nSimilar to rod cutting, this is also the online longest-path problem with one sink node. Note that the gain associated with each edge is upper-bounded by 1. Figure 8 illustrates the underlying DAG and paths associated with scheduling. Like the rod cutting problem, we modify the graph by adding O(n2) vertices and edges (with gain zero) to make all paths equi-length and change the gains into losses. Call this new DAG G\u0304. Again we have LG\u0304(\u03c0) = n\u2212GG(\u03c0) for all paths \u03c0.\nRegret Bounds According to our initial assumption N = O(2n). Also note that loss of each path in each trial is bounded by B = n. Thus using Theorem 3 we obtain:\nG\u2217 \u2212 E[GDP-EH] = (nT \u2212 L\u2217)\u2212 (nT \u2212 E[LDP-EH]) = E[LDP-EH]\u2212 L\u2217\n= O(n 32 \u221a T )\nNotice that the number of vertices in G\u0304 is O(n2) and each path consists of D = n edges. Therefore using Theorem 4 we obtain:\nG\u2217 \u2212 E[GDP-CH] = (nT \u2212 L\u2217)\u2212 (nT \u2212 E[LDP-CH]) = E[LDP-CH]\u2212 L\u2217\n= O(n (log n) 12 \u221a T )"}, {"heading": "B Generalized Weight Pushing Correctness", "text": "Lemma 5. The weights w(t) E\u0303 generated by the generalized weight pushing satisfies the \u03a6 properties and W (t)\u03c0 \u221d \u220f E\u0303\u2208F (w\u0302 (t) E\u0303 )\u03c0E\u0303 . Moreover, the weights w(t) E\u0303 can be computed in O(|E|) time.\nProof For all v \u2208 V , Zv is defined as the normalization constant if v was the source in G. Concretely, let Pv be the set of all k-multipaths sourced from v and sinking at \u2126. Then:\nZv = \u2211 \u03c0v\u2208Pv W (t\u22121)\u03c0v exp [ \u2212\u03b7\u03c0v \u00b7 `(t) ] For a sink node v \u2208 \u2126, the normalization constant is vacuously 1 since no normalization is needed. For other v \u2208 V \u2212 \u2126, we partition the summation by the starting k-tuple from v:\nZv = \u2211 \u03c0v\u2208Pv W (t\u22121)\u03c0v exp [ \u2212\u03b7\u03c0v \u00b7 `(t) ] = \u2211 E\u0303\u2208Fv \u2211 \u03c0v\u2208Pv\nstarts with E\u0303\nW (t\u22121)\u03c0v exp [ \u2212\u03b7\u03c0v \u00b7 `(t) ]\nNow, we can factor out the weight and exponentiated loss associated with E\u0303 \u2208 Fv . Notice, excluding E\u0303 from the k-multipath, we are left with k number of k-multipaths from all u\u2019s such that (v, u) \u2208 E\u0303:\nZv = \u2211 E\u0303\u2208Fv \u2211 \u03c0v\u2208Pv\nstarts with E\u0303\nW (t\u22121)\u03c0v exp [ \u2212\u03b7\u03c0v \u00b7 `(t) ]\n= \u2211 E\u0303\u2208Fv ( w (t\u22121) E\u0303 )\u03c0E\u0303 exp \u2212\u03b7 \u03c0E\u0303\u2211 e\u2208E\u0303 `(t)e  \ufe38 \ufe37\ufe37 \ufe38\nw\u0302 (t)\nE\u0303\n\u2211 {\u03c0u}u:(v,u)\u2208E\u0303\ns.t.\u2200u\u03c0u\u2208Pu\n\u220f u:(v,u)\u2208E\u0303 W (t\u22121)\u03c0u exp [ \u2212\u03b7\u03c0u \u00b7 `(t) ]\nObserve that since the \u03c0u\u2019s are independent for different u\u2019s, we can turn the sum of products into product of sums:\nZv = \u2211 E\u0303\u2208Fv ( w (t\u22121) E\u0303 )\u03c0E\u0303 exp \u2212\u03b7 \u03c0E\u0303\u2211 e\u2208E\u0303 `(t)e  \ufe38 \ufe37\ufe37 \ufe38\nw\u0302 (t)\nE\u0303\n\u2211 {\u03c0u}u:(v,u)\u2208E\u0303\ns.t.\u2200u\u03c0u\u2208Pu\n\u220f u:(v,u)\u2208E\u0303 W (t\u22121)\u03c0u exp [ \u2212\u03b7\u03c0u \u00b7 `(t) ]\n= \u2211 E\u0303\u2208Fv w\u0302 (t) E\u0303 \u220f u:(v,u)\u2208E\u0303 \u2211 \u03c0u\u2208Pu W (t\u22121)\u03c0u exp [ \u2212\u03b7\u03c0u \u00b7 `(t) ] \ufe38 \ufe37\ufe37 \ufe38\nZu = \u2211 E\u0303\u2208Fv w\u0302 (t) E\u0303 \u220f u:(v,u)\u2208E\u0303 Zu\nNow for each v \u2208 V \u2212 \u2126, for all E\u0303 \u2208 Fv, set w(t)E\u0303 := w\u0302 (t) E\u0303\n\u220f u:(v,u)\u2208E\u0303 Zu\nZv and let W (t)\u03c0 :=\u220f\nE\u0303\u2208F (w (t) E\u0303 )\u03c0E\u0303 . \u03a61 becomes immediately true because of the definition of W (t) \u03c0 . \u03a62 is also\ntrue since: \u2211 E\u0303\u2208Fv w (t) E\u0303 = \u2211 E\u0303\u2208Fv w\u0302 (t) E\u0303 \u220f u:(v,u)\u2208E\u0303 Zu Zv\n= 1\nZv \u2211 E\u0303\u2208Fv w\u0302 (t) E\u0303 \u220f u:(v,u)\u2208E\u0303 Zu\n= 1\nZv \u00d7 Zv = 1\nFor W (t)\u03c0 , we can write :\nW (t)\u03c0 = \u220f E\u0303\u2208F (w (t) E\u0303 )\u03c0E\u0303 = \u220f v\u2208V\u2212\u2126 \u220f E\u0303\u2208Fv (w (t) E\u0303 )\u03c0E\u0303\n= \u220f\nv\u2208V\u2212\u2126 \u220f E\u0303\u2208Fv\n( w\u0302 (t)\nE\u0303\n\u220f u:(v,u)\u2208E\u0303 Zu\nZv\n)\u03c0E\u0303\n=  \u220f v\u2208V\u2212\u2126 \u220f E\u0303\u2208Fv ( w\u0302 (t) E\u0303 )\u03c0E\u0303  \u220f v\u2208V\u2212\u2126 \u220f E\u0303\u2208Fv (\u220f u:(v,u)\u2208E\u0303 Zu Zv )\u03c0E\u0303\nNotice that \u220f v\u2208V\u2212\u2126 \u220f E\u0303\u2208Fv (\u220f u:(v,u)\u2208E\u0303 Zu Zv )\u03c0E\u0303 telescopes along the k-tuples in the k-multipath. Therefore we obtain:\nW (t)\u03c0 =  \u220f v\u2208V\u2212\u2126 \u220f E\u0303\u2208Fv ( w\u0302 (t) E\u0303 )\u03c0E\u0303  \u220f v\u2208V\u2212\u2126 \u220f E\u0303\u2208Fv (\u220f u:(v,u)\u2208E\u0303 Zu Zv )\u03c0E\u0303 =\n\u220f E\u0303\u2208F ( w\u0302 (t) E\u0303 )\u03c0E\u0303 [\u220fv\u2208\u2126 Zv Zs ]\n= 1\nZs \u220f E\u0303\u2208F ( w\u0302 (t) E\u0303 )\u03c0E\u0303\nwhich indicates that W (t)\u03c0 \u221d \u220f E\u0303\u2208F (w\u0302 (t)\nE\u0303 )\u03c0E\u0303 . Finally \u03a63 is true as well because:\u2211\n\u03c0\nW (t)\u03c0 = 1\nZs \u220f E\u0303\u2208F ( w\u0302 (t) E\u0303 )\u03c0E\u0303 = 1\nZs \u00d7 Zs = 1\nRegarding the time complexity, we first focus on the the recurrence relation Zv =\u2211 E\u0303\u2208Fv w\u0302 (t) E\u0303 \u220f u:(v,u)\u2208E\u0303 Zu. Note that for each v \u2208 V , Zv can be computed in O(|Ev|) in which Ev is the set of out-going edges from v. Thus the computation of all Zv\u2019s takes O(|E|) time. Now observe that w(t)\nE\u0303 for each E\u0303 \u2208 F can be found inO(k) time using w(t) E\u0303 = w\u0302 (t) E\u0303\n\u220f u:(v,u)\u2208E\u0303 Zu\nZv . Hence\nthe computation of all w(t) E\u0303 \u2019s takes O(|E|) time since |F| \u00d7 k = |E|. Therefore the generalized weight pushing algorithm runs in O(|E|).\nC Relative Entropy Projection to k-Flow Polytope\nFormally, the projection w of a given point w\u0302 to constraint C is the solution to the following:\narg min w\u2208C \u2211 e\u2208E w log ( we w\u0302e ) + w\u0302e \u2212 we\nC can be three different constraints. We use the method of Lagrange multipliers in all three cases. Observe that if k = 1, then the third constraint is non-existent and the updates in Koolen et. al. [15] are recovered.\nC.1 Root Outflow\nThe outflow from the root r must be k. Assume wr1 , . . . , wrs are the weights associated with the outgoing edges from the root. Then:\nL(w, \u03bb) := \u2211 e\u2208E we log ( we w\u0302e ) + w\u0302e \u2212 we \u2212 \u03bb  s\u2211 j=1 wrj \u2212 k  \u2202L \u2202we = log we w\u0302e = 0 \u2212\u2192 we = w\u0302e \u2200e \u2208 E \u2212 {r1, . . . , rs}\n\u2202L\n\u2202wrj = log wrj w\u0302rj \u2212 \u03bb = 0 \u2212\u2192 wrj = w\u0302rj exp(\u03bb) (11)\n\u2202L \u2202\u03bb = s\u2211 j=1 wrj \u2212 k = 0 (12)\nCombining equations (11) and (12) results in normalizing wr1 , . . . , wrs , that is:\n\u2200j \u2208 [s] wrj = k w\u0302rj\u2211s j\u2032=1 w\u0302rj\u2032\nC.2 k-Flow Preservation at Node v\nGiven any node v other than the root, the out-flow from the node v must be k times of the in-flow of that node. Assume w(in)v1 , . . . , w (in) va and w (out) v1 , . . . , w (out) vb are the weights associated with the\nincoming and outgoing edges from/to the node v, respectively. Then:\nL(w, \u03bb) := \u2211 e\u2208E w log ( we w\u0302e ) + w\u0302e \u2212 we \u2212 \u03bb ( b\u2211 b\u2032=1 w(out)vb\u2032 \u2212 k a\u2211 a\u2032=1 w(in)va\u2032 ) \u2202L \u2202we = log we w\u0302e = 0 \u2212\u2192 we = w\u0302e \u2200e non-adjacent to v\n\u2202L\n\u2202w (out) vb\u2032\n= log w\n(out) vb\u2032 w\u0302 (out) vb\u2032 \u2212 \u03bb = 0 \u2212\u2192 w(out)vb\u2032 = w\u0302 (out) vb\u2032 exp(\u03bb) \u2200b\u2032 \u2208 [b] (13)\n\u2202L\n\u2202w (in) va\u2032\n= log w\n(in) va\u2032 w\u0302 (in) va\u2032 + k\u03bb = 0 \u2212\u2192 w(in)va\u2032 = w\u0302 (in) va\u2032 exp(\u2212k\u03bb) \u2200a\u2032 \u2208 [a] (14)\n\u2202L \u2202\u03bb = b\u2211 b\u2032=1 w(out)vb\u2032 \u2212 k a\u2211 a\u2032=1 w(in)va\u2032 = 0 (15)\nLetting \u03b2 = exp(k), for all a\u2032 \u2208 [a] and all b\u2032 \u2208 [b], we can obtain the following by combining equations (13), (14) and (15):\n\u03b2\n( b\u2211\nb\u2032=1\nw\u0302(out)vb\u2032\n) = k\n\u03b2k\n( a\u2211\na\u2032=1\nw\u0302(in)va\u2032\n) \u2212\u2192 \u03b2 = k+1 \u221a\u221a\u221a\u221ak \u2211aa\u2032=1 w\u0302(in)va\u2032\u2211b b\u2032=1 w\u0302 (out) vb\u2032\nw(out)vb\u2032 = w\u0302 (out) vb\u2032\n( k \u2211a a\u2032\u2032=1 w\u0302\n(in) va\u2032\u2032\u2211b\nb\u2032\u2032=1 w\u0302 (out) vb\u2032\u2032\n) 1 k+1\n, w(in)va\u2032 = w\u0302 (in) va\u2032\n( 1\nk\n\u2211b b\u2032\u2032=1 w\u0302\n(out) vb\u2032\u2032\u2211a\na\u2032\u2032=1 w\u0302 (in) va\u2032\u2032\n) k k+1\nThis indicates that to enforce the k-flow property at each node, the weights must be multiplicatively scaled up/down so that the out- and in-flow will be proportionate to the k-to-1 weighted geometric average of the out- and in-flow, respectively. Concretely:\nout-flow = k \u00d7 in-flow = k+1 \u221a k ( \u0302out-flow)k ( \u0302in-flow)\nC.3 k-Tuple Equality\nLet F be the set of all k-tuples of edges the components of which must have equal weights. For a given tuple J \u2208 F , let w(J)0 , . . . , w (J) k\u22121 be the weights. Assuming j\n\u2212 = j \u2212 1(mod k) and j+ = j + 1(mod k) ,then:\nL(w, \u03bb) := \u2211 e\u2208E we log ( we w\u0302e ) + w\u0302e \u2212 we \u2212 \u2211 J\u2208F k\u22121\u2211 j=0 \u03bb (J) j (w (J) j \u2212 w (J) j\u2212 )\n\u2202L\n\u2202w (J) j\n= log w\n(J) j\nw\u0302 (J) j\n\u2212 \u03bb(J)j + \u03bb (J) j+ = 0 \u2212\u2192 w (J) j = w\u0302 (J) j\ne\u03bb (J) j\ne \u03bb (J) j+\n\u2200j \u2208 {0, 1, . . . , k \u2212 1} (16)\n\u2202L\n\u2202\u03bb (J) j\n= w (J) j \u2212 w (J) j\u2212 = 0 \u2212\u2192 w (J) j = w (J) j\u2212 \u2200j \u2208 {0, 1, . . . , k \u2212 1} (17)\nCombining equations (16) and (17), for all J \u2208 F and for all j \u2208 J , we can obtain:\n( w\n(J) j\n)k = k\u22121\u220f j\u2032=0 w (J) j\u2032 = k\u22121\u220f j\u2032=0 w\u0302 (J) j\u2032 \u2212\u2192 w (J) j = k \u221a\u221a\u221a\u221ak\u22121\u220f j\u2032=0 w\u0302 (J) j\u2032\nwhich basically indicates that each weight must be assigned to the geometric average of the weights in its tuple.\nD CH Regret Bound on k-Multipaths\nProof According to Koolen, Warmuth and Kivinen [15], the regret bound of CH is: E[LCH]\u2212 L\u2217 \u2264 \u221a 2L\u2217\u2206(\u03c0||w(0)) + \u2206(\u03c0||w(0)) (18)\nin which \u03c0 \u2208 N|E| and L\u2217 are the best k-multipath and its loss, respectively. Let w\u0303(0) = 1|V |2 1 in which 1 \u2208 R|E| is a vector of all ones. Now let the initial pointw(0) be the relative entropy projection of w\u0303(0) onto the k-flow prolytope8\nw(0) = arg min w\u2208P \u2206(w||w\u0303(0))\nAssuming \u2016\u03c0\u20161 \u2264 D \u2264 |E|, we obtain:\n\u2206(\u03c0||w(0)) \u2264 \u2206(\u03c0||w\u0303(0)) Pythagorean Theorem = \u2211 e\u2208E \u03c0e log \u03c0e w\u0303 (0) i + w\u0303 (0) i \u2212 \u03c0e\n= \u2211 e\u2208E \u03c0e log 1 w\u0303 (0) i + \u03c0e log \u03c0e + w\u0303 (0) i \u2212 \u03c0e\n\u2264 \u2211 e\u2208E \u03c0e(2 log |V |) + \u2211 e\u2208E \u03c0e log \u03c0e + \u2211 e\u2208E 1 |V |2 \u2212 \u2211 e\u2208E \u03c0e (19)\n\u2264 D(2 log |V |) +D logD + |E| 1 |V |2 \u2212 \u2211 e\u2208E \u03c0e\n\u2264 4D log |V |\nThus, using inequality (18), the regret bound will be: E[LCH]\u2212 L\u2217 \u2264 \u221a 8L\u2217D log |V |+ 4D log |V |\nNote that if \u2016\u03c0\u2016\u221e = 1, then \u2211 e\u2208E \u03c0e log \u03c0e = 0, and consequently, the expression (19) can be bound as below:\n\u2206(\u03c0||w(0)) \u2264 \u2211 e\u2208E \u03c0e(2 log |V |) + \u2211 e\u2208E \u03c0e log \u03c0e + \u2211 e\u2208E 1 |V |2 \u2212 \u2211 e\u2208E \u03c0e\n\u2264 D(2 log |V |) + |E| 1 |V |2 \u2212 \u2211 e\u2208E \u03c0e\n\u2264 2D log |V |\nAgain, using inequality (18), the regret bound will be: E[LCH]\u2212 L\u2217 \u2264 \u221a 4L\u2217D log |V |+ 2D log |V |"}, {"heading": "E Additional Loss with Approximate Projection", "text": "First, let us define the notation . Given two vectors a and b, we say a b iff every element of a is less than or equal b.\nNow let us discuss approximate projection and additional loss. As we are working with in-exact projection, we propose a slightly different prediction algorithm for Component Hedge. Suppose, using iterative Bregman projections, we reached at w\u0302 \u2208 R|F|+ which is -close to the exact projection w \u2208 R|F|+ in 1-norm, that is \u2016w \u2212 w\u0302\u20161 < . Then do the following steps for prediction:\n8This computation can be done as a pre-processing step.\n1. Set w\u0303 := w\u0302 + \u00b7 1 where 1 \u2208 R|F|+ is a vector of all ones. 2. Apply decomposition procedure on w\u0303 and obtain \u03a0. Since w\u0303 does not necessarily belongs\nto the polytope \u03a8, the decomposition \u03a0 will not zero-out all the edges in w\u0303: w\u0303 \u2211 \u03c0\u2208\u03a0 p\u03c0 \u00b7 \u03c0 = w\u0304\n3. Normalize and sample from decomposition \u03a0.\nAccording to the definition, w\u0303 w. Thus w can be subtracted out from w\u0303 in the decomposition and we have w\u0304 w. Therefore:\nw w\u0304 w\u0303 = w\u0302 + \u00b7 1 (20)\nNow let z be the normalization constant for \u03a0. Hence the expected prediction will be w\u0304/z. Note that since w\u0304 w and w \u2208 \u03a8, then z \u2265 1. Also notice that the weights of out-going k-tuple from the source s in w\u0303 are at most 2 greater than the ones in w which belongs to \u03a6. Thus the out-flow at s in w\u0303 is at most k + 2n . Therefore, since w\u0304 w\u0303, we have z \u2264 1 + 2nk . Now we establish a closeness property between the approximate projected vector and the expected prediction vector with approximate projection :\n\u2016w\u0304 z \u2212 w\u0302\u20161 \u2264 \u2016w\u0304 \u2212 w\u0302\u20161 + z \u2212 1 z \u2016w\u0304\u20161\n\u2264 \u2016w\u0304 \u2212 w\u0302\u20161 + 2n\nk \u2016w\u0304\u20161\n\u2264 |F|+ 2n k |F| = |F|(1 + 2n k ) (20)\nNext we establish closeness between the expected prediction vectors in exact and approximate projections:\n\u2016w\u0304 z \u2212w\u20161 \u2264 \u2016 w\u0304 z \u2212 w\u0302\u20161 + \u2016w\u0302 \u2212w\u20161\n\u2264 |F|(1 + 2n k ) + = (1 + |F|+ 2n k |F|)\nNow we can compute the total expected loss using approximate projection:\u2225\u2225\u2225\u2225\u2225 T\u2211 t=1 w\u0304(t) z \u00b7 `(t) \u2225\u2225\u2225\u2225\u2225 1 \u2264 \u2225\u2225\u2225\u2225\u2225 T\u2211 t=1 w(t) \u00b7 `(t) \u2225\u2225\u2225\u2225\u2225 1 + \u2225\u2225\u2225\u2225\u2225 T\u2211 t=1 ( w\u0304(t) z \u2212w(t)) \u00b7 `(t) \u2225\u2225\u2225\u2225\u2225 1\n\u2264 \u2225\u2225\u2225\u2225\u2225 T\u2211 t=1 w(t) \u00b7 `(t) \u2225\u2225\u2225\u2225\u2225\n1\n+ T\u2211 t=1 \u2225\u2225\u2225\u2225w\u0304(t)z \u2212w(t) \u2225\u2225\u2225\u2225 2 \u00b7 \u2225\u2225\u2225`(t)\u2225\u2225\u2225 2\n\u2264 \u2225\u2225\u2225\u2225\u2225 T\u2211 t=1 w(t) \u00b7 `(t) \u2225\u2225\u2225\u2225\u2225\n1\n+ T \u00d7 (1 + |F|+ 2n k |F|)\u00d7\n\u221a |F|\nSetting = 1 T (1+|F|+ 2nk |F|) \u221a |F| we add at most one unit to the expected cumulative loss with exact projection."}], "references": [{"title": "Improved bounds for online learning over the permutahedron and other ranking polytopes", "author": ["Nir Ailon"], "venue": "In AISTATS,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Regret in online combinatorial optimization", "author": ["Jean-Yves Audibert", "S\u00e9bastien Bubeck", "G\u00e1bor Lugosi"], "venue": "Mathematics of Operations Research,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Online linear optimization and adaptive routing", "author": ["Baruch Awerbuch", "Robert Kleinberg"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2008}, {"title": "Legendre functions and the method of random bregman projections", "author": ["Heinz H Bauschke", "Jonathan M Borwein"], "venue": "Journal of Convex Analysis,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1997}, {"title": "The relaxation method of finding the common point of convex sets and its application to the solution of problems in convex programming", "author": ["Lev M Bregman"], "venue": "USSR computational mathematics and mathematical physics,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1967}, {"title": "Introduction to algorithms", "author": ["Thomas H.. Cormen", "Charles Eric Leiserson", "Ronald L Rivest", "Clifford Stein"], "venue": "MIT press Cambridge,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "On-line learning algorithms for path experts with non-additive losses", "author": ["Corinna Cortes", "Vitaly Kuznetsov", "Mehryar Mohri", "Manfred Warmuth"], "venue": "In Conference on Learning Theory,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "The price of bandit information for online optimization", "author": ["Varsha Dani", "Sham M Kakade", "Thomas P Hayes"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2008}, {"title": "A decision-theoretic generalization of on-line learning and an application to boosting", "author": ["Yoav Freund", "Robert E Schapire"], "venue": "Journal of computer and system sciences,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1997}, {"title": "Solving combinatorial games using products, projections and lexicographically optimal bases", "author": ["Swati Gupta", "Michel Goemans", "Patrick Jaillet"], "venue": "arXiv preprint arXiv:1603.00522,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "The on-line shortest path problem under partial monitoring", "author": ["Andr\u00e1s Gy\u00f6rgy", "Tam\u00e1s Linder", "G\u00e1bor Lugosi", "Gy\u00f6rgy Ottucs\u00e1k"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2007}, {"title": "Learning permutations with exponential weights", "author": ["David P Helmbold", "Manfred K Warmuth"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2009}, {"title": "Efficient algorithms for online decision problems", "author": ["Adam Kalai", "Santosh Vempala"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2005}, {"title": "Optimum follow the leader algorithm", "author": ["Dima Kuzmin", "Manfred K Warmuth"], "venue": "In Learning Theory,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2005}, {"title": "The weighted majority algorithm", "author": ["Nick Littlestone", "Manfred K Warmuth"], "venue": "Information and computation,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1994}, {"title": "Weighted automata algorithms. In Handbook of weighted automata, pages 213\u2013254", "author": ["Mehryar Mohri"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "Online decision-making in general combinatorial spaces", "author": ["Arun Rajkumar", "Shivani Agarwal"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Online prediction under submodular constraints", "author": ["Daiki Suehiro", "Kohei Hatano", "Shuji Kijima", "Eiji Takimoto", "Kiyohito Nagano"], "venue": "In International Conference on Algorithmic Learning Theory,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2012}, {"title": "Path kernels and multiplicative updates", "author": ["Eiji Takimoto", "Manfred K Warmuth"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2003}, {"title": "Randomized online pca algorithms with regret bounds that are logarithmic in the dimension", "author": ["Manfred K Warmuth", "Dima Kuzmin"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2008}], "referenceMentions": [{"referenceID": 8, "context": "Our framework allows us to extend online learning algorithms like Hedge [9] and Component Hedge [15] to a significantly wider class of combinatorial objects than was possible before.", "startOffset": 72, "endOffset": 75}, {"referenceID": 19, "context": "Such work includes k-sets [22], permutations [1, 12, 23] and paths [3, 7, 11, 16, 21].", "startOffset": 26, "endOffset": 30}, {"referenceID": 0, "context": "Such work includes k-sets [22], permutations [1, 12, 23] and paths [3, 7, 11, 16, 21].", "startOffset": 45, "endOffset": 56}, {"referenceID": 11, "context": "Such work includes k-sets [22], permutations [1, 12, 23] and paths [3, 7, 11, 16, 21].", "startOffset": 45, "endOffset": 56}, {"referenceID": 2, "context": "Such work includes k-sets [22], permutations [1, 12, 23] and paths [3, 7, 11, 16, 21].", "startOffset": 67, "endOffset": 85}, {"referenceID": 6, "context": "Such work includes k-sets [22], permutations [1, 12, 23] and paths [3, 7, 11, 16, 21].", "startOffset": 67, "endOffset": 85}, {"referenceID": 10, "context": "Such work includes k-sets [22], permutations [1, 12, 23] and paths [3, 7, 11, 16, 21].", "startOffset": 67, "endOffset": 85}, {"referenceID": 13, "context": "Such work includes k-sets [22], permutations [1, 12, 23] and paths [3, 7, 11, 16, 21].", "startOffset": 67, "endOffset": 85}, {"referenceID": 18, "context": "Such work includes k-sets [22], permutations [1, 12, 23] and paths [3, 7, 11, 16, 21].", "startOffset": 67, "endOffset": 85}, {"referenceID": 12, "context": "Follow the Perturbed Leader (FPL) [13] is a simple algorithm which adds random perturbation to the cumulative loss of each component, and then predicts with the combinatorial object with minimum perturbed loss.", "startOffset": 34, "endOffset": 38}, {"referenceID": 9, "context": "to submodular base polytopes [10, 19, 20] are powerful generic techniques which keep track of component-wise weights in the convex hull of the objects for prediction.", "startOffset": 29, "endOffset": 41}, {"referenceID": 16, "context": "to submodular base polytopes [10, 19, 20] are powerful generic techniques which keep track of component-wise weights in the convex hull of the objects for prediction.", "startOffset": 29, "endOffset": 41}, {"referenceID": 17, "context": "to submodular base polytopes [10, 19, 20] are powerful generic techniques which keep track of component-wise weights in the convex hull of the objects for prediction.", "startOffset": 29, "endOffset": 41}, {"referenceID": 8, "context": "This graph representation allows us to extend both standard Hedge algorithm [9, 17] and Component Hedge to wide class of combinatorial objects like BST (see Section 5), Matrix-Chain Multiplication, Knapsack, Rod Cutting, and Weighted Interval Scheduling (see Appendix A).", "startOffset": 76, "endOffset": 83}, {"referenceID": 14, "context": "This graph representation allows us to extend both standard Hedge algorithm [9, 17] and Component Hedge to wide class of combinatorial objects like BST (see Section 5), Matrix-Chain Multiplication, Knapsack, Rod Cutting, and Weighted Interval Scheduling (see Appendix A).", "startOffset": 76, "endOffset": 83}, {"referenceID": 14, "context": "Perhaps the simplest algorithms in online learning are the well-known so-call \u201cexperts algorithms\u201d like the Randomized Weighted Majority [17] or Hedge [9] algorithms.", "startOffset": 137, "endOffset": 141}, {"referenceID": 8, "context": "Perhaps the simplest algorithms in online learning are the well-known so-call \u201cexperts algorithms\u201d like the Randomized Weighted Majority [17] or Hedge [9] algorithms.", "startOffset": 151, "endOffset": 154}, {"referenceID": 18, "context": "1 Learning Paths The online shortest path has been explored both in full information setting [15, 21] and various bandit settings [2, 3, 8, 11].", "startOffset": 93, "endOffset": 101}, {"referenceID": 1, "context": "1 Learning Paths The online shortest path has been explored both in full information setting [15, 21] and various bandit settings [2, 3, 8, 11].", "startOffset": 130, "endOffset": 143}, {"referenceID": 2, "context": "1 Learning Paths The online shortest path has been explored both in full information setting [15, 21] and various bandit settings [2, 3, 8, 11].", "startOffset": 130, "endOffset": 143}, {"referenceID": 7, "context": "1 Learning Paths The online shortest path has been explored both in full information setting [15, 21] and various bandit settings [2, 3, 8, 11].", "startOffset": 130, "endOffset": 143}, {"referenceID": 10, "context": "1 Learning Paths The online shortest path has been explored both in full information setting [15, 21] and various bandit settings [2, 3, 8, 11].", "startOffset": 130, "endOffset": 143}, {"referenceID": 0, "context": "Then, for each edge e \u2208 E, the adversary reveals a loss `e \u2208 [0, 1].", "startOffset": 61, "endOffset": 67}, {"referenceID": 18, "context": "1 Expanded Hedge on Paths Takimoto and Warmuth [21] developed an algorithmic approach, namely path kernels, to apply Expanded Hedge on path problem efficiently by exploiting the underlying structure of the paths.", "startOffset": 47, "endOffset": 51}, {"referenceID": 15, "context": "In each trial, the weight of each edge is updated multiplicatively by its associated exponentiated loss followed by normalization via weight pushing [18].", "startOffset": 149, "endOffset": 153}, {"referenceID": 8, "context": "The regret bound is similar to the one of the Hedge algorithm [9]:", "startOffset": 62, "endOffset": 65}, {"referenceID": 18, "context": "Theorem 1 (Takimoto-Warmuth [21]).", "startOffset": 28, "endOffset": 32}, {"referenceID": 4, "context": "To do projection, iterative Bregman projection [5] is used which basically enforces flow conservation at each node by setting input and output flow to their geometric average as it cycles through the vertices.", "startOffset": 47, "endOffset": 50}, {"referenceID": 0, "context": "Then, for each edge e \u2208 E, the adversary reveals a loss ` e \u2208 [0, 1].", "startOffset": 62, "endOffset": 68}, {"referenceID": 15, "context": "Generalized Weight Pushing For efficient normalization, we generalize the weight pushing algorithm [18] for k-multipaths.", "startOffset": 99, "endOffset": 103}, {"referenceID": 8, "context": "Regret Bound In order to use the regret bound of Expanded Hedge [9], we have to initialize W (0) to the uniform distribution.", "startOffset": 64, "endOffset": 67}, {"referenceID": 4, "context": "To do this projection, iterative Bregman projection [5] can be used which cycles through the constraints and project the point to each constraint iteratively.", "startOffset": 52, "endOffset": 55}, {"referenceID": 5, "context": "Denote V as the set of all subproblems v in dynamic programming which needs to be solved in order to eventually solve P iteratively in bottom-up fashion [6].", "startOffset": 153, "endOffset": 156}, {"referenceID": 0, "context": "Now if the given loss function of the problem is in such way that `e \u2208 [0, 1], we can apply both algorithms CH and EH and their corresponding regret guarantees in Theorems 3 and 4, respectively 5.", "startOffset": 71, "endOffset": 77}, {"referenceID": 5, "context": "Consider the online version of optimal binary search tree problem [6].", "startOffset": 66, "endOffset": 69}, {"referenceID": 0, "context": "Then the adversary reveals the a probability vector ` = (p, q) with p \u2208 [0, 1], q \u2208 [0, 1] and \u2211n i=1 p (t) i + \u2211n i=0 q (t) i = 1.", "startOffset": 72, "endOffset": 78}, {"referenceID": 0, "context": "Then the adversary reveals the a probability vector ` = (p, q) with p \u2208 [0, 1], q \u2208 [0, 1] and \u2211n i=1 p (t) i + \u2211n i=0 q (t) i = 1.", "startOffset": 84, "endOffset": 90}, {"referenceID": 17, "context": "[20] does not apply to this problem as the polytope is not a subset of a simplex, and consequently, cannot be characterized as submodular base polytope.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "Nevertheless, one can apply Follow the Perturbed Leader (FPT) [13] to this problem.", "startOffset": 62, "endOffset": 66}, {"referenceID": 5, "context": "programming [6] with the recurrence relation below:", "startOffset": 12, "endOffset": 15}, {"referenceID": 5, "context": "Regret Bound It is well-known that the number of binary trees with n nodes is the nth Catalan number [6].", "startOffset": 101, "endOffset": 104}, {"referenceID": 11, "context": "In contrast, iterative Bregman projections are often used for algorithms like Component Hedge [12, 15].", "startOffset": 94, "endOffset": 102}, {"referenceID": 3, "context": "These methods are known to converge to the exact projection theoretically [4, 5] and are reported to be empirically very efficient [15].", "startOffset": 74, "endOffset": 80}, {"referenceID": 4, "context": "These methods are known to converge to the exact projection theoretically [4, 5] and are reported to be empirically very efficient [15].", "startOffset": 74, "endOffset": 80}, {"referenceID": 0, "context": "References [1] Nir Ailon.", "startOffset": 11, "endOffset": 14}, {"referenceID": 1, "context": "[2] Jean-Yves Audibert, S\u00e9bastien Bubeck, and G\u00e1bor Lugosi.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] Baruch Awerbuch and Robert Kleinberg.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] Heinz H Bauschke and Jonathan M Borwein.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] Lev M Bregman.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] Thomas H.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] Corinna Cortes, Vitaly Kuznetsov, Mehryar Mohri, and Manfred Warmuth.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] Varsha Dani, Sham M Kakade, and Thomas P Hayes.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] Yoav Freund and Robert E Schapire.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] Swati Gupta, Michel Goemans, and Patrick Jaillet.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] Andr\u00e1s Gy\u00f6rgy, Tam\u00e1s Linder, G\u00e1bor Lugosi, and Gy\u00f6rgy Ottucs\u00e1k.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] David P Helmbold and Manfred K Warmuth.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] Adam Kalai and Santosh Vempala.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[16] Dima Kuzmin and Manfred K Warmuth.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[17] Nick Littlestone and Manfred K Warmuth.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[18] Mehryar Mohri.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[19] Arun Rajkumar and Shivani Agarwal.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[20] Daiki Suehiro, Kohei Hatano, Shuji Kijima, Eiji Takimoto, and Kiyohito Nagano.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[21] Eiji Takimoto and Manfred K Warmuth.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[22] Manfred K Warmuth and Dima Kuzmin.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "Now consider the following online version of matrix-chain multiplication problem [6].", "startOffset": 81, "endOffset": 84}, {"referenceID": 5, "context": "The matrix-chain multiplication problem can be solved via dynamic programming [6] with the recurrence relation below:", "startOffset": 78, "endOffset": 81}, {"referenceID": 5, "context": "Regret Bound It is well-known that the number of full parenthesizing of a sequence of n matrices is the nth Catalan number [6].", "startOffset": 123, "endOffset": 126}, {"referenceID": 0, "context": "Then the adversary reveals a profit vector p \u2208 [0, 1] in which the ith component \u2013 p i \u2013 is the profit of the ith item at trial t.", "startOffset": 47, "endOffset": 53}, {"referenceID": 17, "context": "[20] does not apply to this problem as the polytope is not a subset of a simplex, and consequently, cannot be characterized as submodular base polytope.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "Nevertheless, one can apply Follow the Perturbed Leader (FPT) [13] to this problem.", "startOffset": 62, "endOffset": 66}, {"referenceID": 1, "context": "Figure 4: Example with C = 7 and h = [2, 3, 4].", "startOffset": 37, "endOffset": 46}, {"referenceID": 2, "context": "Figure 4: Example with C = 7 and h = [2, 3, 4].", "startOffset": 37, "endOffset": 46}, {"referenceID": 3, "context": "Figure 4: Example with C = 7 and h = [2, 3, 4].", "startOffset": 37, "endOffset": 46}, {"referenceID": 5, "context": "3 Rod Cutting Consider the online version of rod cutting problem [6].", "startOffset": 65, "endOffset": 68}, {"referenceID": 0, "context": "Then the adversary reveals a price vector p \u2208 [0, 1] in which the ith component \u2013 p i \u2013 is the price of the piece of length i at trial t.", "startOffset": 46, "endOffset": 52}, {"referenceID": 17, "context": "[20] does not apply to this problem as the polytope is not a subset of a simplex, and consequently, cannot be characterized as submodular base polytope.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "Nevertheless, one can apply Follow the Perturbed Leader (FPT) [13] to this problem.", "startOffset": 62, "endOffset": 66}, {"referenceID": 5, "context": "The rod cutting problem can be solved via dynamic programming [6] with the recurrence relation below: OPT(i) = { 0 i = 0 max0\u2264j\u2264i{OPT (j) + p j\u2212i} i > 0 (9)", "startOffset": 62, "endOffset": 65}, {"referenceID": 10, "context": "[11], we can add O(n) vertices and edges (with gain zero) to make all paths equi-length.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "The number of possible cutting is called partition function which is approximately e \u221a /4n \u221a 3 [6].", "startOffset": 95, "endOffset": 98}, {"referenceID": 0, "context": "Then the adversary reveals a profit vector p \u2208 [0, 1] in which the ith component \u2013 p i \u2013 is the profit of including Ii in the scheduling at trial t.", "startOffset": 47, "endOffset": 53}, {"referenceID": 17, "context": "[20] does not apply to this problem as the polytope is not a subset of a simplex, and consequently, cannot be characterized as submodular base polytope.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "Nevertheless, one can apply Follow the Perturbed Leader (FPT) [13] to this problem.", "startOffset": 62, "endOffset": 66}], "year": 2017, "abstractText": "We consider the problem of repeatedly solving a variant of the same dynamic programming problem in successive trials. An instance of the type of problems we consider is to find the optimal binary search tree. At the beginning of each trial, the learner probabilistically chooses a tree with the n keys at the internal nodes and the n+ 1 gaps between keys at the leaves. It is then told the frequencies of the keys and gaps and is charged by the average search cost for the chosen tree. The problem is online because the frequencies can change between trials. The goal is to develop algorithms with the property that their total average search cost (loss) in all trials is close to the total loss of the best tree chosen in hind sight for all trials. The challenge, of course, is that the algorithm has to deal with exponential number of trees. We develop a methodology for tackling such problems for a wide class of dynamic programming algorithms. Our framework allows us to extend online learning algorithms like Hedge [9] and Component Hedge [15] to a significantly wider class of combinatorial objects than was possible before.", "creator": "LaTeX with hyperref package"}}}