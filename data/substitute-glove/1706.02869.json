{"id": "1706.02869", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jun-2017", "title": "Adaptive Consensus ADMM for Distributed Optimization", "abstract": "The layers direction means \u2014 multipliers (ADMM) and type used for reprinted introducing shiny problems, but existing excellent still expertise potential reacted on computer - fundamental equaliser formula_6. We study variety ADMM methods say investment result by using elements same - audiences discrete parameters on each resident basal. We this well O (16 / w) convergence rate for enhancement ADMM involves brought cell - methods parameters, however proposing anti-gravity consensus ADMM (ACADMM ), with using hop parameters without downloaded governmental.", "histories": [["v1", "Fri, 9 Jun 2017 08:52:37 GMT  (410kb,D)", "https://arxiv.org/abs/1706.02869v1", "ICML 2017"], ["v2", "Tue, 20 Jun 2017 05:22:11 GMT  (410kb,D)", "http://arxiv.org/abs/1706.02869v2", "ICML 2017"]], "COMMENTS": "ICML 2017", "reviews": [], "SUBJECTS": "cs.LG cs.NA cs.SY", "authors": ["zheng xu 0002", "gavin taylor", "hao li", "m\u00e1rio a t figueiredo", "xiaoming yuan", "tom goldstein"], "accepted": true, "id": "1706.02869"}, "pdf": {"name": "1706.02869.pdf", "metadata": {"source": "CRF", "title": "Adaptive Consensus ADMM for Distributed Optimization", "authors": ["Zheng Xu", "Gavin Taylor", "Hao Li", "M\u00e1rio A. T. Figueiredo", "Xiaoming Yuan", "Tom Goldstein"], "emails": ["<xuzhustc@gmail.com>."], "sections": [{"heading": "1. Introduction", "text": "The alternating direction method of multipliers (ADMM) is a popular tool for solving problems of the form,\nmin u\u2208Rn,v\u2208Rm f(u) + g(v), subject to Au+Bv = b, (1)\nwhere f : Rn \u2192 R and g : Rm \u2192 R are convex functions, A \u2208 Rp\u00d7n, B \u2208 Rp\u00d7m, and b \u2208 Rp. ADMM was first introduced in (Glowinski & Marroco, 1975) and (Gabay & Mercier, 1976), and has found applications in many optimization problems in machine learning, distributed computing and many other areas (Boyd et al., 2011).\nConsensus ADMM (Boyd et al., 2011) solves minimization problems involving a composite objective f(v) =\u2211 i fi(v), where worker i stores the data needed to compute fi, and so is well suited for distributed model fitting problems (Boyd et al., 2011; Zhang & Kwok, 2014; Song et al., 2016; Chang et al., 2016; Goldstein et al., 2016; Taylor et al., 2016). To distribute this problem, consensus methods assign a separate copy of the unknowns, ui, to\n1University of Maryland, College Park; 2United States Naval Academy, Annapolis; 3Instituto de Telecomunicac\u0327o\u0303es, IST, ULisboa, Portugal; 4Hong Kong Baptist University, Hong Kong. Correspondence to: Zheng Xu <xuzhustc@gmail.com>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\neach worker, and then apply ADMM to solve\nmin ui\u2208Rd,v\u2208Rd N\u2211 i=1 fi(ui) + g(v), subject to ui = v, (2)\nwhere v is the \u201ccentral\u201d copy of the unknowns, and g(v) is a regularizer. The consensus problem (2) coincides with (1) by defining u = (u1; . . . ; uN ) \u2208 RdN , A = IdN \u2208 RdN\u00d7dN , and B = \u2212(Id; . . . ; Id) \u2208 RdN\u00d7d, where Id represents the d\u00d7 d identity matrix.\nADMM methods rely on a penalty parameter (stepsize) that is chosen by the user. In theory, ADMM converges for any constant penalty parameter (Eckstein & Bertsekas, 1992; He & Yuan, 2012; Ouyang et al., 2013). In practice, however, the efficiency of ADMM is highly sensitive to this parameter choice (Nishihara et al., 2015; Ghadimi et al., 2015), and can be improved via adaptive penalty selection methods (He et al., 2000; Song et al., 2016; Xu et al., 2017a).\nOne such approach, residual balancing (RB) (He et al., 2000), adapts the penalty parameter so that the residuals (derivatives of the Lagrangian with respect to primal and dual variables) have similar magnitudes. When the same penalty parameter is used across nodes, RB is known to converge, although without a known rate guarantee. A more recent approach, AADMM (Xu et al., 2017a), achieves impressive practical convergence speed on many applications, including consensus problems, with adaptive penalty parameters by estimating the local curvature of the dual functions. However, the dimension of the unknown variables in consensus problems grows with the number of distributed nodes, causing the curvature estimation to be inaccurate and unstable. AADMM uses the same convergence analysis as RB. Consensus residual balancing (CRB) (Song et al., 2016) extends residual balancing to consensusbased ADMM for distributed optimization by balancing the local primal and dual residuals on each node. However, convergence guarantees for this method are fairly weak, and adaptive penalties need to be reset after several iterations to guarantee convergence.\nWe study the use of adaptive ADMM in the distributed setting, where different workers use different local algorithm parameters to accelerate convergence. We begin by studying the theory and provide convergence guarantees when\nar X\niv :1\n70 6.\n02 86\n9v 2\n[ cs\n.L G\n] 2\n0 Ju\nn 20\n17\nnode-specific penalty parameters are used. We demonstrate a O(1/k) convergence rate under mild conditions that is applicable for many forms of adaptive ADMM including all the above methods. Our theory is more general than the convergence guarantee in (He et al., 2000; Xu et al., 2017a) that only shows convergence when the scalar penalty parameter is adapted. Next, we propose an adaptive consensus ADMM (ACADMM) method to automate local algorithm parameters selection. Instead of estimating one global penalty parameter for all workers, different local penalty parameters are estimated using the local curvature of subproblems on each node."}, {"heading": "2. Related work", "text": "ADMM is known to have aO(1/k) convergence rate under mild conditions for convex problems (He & Yuan, 2012; 2015), while a O(1/k2) rate is possible when at least one of the functions is strongly convex or smooth (Goldfarb et al., 2013; Goldstein et al., 2014; Kadkhodaie et al., 2015; Tian & Yuan, 2016). Linear convergence can be achieved with strong convexity assumptions (Davis & Yin, 2014; Nishihara et al., 2015; Giselsson & Boyd, 2016). All of these results assume constant parameters; to the best of our knowledge, no convergence rate has been proven for ADMM with an adaptive penalty: (He et al., 2000; Xu et al., 2017b) proves convergence without providing a rate, and (Lin et al., 2011; Banert et al., 2016; Goldstein et al., 2015) prove convergence for some particular variants of ADMM (\u201clinearized\u201d or \u201cpreconditioned\u201d).\nTo improve practical convergence of ADMM, fixed optimal parameters are discussed in (Raghunathan & Di Cairano, 2014; Ghadimi et al., 2015; Nishihara et al., 2015; Franc\u0327a & Bento, 2016). These methods make strong assumptions about the objective and require information about the spectrum of A and/or B. Additionally, adaptive methods have been proposed; the most closely related work to our own is (Song et al., 2016), which extends the results of (He et al., 2000) to consensus problems, where communication is controlled by predefined network structure and the regularizer g(v) is absent. In contrast to these methods, the proposed ACADMM extends the spectral penalty in (Xu et al., 2017a) to consensus problems and provides convergence theory that can be applied to a broad range of adaptive ADMM variants."}, {"heading": "3. Consensus ADMM", "text": "In the following, we use the subscript i to denote iterates computed on the ith node, superscript k is the iteration number, \u03bbki is the dual vector of Lagrange multipliers, and {\u03c4ki } are iteration/worker-specific penalty parameters (contrasted with the single constant penalty parameter \u03c4 of\n\u201cvanilla\u201d ADMM). Consensus methods apply ADMM to (2), resulting in the steps\nuk+1i = arg minui fi(ui) + \u03c4ki 2 \u2016vk \u2212 ui + \u03bbki \u03c4ki \u20162 (3)\nvk+1 = arg min v g(v) + N\u2211 i=1 \u03c4ki 2 \u2016v \u2212 uk+1i + \u03bbki \u03c4ki \u20162 (4) \u03bbk+1i = \u03bb k i + \u03c4 k i (v k+1 \u2212 uk+1i ). (5)\nThe primal and dual residuals, rk and dk, are used to monitor convergence.\nrk = r k 1\n... rkN\n , dk = d k 1\n... dkN\n , {rki = vk \u2212 uki dki = \u03c4 k i (v k\u22121 \u2212 vk). (6)\nThe primal residual rk approaches zero when the iterates accurately satisfy the linear constraints in (2), and the dual residual dk approaches zero as the iterates near a minimizer of the objective. Iteration can be terminated when\n\u2016rk\u20162 \u2264 tol max{ \u2211N\ni=1 \u2016uki \u20162, N\u2016vk\u20162} and \u2016dk\u20162 \u2264 tol \u2211N\ni=1 \u2016\u03bbki \u20162,\n(7)\nwhere tol is the stopping tolerance. The residuals in (6) and stopping criterion in (7) are adopted from the general problem (Boyd et al., 2011) to the consensus problem. The observation that residuals rk, dk can be decomposed into \u201clocal residuals\u201d rki , d k i has been exploited to generalize the residual balancing method (He et al., 2000) for distributed consensus problems (Song et al., 2016)."}, {"heading": "4. Convergence analysis", "text": "We now study the convergence of ADMM with nodespecific adaptive penalty parameters. We provide conditions on penalty parameters that guarantee convergence, and also a convergence rate. The issue of how to automatically tune penalty parameters effectively will be discussed in Section 5."}, {"heading": "4.1. Diagonal penalty parameters for ADMM", "text": "Let T k = diag(\u03c4k1 Id, . . . , \u03c4 k NId) be a diagonal matrix containing non-negative penalty parameters on iteration k. Define the norm \u2016u\u20162T = uTTu. Using the notation defined above with u = (u1; . . . ; uN ) \u2208 RdN , we can rewrite the consensus ADMM steps (3)\u2013(5) as\nuk+1 = arg min u f(u) + \u3008\u2212Au, \u03bbk\u3009\n+ 1/2\u2016b\u2212Au\u2212Bvk\u20162Tk (8)\nvk+1 = arg min v g(v) + \u3008\u2212Bv, \u03bbk\u3009\n+ 1/2\u2016b\u2212Auk+1 \u2212Bv\u20162Tk (9)\n\u03bbk+1 = \u03bbk + T k(b\u2212Auk+1 \u2212Bvk+1). (10)\nWhen using a diagonal penalty matrix, the generalized residuals become{\nrk = b\u2212Auk \u2212Buk dk = ATT kB(vk \u2212 vk\u22121). (11)\nThe sequel contains a convergence proof for generalized ADMM with adaptive penalty matrix T k. Our proof is inspired by the variational inequality (VI) approach in (He et al., 2000; He & Yuan, 2012; 2015)."}, {"heading": "4.2. Preliminaries", "text": "Notation. We use the following notation to simplify the discussions. Define the combined variables y = (u; v) \u2208 Rn+m and z = (u; v;\u03bb) \u2208 Rn+m+p, and denote iterates as yk = (uk; vk) and zk = (uk; vk;\u03bbk). Let y\u2217 and z\u2217 denote optimal primal/dual solutions. Further define \u2206z+k = (\u2206u + k ; \u2206v + k ; \u2206\u03bb + k ) := z\nk+1 \u2212 zk and \u2206z\u2217k = (\u2206u\u2217k; \u2206v \u2217 k; \u2206\u03bb \u2217 k) := z \u2217 \u2212 zk. Set\n\u03c6(y) = f(u) + g(v), F (z) =  \u2212AT\u03bb\u2212BT\u03bb Au+Bv \u2212 b  , Hk=\n0 0 00 BTT kB 0 0 0 (T k)\u22121 , Mk= In 0 00 Im 0 0 \u2212T kB Ip . Note that F (z) is a monotone operator satisfying \u2200z, z\u2032, (z \u2212 z\u2032)T (F (z) \u2212 F (z\u2032)) \u2265 0. We introduce intermediate variable z\u0303k+1 = (uk+1; vk+1; \u03bb\u0302k+1), where \u03bb\u0302k+1 = \u03bbk + T k(b\u2212Auk+1 \u2212Bvk). We thus have\n\u2206z+k = M k(z\u0303k+1 \u2212 zk). (12)\nVariational inequality formulation. The optimal solution z\u2217 of problem (1) satisfies the variational inequality (VI),\n\u2200z, \u03c6(y)\u2212 \u03c6(y\u2217) + (z \u2212 z\u2217)TF (z\u2217) \u2265 0. (13)\nFrom the optimality conditions for the sub-steps (8, 9), we see that yk+1 satisfies the variational inequalities\n\u2200u, f(u)\u2212 f(uk+1) + (u\u2212 uk+1)T\n(ATT k(Auk+1 +Bvk \u2212 b)\u2212AT\u03bbk) \u2265 0 (14)\n\u2200v, g(v)\u2212 g(vk+1) + (v \u2212 vk+1)T\n(BTT k(Auk+1 +Bvk+1 \u2212 b)\u2212BT\u03bbk) \u2265 0, (15)\nwhich can be combined as\n\u03c6(y)\u2212 \u03c6(yk+1) + (z \u2212 z\u0303k+1)T ( F (z\u0303k+1) +Hk\u2206z+k ) \u2265 0. (16)\nLemmas. We present several lemmas to facilitate the proof of our main convergence theory, which extend previous results regarding ADMM (He & Yuan, 2012; 2015) to ADMM with a diagonal penalty matrix. Lemma 1 shows the difference between iterates decreases as the iterates approach the true solution, while Lemma 2 implies a contraction in the VI sense. Full proofs are provided in supplementary material; Eq. (17) and Eq. (18) are supported using equations (13, 15, 16) and standard techniques, while Eq. (19) is proven from Eq. (18). Lemma 2 is supported by the relationship in Eq. (12). Lemma 1. The optimal solution z\u2217 = (u\u2217; v\u2217;\u03bb\u2217) and sequence zk = (uk; vk;\u03bbk) of generalized ADMM satisfy\n(B\u2206v+k ) T\u2206\u03bb+k \u2265 0, (17) \u2206z\u2217k+1H k\u2206z+k \u2265 0, (18)\n\u2016\u2206z+k \u2016 2 Hk \u2264 \u2016\u2206z \u2217 k\u20162Hk \u2212 \u2016\u2206z \u2217 k+1\u20162Hk . (19)\nLemma 2. The sequence z\u0303k = (uk; vk; \u03bb\u0302k) and zk = (uk; vk;\u03bbk)T from generalized ADMM satisfy, \u2200z,\n(z\u0303k+1\u2212z)THk\u2206z+k \u2265 1\n2 (\u2016zk+1\u2212z\u20162Hk\u2212\u2016z k\u2212z\u20162Hk ). (20)"}, {"heading": "4.3. Convergence criteria", "text": "We provide a convergence analysis of ADMM with an adaptive diagonal penalty matrix by showing (i) the norm of the residuals converges to zero; (ii) the method attains a worst-case ergodic O(1/k) convergence rate in the VI sense. The key idea of the proof is to bound the adaptivity of T k so that ADMM is stable enough to converge, which is presented as the following assumption. Assumption 1. The adaptivity of the diagonal penalty matrix T k = diag(\u03c4ki , . . . , \u03c4 k p ) is bounded by\n\u221e\u2211 k=1 (\u03b7k)2 <\u221e, where (\u03b7k)2 = max i\u2208{1,...,p} {(\u03b7ki )2},\n(\u03b7ki ) 2 = max{\u03c4ki /\u03c4k\u22121i \u2212 1, \u03c4 k\u22121 i /\u03c4 k i \u2212 1}.\n(21)\nWe can apply Assumption 1 to verify that\n1 1 + (\u03b7k)2 \u2264 \u03c4\nk i\n\u03c4k\u22121i \u2264 1 + (\u03b7k)2. (22)\nwhich is needed to prove Lemma 3. Lemma 3. Suppose Assumption 1 holds. Then z = (u; v; \u03bb) and z\u2032 = (u\u2032; v\u2032; \u03bb\u2032) satisfy, \u2200z, z\u2032\n\u2016z \u2212 z\u2032\u20162Hk \u2264 (1 + (\u03b7 k)2)\u2016z \u2212 z\u2032\u20162Hk\u22121 . (23)\nNow we are ready to prove the convergence of generalized ADMM with adaptive penalty under Assumption 1. We prove the following quantity, which is a norm of the residuals, converges to zero.\n\u2016\u2206z+k \u2016 2 Hk =\u2016B\u2206v + k \u2016 2 Tk + \u2016\u2206\u03bb + k \u2016 2 (Tk)\u22121\n=\u2016(ATT k)\u2020dk\u20162Tk + \u2016r k\u20162Tk ,\n(24)\nwhere A\u2020 denotes generalized inverse of a matrix A. Note that \u2016\u2206z+k \u20162Hk converges to zero only if \u2016r\nk\u2016 and \u2016dk\u2016 converge to zero, provided A and T k are bounded.\nTheorem 1. Suppose Assumption 1 holds. Then the iterates zk = (uk; vk;\u03bbk) of generalized ADMM satisfy\nlim k\u2192\u221e\n\u2016\u2206z+k \u2016 2 Hk = 0. (25)\nProof. Let z = zk, z\u2032 = z\u2217 in Lemma 3 to achieve\n\u2016\u2206z\u2217k\u20162Hk \u2264 (1 + (\u03b7 k)2)\u2016\u2206z\u2217k\u20162Hk\u22121 . (26)\nCombine (26) with Lemma 1 (19) to get\n\u2016\u2206z+k \u2016 2 Hk \u2264 (1+(\u03b7 k)2)\u2016\u2206z\u2217k\u20162Hk\u22121\u2212\u2016\u2206z \u2217 k+1\u20162Hk . (27)\nAccumulate (27) for k = 1 to l,\nl\u2211 k=1 l\u220f t=k+1 (1 + (\u03b7t)2)\u2016\u2206z+k \u2016 2 Hk \u2264\nl\u220f t=1 (1 + (\u03b7t)2)\u2016\u2206z\u22171\u20162H0 \u2212 \u2016\u2206z\u2217l+1\u20162Hl .\n(28)\nThen we have\nl\u2211 k=1 \u2016\u2206z+k \u2016 2 Hk \u2264 l\u220f t=1 (1 + (\u03b7t)2)\u2016\u2206z\u22171\u20162H0 . (29)\nWhen l \u2192 \u221e, Assumption 1 suggests \u220f\u221e t=1(1 +\n(\u03b7t)2) < \u221e, which means \u2211\u221e k=1 \u2016\u2206z + k \u20162Hk < \u221e. Hence limk\u2192\u221e \u2016\u2206z+k \u20162Hk = 0.\nWe further exploit Assumption 1 and Lemma 3 to prove Lemma 4, and combine VI (16), Lemma 2, and Lemma 4 to prove the O(1/k) convergence rate in Theorem 2.\nLemma 4. Suppose Assumption 1 holds. Then z = (u; v;\u03bb) \u2208 Rm+n+p and the iterates zk = (uk; vk;\u03bbk) of generalized ADMM satisfy, \u2200z\nl\u2211 k=1 (\u2016z \u2212 zk\u20162Hk \u2212 \u2016z \u2212 z k\u20162Hk\u22121) \u2264\nC\u03a3\u03b7 C \u03a0 \u03b7 (\u2016z \u2212 z\u2217\u20162H0 + \u2016\u2206z\u22171\u20162H0) <\u221e,\n(30)\nwhere C\u03a3\u03b7 = \u2211\u221e k=1(\u03b7 k)2, C\u03a0\u03b7 = \u220f\u221e t=1(1 + (\u03b7 t)2).\nTheorem 2. Suppose Assumption 1 holds. Consider the sequence z\u0303k = (uk; vk; \u03bb\u0302k) of generalized ADMM and define z\u0304l = 1l \u2211l k=1 z\u0303\nk.Then sequence z\u0304l satisfies the convergence bound\n\u03c6(y)\u2212 \u03c6(y\u0304l) + (z \u2212 z\u0304l)TF (z\u0304l) \u2265 \u2212 1 2 l (\u2016z \u2212 z0\u20162H0\n+ C\u03a3\u03b7 C \u03a0 \u03b7 \u2016z \u2212 z\u2217\u20162H0 + C\u03a3\u03b7 C\u03a0\u03b7 \u2016\u2206z\u22171\u20162H0). (31)\nProof. We can verify with simple algebra that\n(z \u2212 z\u2032)TF (z) = (z \u2212 z\u2032)TF (z\u2032). (32)\nApply (32) with z\u2032 = z\u0303k+1, and combine VI (16) and Lemma 2 to get\n\u03c6(y)\u2212 \u03c6(yk+1) + (z \u2212 z\u0303k+1)TF (z) (33) =\u03c6(y)\u2212 \u03c6(yk+1) + (z \u2212 z\u0303k+1)TF (z\u0303k+1) (34) \u2265(z\u0303k+1 \u2212 z)THk\u2206z+k (35) \u22651 2 (\u2016zk+1 \u2212 z\u20162Hk \u2212 \u2016z k \u2212 z\u20162Hk). (36)\nSumming for k = 0 to l \u2212 1 gives us\u2211l k=1 \u03c6(y)\u2212 \u03c6(yk) + (z \u2212 z\u0303k)TF (z)\n\u22651 2 \u2211l k=1 (\u2016z \u2212 zk\u20162Hk\u22121 \u2212 \u2016z \u2212 z k\u22121\u20162Hk\u22121). (37)\nSince \u03c6(y) is convex, the left hand side of (37) satisfies,\nLHS = l \u03c6(y)\u2212 l\u2211\nk=1\n\u03c6(yk) + (l z \u2212 l\u2211\nk=1\nz\u0303k)TF (z)\n\u2264 l \u03c6(y)\u2212 l \u03c6(y\u0304l) + (l z \u2212 l z\u0304l)TF (z). (38)\nApplying Lemma 4, we see the right hand side satisfies,\nRHS = 1\n2 l\u2211 k=1 (\u2016z \u2212 zk\u20162Hk \u2212 \u2016z \u2212 z k\u22121\u20162Hk\u22121)+\n1\n2 l\u2211 k=1 (\u2016z \u2212 zk\u20162Hk\u22121 \u2212 \u2016z \u2212 z k\u20162Hk)\n(39)\n\u22651 2 (\u2016z \u2212 zl\u20162Hl \u2212 \u2016z \u2212 z 0\u20162H0)+\n\u2212 1 2 C\u03a3\u03b7 C \u03a0 \u03b7 (\u2016z \u2212 z\u2217\u20162H0 + \u2016\u2206z\u22171\u20162H0)\n(40)\n\u2265\u2212 1 2 (\u2016z \u2212 z0\u20162H0 + C\u03a3\u03b7 C\u03a0\u03b7 \u2016z \u2212 z\u2217\u20162H0+\nC\u03a3\u03b7 C \u03a0 \u03b7 \u2016\u2206z\u22171\u20162H0).\n(41)\nCombining inequalities (37), (38) and (41), and letting z\u2032 = z\u0304k in (32) yields the O(1/k) convergence rate in (31)"}, {"heading": "5. Adaptive Consensus ADMM (ACADMM)", "text": "To address the issue of how to automatically tune parameters on each node for optimal performance, we propose adaptive consensus ADMM (ACADMM), which sets worker-specific penalty parameters by exploiting curvature information. We derive our method from the dual interpretation of ADMM \u2013 Douglas-Rachford splitting (DRS) \u2013 using a diagonal penalty matrix. We then derive the spectral stepsizes for consensus problems by assuming the curvatures of the objectives are diagonal matrices with diverse parameters on different nodes. At last, we discuss the practical computation of the spectral stepsizes from consensus ADMM iterates and apply our theory in Section 4 to guarantee convergence."}, {"heading": "5.1. Dual interpretation of generalized ADMM", "text": "The dual form of problem (1) can be written\nmin \u03bb\u2208Rp f\u2217(AT\u03bb)\u2212 \u3008\u03bb, b\u3009\ufe38 \ufe37\ufe37 \ufe38 f\u0302(\u03bb) + g\u2217(BT\u03bb)\ufe38 \ufe37\ufe37 \ufe38 g\u0302(\u03bb) , (42)\nwhere \u03bb denotes the dual variable, while f\u2217, g\u2217 denote the Fenchel conjugate of f, g (Rockafellar, 1970). It is known that ADMM steps for the primal problem (1) are equivalent to performing Douglas-Rachford splitting (DRS) on the dual problem (42) (Eckstein & Bertsekas, 1992; Xu et al., 2017a). In particular, the generalized ADMM iterates satisfy the DRS update formulas\n0 \u2208 (T k)\u22121(\u03bb\u0302k+1 \u2212 \u03bbk) + \u2202f\u0302(\u03bb\u0302k+1) + \u2202g\u0302(\u03bbk) (43)\n0 \u2208 (T k)\u22121(\u03bbk+1 \u2212 \u03bbk) + \u2202f\u0302(\u03bb\u0302k+1) + \u2202g\u0302(\u03bbk+1), (44)\nwhere \u03bb\u0302 denotes the intermediate variable defined in Section 4.2. We prove the equivalence of generalized ADMM and DRS in the supplementary material."}, {"heading": "5.2. Generalized spectral stepsize rule", "text": "Xu et al. (2017a) first derived spectral penalty parameters for ADMM using the DRS. Proposition 1 in (Xu et al., 2017a) proved that the minimum residual of DRS can be obtained by setting the scalar penalty to \u03c4k = 1/ \u221a \u03b1\u03b2, where we assume the subgradients are locally linear as\n\u2202f\u0302(\u03bb\u0302) = \u03b1 \u03bb\u0302+ \u03a8 and \u2202g\u0302(\u03bb) = \u03b2 \u03bb+ \u03a6, (45)\n\u03b1, \u03b2 \u2208 R represent scalar curvatures, and \u03a8,\u03a6 \u2282 Rp.\nWe now present generalized spectral stepsize rules that can accomodate consensus problems.\nProposition 1 (Generalized spectral DRS). Suppose the generalized DRS steps (43, 44) are used, and assume the subgradients are locally linear,\n\u2202f\u0302(\u03bb\u0302) = M\u03b1 \u03bb\u0302+ \u03a8 and \u2202g\u0302(\u03bb) = M\u03b2 \u03bb+ \u03a6. (46)\nfor matrices M\u03b1 = diag(\u03b11Id, . . . , \u03b1NId) and M\u03b2 = diag(\u03b21Id, . . . , \u03b2NId), and some \u03a8,\u03a6 \u2282 Rp. Then the minimal residual of f\u0302(\u03bbk+1) + g\u0302(\u03bbk+1) is obtained by setting \u03c4ki = 1/ \u221a \u03b1i \u03b2i, \u2200i = 1, . . . , N .\nProof. Substituting subgradients \u2202f\u0302(\u03bb\u0302), \u2202g\u0302(\u03bb) into the generalized DRS steps (43, 44), and using our linear assumption (46) yields\n0 \u2208 (T k)\u22121(\u03bb\u0302k+1 \u2212 \u03bbk) + (M\u03b1 \u03bb\u0302k+1 + \u03a8) + (M\u03b2 \u03bbk + \u03a6) 0 \u2208 (T k)\u22121(\u03bbk+1 \u2212 \u03bbk) + (M\u03b1 \u03bb\u0302k+1 + \u03a8) + (M\u03b2 \u03bbk+1 + \u03a6).\nSince T k,M\u03b1,M\u03b2 are diagonal matrices, we can split the equations into independent blocks, \u2200i = 1, . . . , N,\n0 \u2208 (\u03bb\u0302k+1i \u2212 \u03bb k i )/\u03c4 k i + (\u03b1i \u03bb\u0302 k+1 + \u03a8i) + (\u03b2i \u03bb k + \u03a6i) 0 \u2208 (\u03bbk+1i \u2212 \u03bb k i )/\u03c4 k i + (\u03b1i \u03bb\u0302 k+1 + \u03a8i) + (\u03b2i \u03bb k+1 + \u03a6i).\nApplying Proposition 1 in (Xu et al., 2017a) to each block, \u03c4ki = 1/ \u221a \u03b1i \u03b2i minimizes the block residual represented by rk+1DR,i = \u2016(\u03b1i + \u03b2i)\u03bbk+1 + (ai + bi)\u2016, where ai \u2208 \u03a8i, bi \u2208 \u03a6i. Hence the residual norm at step k + 1, which is \u2016(M\u03b1 + M\u03b2)\u03bbk+1 + (a + b)\u2016 = \u221a\u2211N i=1(r k+1 DR,i) 2 is minimized by setting \u03c4ki = 1/ \u221a \u03b1i \u03b2i, \u2200i = 1, . . . , N ."}, {"heading": "5.3. Stepsize estimation for consensus problems", "text": "Thanks to the equivalence of ADMM and DRS, Proposition 1 can also be used to guide the selection of the \u201coptimal\u201d penalty parameter. We now show that the generalized spectral stepsizes can be estimated from the ADMM iterates for the primal consensus problem (2), without explicitly supplying the dual functions.\nThe subgradients of dual functions \u2202f\u0302 , \u2202g\u0302 can be computed from the ADMM iterates using the identities derived from (8, 9),\nAuk+1 \u2212 b \u2208 \u2202f\u0302(\u03bb\u0302k+1) and Bvk+1 \u2208 \u2202g\u0302(\u03bbk+1). (47)\nFor the consensus problem we have A = IdN , B = \u2212(Id; . . . ; Id), and b = 0, and so\n(uk+11 ; . . . ; u k+1 N ) \u2208 \u2202f\u0302(\u03bb\u0302 k+1) (48)\n\u2212(vk+1; . . . ; vk+1\ufe38 \ufe37\ufe37 \ufe38 N duplicates of vk+1 ) \u2208 \u2202g\u0302(\u03bbk+1). (49)\nIf we approximate the behavior of these sub-gradients using the linear approximation (46), and break the subgradients into blocks (one for each worker node), we get (omitting iteration index k for clarity)\nui = \u03b1i \u03bb\u0302i + ai and \u2212 v = \u03b2i \u03bbi + bi, \u2200i (50)\nwhere \u03b1i and \u03b2i represent the curvature of local functions f\u0302i and g\u0302i on the ith node.\nWe select stepsizes with a two step procedure, which follows the spectral stepsize literature. First, we estimate the local curvature parameters, \u03b1i and \u03b2i, by finding leastsquares solutions to (50). Second, we plug these curvature estimates into the formula \u03c4ki = 1/ \u221a \u03b1i \u03b2i. This formula produces the optimal stepsize when f\u0302 and g\u0302 are well approximated by a linear function, as shown in Proposition 1.\nFor notational convenience, we work with the quantities \u03b1\u0302ki = 1/\u03b1i, \u03b2\u0302 k i = 1/\u03b2i, which are estimated on each node using the current iterates uki , v k, \u03bbki , \u03bb\u0302 k i and also an older iterate uk0i , v k0 , \u03bbk0i , \u03bb\u0302 k0 i , k0 < k. Defining \u2206u k i = uki \u2212 u k0 i , \u2206\u03bb\u0302 k i = \u03bb\u0302 k i \u2212 \u03bb\u0302 k0 i and following the literature for Barzilai-Borwein/spectral stepsize estimation, there are two least squares estimators that can be obtained from (50):\n\u03b1\u0302kSD,i = \u3008\u2206\u03bb\u0302ki ,\u2206\u03bb\u0302ki \u3009 \u3008\u2206uki ,\u2206\u03bb\u0302ki \u3009 and \u03b1\u0302kMG,i = \u3008\u2206uki ,\u2206\u03bb\u0302k\u3009 \u3008\u2206uki ,\u2206uki \u3009 (51)\nwhere SD stands for steepest descent, and MG stands for minimum gradient. (Zhou et al., 2006) recommend using a hybrid of these two estimators, and choosing\n\u03b1\u0302ki =\n{ \u03b1\u0302kMG,i if 2 \u03b1\u0302 k MG,i > \u03b1\u0302 k SD,i\n\u03b1\u0302kSD,i \u2212 \u03b1\u0302kMG,i/2 otherwise. (52)\nIt was observed that this choice worked well for nondistributed ADMM in (Xu et al., 2017a). We can similarly estimate \u03b2\u0302ki from \u2206v k = \u2212vk + vk0 and \u2206\u03bbki = \u03bbki \u2212\u03bb k0 i .\nACADMM estimates the curvatures in the original ddimensional feature space, and avoids estimating the curvature in the higher Nd-dimensional feature space (which grows with the number of nodes N in AADMM (Xu et al., 2017a)), which is especially useful for heterogeneous data with different distributions allocated to different nodes. The overhead of our adaptive scheme is only a few inner products, and the computation is naturally distributed on different workers."}, {"heading": "5.4. Safeguarding and convergence", "text": "Spectral stepsizes for gradient descent methods are equipped with safeguarding strategies like backtracking line search to handle inaccurate curvature estimation and to guarantee convergence. To safeguard the proposed spectral penalty parameters, we check whether our linear subgradient assumption is reasonable before updating the stepsizes. We do this by testing that the correlations\n\u03b1kcor,i = \u3008\u2206uki ,\u2206\u03bb\u0302ki \u3009 \u2016\u2206uki \u2016 \u2016\u2206\u03bb\u0302ki \u2016 and \u03b2kcor,i = \u3008\u2206vk,\u2206\u03bbki \u3009 \u2016\u2206vk\u2016 \u2016\u2206\u03bbki \u2016 , (53)\nare bounded away from zero by a fixed threshold. We also bound changes in the penalty parameter by (1 +Ccg/k2) according to Assumption 1, which was shown in Theorem 1\nAlgorithm 1 Adaptive consensus ADMM (ACADMM)\nInput: initialize v0, \u03bb0i , \u03c40i , k0 =0, 1: while not converge by (7) and k < maxiter do 2: Locally update uki on each node by (3) 3: Globally update vk on central server by (4) 4: Locally update dual variable \u03bbki on each node by (5) 5: if mod(k, Tf ) = 1 then 6: Locally update \u03bb\u0302ki = \u03bb k\u22121 i + \u03c4 k i (v\nk\u22121 \u2212 uki ) 7: Locally compute spectral stepsizes \u03b1\u0302ki , \u03b2\u0302 k i 8: Locally estimate correlations \u03b1kcor,i , \u03b2 k cor,i\n9: Locally update \u03c4k+1i using (54) 10: k0 \u2190 k 11: else 12: \u03c4k+1i \u2190 \u03c4ki 13: end if 14: k \u2190 k + 1 15: end while\nand Theorem 2 to guarantee convergence. The final safeguarded ACADMM rule is\n\u03c4\u0302k+1i =  \u221a \u03b1\u0302ki \u03b2\u0302 k i if \u03b1 k cor,i > cor and \u03b2kcor,i > cor \u03b1\u0302ki if \u03b1 k cor,i > cor and \u03b2kcor,i \u2264 cor \u03b2\u0302ki if \u03b1 k cor,i \u2264 cor and \u03b2kcor,i > cor\n\u03c4ki otherwise,\n\u03c4k+1i = max{min{\u03c4\u0302 k+1 i , (1 + Ccg k2 )\u03c4ki } , \u03c4ki 1 + Ccg/k2 }.\n(54)\nThe complete adaptive consensus ADMM is shown in Algorithm 1. We suggest updating the stepsize every Tf = 2 iterations, fixing the safeguarding threshold cor = 0.2, and choosing a large convergence constant Ccg = 1010."}, {"heading": "6. Experiments & Applications", "text": "We now study the performance of ACADMM on benchmark problems, and compare to other methods."}, {"heading": "6.1. Applications", "text": "Our experiments use the following test problems that are commonly solved using consensus methods.\nLinear regression with elastic net regularizer. We consider consensus formulations of the elastic net (Zou & Hastie, 2005) with fi and g defined as,\nfi(ui) = 1\n2 \u2016Diui \u2212 ci\u20162, g(v) = \u03c11|v|+ \u03c12 2 \u2016v\u20162, (55)\nwhere Di \u2208 Rni\u00d7m is the data matrix on node i, and ci is a vector of measurements.\nSparse logistic regression with `1 regularizer can be written in the consensus form for distributed computing,\nfi(ui) = ni\u2211 j=1 log(1 + exp(\u2212ci,jDTi,jui)), g(v) = \u03c1|v| (56)\nwhere Di,j \u2208 Rm is the jth sample, and ci,j \u2208 {\u22121, 1} is the corresponding label. The minimization sub-step (3) in this case is solved by L-BFGS (Liu & Nocedal, 1989).\nSupport Vector Machines (SVMs) minimize the distributed objective function (Goldstein et al., 2016)\nfi(ui) = C ni\u2211 j=1 max{1\u2212 ci,jDTi,jui, 0}, g(v) = 1 2 \u2016v\u201622 (57)\nwhere Di,j \u2208 Rm is the jth sample on the ith node, and ci,j \u2208 {\u22121, 1} is its label. The minimization (3) is solved by dual coordinate ascent (Chang & Lin, 2011).\nSemidefinite programming (SDP) can be distributed as,\nfi(Ui) = \u03b9{Di(Ui) = ci}, g(v) = \u3008F, V \u3009+ \u03b9{V 0} (58)\nwhere \u03b9{S} is a characteristic function that is 0 if condition S is satisfied and infinity otherwise. V 0 indicates that V is positive semidefinite. V, F, Di,j \u2208 Rn\u00d7n are symmetric matrices, \u3008X,Y \u3009 = trace(XTY ) denotes the inner product of X and Y , and Di(X) = (\u3008Di,1, X\u3009; . . . ; \u3008Di,mi , X\u3009)."}, {"heading": "6.2. Experimental Setup", "text": "We test the problems in Section 6.1 with synthetic and real datasets. The number of samples and features are specified in Table 1. Synthetic1 contains samples from a normal distribution, and Synthetic2 contains samples from a\nmixture of 10 random Gaussians. Synthetic2 is heterogeneous because the data block on each individual node is sampled from only 1 of the 10 Gaussians. We also acquire large empirical datasets from the LIBSVM webpage (Liu et al., 2009), as well as MNIST digital images (LeCun et al., 1998), and CIFAR10 object images (Krizhevsky & Hinton, 2009). For binary classification tasks (SVM and logreg), we equally split the 10 category labels of MNIST and CIFAR into \u201cpositive\u201d and \u201cnegative\u201d groups. We use a graph from the Seventh DIMACS Implementation Challenge on Semidefinite and Related Optimization Problems following (Burer & Monteiro, 2003) for Semidefinite Programming (SDP). The regularization parameter is fixed at \u03c1 = 10 in all experiments.\nConsensus ADMM (CADMM) (Boyd et al., 2011), residual balancing (RB-ADMM) (He et al., 2000), adaptive ADMM (AADMM) (Xu et al., 2017a), and consensus residual balancing (CRB-ADMM) (Song et al., 2016) are implemented and reported for comparison. Hyperparameters of these methods are set as suggested by their creators. The initial penalty is fixed at \u03c40 = 1 for all methods unless otherwise specified."}, {"heading": "6.3. Convergence results", "text": "Table 1 reports the convergence speed in iterations and wall-clock time (secs) for various test cases. These experiments are performed with 128 cores on a Cray XC-30 supercomputer. CADMM with default penalty \u03c4 = 1 (Boyd et al., 2011) is often slow to converge. ACADMM outperforms the other ADMM variants on all the real-world\ndatasets, and is competitive with AADMM on two homogeneous synthetic datasets where the curvature may be globally estimated with a scalar.\nACADMM is more reliable than AADMM since the curvature estimation becomes difficult for high dimensional variables. RB is relatively stable but sometimes has difficulty finding the exact optimal penalty, as the adaptation can stop because the difference of residuals are not significant enough to trigger changes. RB does not change the initial penalty in several experiments such as logistic regression on RCV1. CRB achieves comparable results with RB, which suggests that the relative sizes of local residuals may not always be very informative. ACADMM significantly boosts AADMM and the local curvature estimations are helpful in practice."}, {"heading": "6.4. Robustness and sensitivity", "text": "Fig. 1a shows that the practical convergence of ADMM is sensitive to the choice of penalty parameter. ACADMM is robust to the selection of the initial penalty parameter and achieves promising results for both homogeneous and heterogeneous data, comparable to ADMM with a fine-tuned penalty parameter.\nWe study scalability of the method by varying the number of workers and training samples (Fig. 1b). ACADMM is fairly robust to the scaling factor. AADMM occasion-\nally performs well when small numbers of nodes are used, while ACADMM is much more stable. RB and CRB are more stable than AADMM, but cannot compete with ACADMM. Fig. 1c (bottom) presents the acceleration in (wall-clock secs) achieved by increasing the number of workers.\nFinally, ACADMM is insensitive to the safeguarding hyper-parameters, correlation threshold cor and convergence constant Ccg. Though tuning these parameters may further improve the performance, the fixed default values generally perform well in our experiments and enable ACADMM to run without user oversight. In further experiments in the supplementary material, we also show that ACADMM is fairly insensitive to the regularization parameter \u03c1 in our classification/regression models."}, {"heading": "7. Conclusion", "text": "We propose ACADMM, a fully automated algorithm for distributed optimization. Numerical experiments on various applications and real-world datasets demonstrate the efficiency and robustness of ACADMM. We also prove a O(1/k) convergence rate for ADMM with adaptive penalties under mild conditions. By automating the selection of algorithm parameters, adaptive methods make distributed systems more reliable, and more accessible to users that lack expertise in optimization."}, {"heading": "Acknowledgements", "text": "ZX , GT, HL and TG were supported by the US Office of Naval Research under grant N00014-17-1-2078 and by the US National Science Foundation (NSF) under grant CCF1535902. GT was partially supported by the DOD High Performance Computing Modernization Program. MF was partially supported by the Fundac\u0327a\u0303o para a Cie\u0302ncia e Tecnologia, grant UID/EEA/5008/2013. XY was supported by the General Research Fund from Hong Kong Research Grants Council under grant HKBU-12313516."}], "references": [{"title": "Fixing and extending some recent results on the admm algorithm", "author": ["Banert", "Sebastian", "Bot", "Radu Ioan", "Csetnek", "Ern\u00f6 Robert"], "venue": "arXiv preprint arXiv:1612.05057,", "citeRegEx": "Banert et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Banert et al\\.", "year": 2016}, {"title": "Distributed optimization and statistical learning via the alternating direction method of multipliers", "author": ["Boyd", "Stephen", "Parikh", "Neal", "Chu", "Eric", "Peleato", "Borja", "Eckstein", "Jonathan"], "venue": "Found. and Trends in Mach. Learning,", "citeRegEx": "Boyd et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Boyd et al\\.", "year": 2011}, {"title": "A nonlinear programming algorithm for solving semidefinite programs via low-rank factorization", "author": ["Burer", "Samuel", "Monteiro", "Renato DC"], "venue": "Mathematical Programming,", "citeRegEx": "Burer et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Burer et al\\.", "year": 2003}, {"title": "LIBSVM: a library for support vector machines", "author": ["Chang", "Chih-Chung", "Lin", "Chih-Jen"], "venue": "ACM Transactions on Intelligent Systems and Technology (TIST),", "citeRegEx": "Chang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chang et al\\.", "year": 2011}, {"title": "Asynchronous distributed alternating direction method of multipliers: Algorithm and convergence analysis", "author": ["Chang", "Tsung-Hui", "Hong", "Mingyi", "Liao", "Wei-Cheng", "Wang", "Xiangfeng"], "venue": "In 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "Chang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Chang et al\\.", "year": 2016}, {"title": "Faster convergence rates of relaxed peaceman-rachford and admm under regularity assumptions", "author": ["Davis", "Damek", "Yin", "Wotao"], "venue": "arXiv preprint arXiv:1407.5210,", "citeRegEx": "Davis et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Davis et al\\.", "year": 2014}, {"title": "On the Douglas-Rachford splitting method and the proximal point algorithm for maximal monotone operators", "author": ["Eckstein", "Jonathan", "Bertsekas", "Dimitri"], "venue": "Mathematical Programming,", "citeRegEx": "Eckstein et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Eckstein et al\\.", "year": 1992}, {"title": "An explicit rate bound for over-relaxed admm", "author": ["Fran\u00e7a", "Guilherme", "Bento", "Jos\u00e9"], "venue": "In Information Theory (ISIT),", "citeRegEx": "Fran\u00e7a et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Fran\u00e7a et al\\.", "year": 2016}, {"title": "Optimal parameter selection for the alternating direction method of multipliers: quadratic problems", "author": ["Ghadimi", "Euhanna", "Teixeira", "Andr\u00e9", "Shames", "Iman", "Johansson", "Mikael"], "venue": "IEEE Trans. Autom. Control,", "citeRegEx": "Ghadimi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ghadimi et al\\.", "year": 2015}, {"title": "Linear convergence and metric selection in douglas-rachford splitting and admm", "author": ["Giselsson", "Pontus", "Boyd", "Stephen"], "venue": null, "citeRegEx": "Giselsson et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Giselsson et al\\.", "year": 2016}, {"title": "Sur l\u2019approximation, par \u00e9l\u00e9ments finis d\u2019ordre un, et la r\u00e9solution, par p\u00e9nalisation-dualit\u00e9 d\u2019une classe de probl\u00e9mes de Dirichlet non lin\u00e9aires", "author": ["Glowinski", "Roland", "A. Marroco"], "venue": "ESAIM: Modlisation Mathmatique et Analyse Numrique,", "citeRegEx": "Glowinski et al\\.,? \\Q1975\\E", "shortCiteRegEx": "Glowinski et al\\.", "year": 1975}, {"title": "Fast alternating linearization methods for minimizing the sum of two convex functions", "author": ["Goldfarb", "Donald", "Ma", "Shiqian", "Scheinberg", "Katya"], "venue": "Mathematical Programming,", "citeRegEx": "Goldfarb et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Goldfarb et al\\.", "year": 2013}, {"title": "High-order methods for basis pursuit", "author": ["Goldstein", "Tom", "Setzer", "Simon"], "venue": "UCLA CAM Report,", "citeRegEx": "Goldstein et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Goldstein et al\\.", "year": 2010}, {"title": "Fast alternating direction optimization methods", "author": ["Goldstein", "Tom", "O\u2019Donoghue", "Brendan", "Setzer", "Simon", "Baraniuk", "Richard"], "venue": "SIAM Journal on Imaging Sciences,", "citeRegEx": "Goldstein et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goldstein et al\\.", "year": 2014}, {"title": "Adaptive primal-dual splitting methods for statistical learning and image processing", "author": ["Goldstein", "Tom", "Li", "Min", "Yuan", "Xiaoming"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Goldstein et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Goldstein et al\\.", "year": 2015}, {"title": "Unwrapping ADMM: efficient distributed computing via transpose reduction", "author": ["Goldstein", "Tom", "Taylor", "Gavin", "Barabin", "Kawika", "Sayre", "Kent"], "venue": "In AISTATS,", "citeRegEx": "Goldstein et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Goldstein et al\\.", "year": 2016}, {"title": "On the o(1/n) convergence rate of the douglas-rachford alternating direction method", "author": ["He", "Bingsheng", "Yuan", "Xiaoming"], "venue": "SIAM Journal on Numerical Analysis,", "citeRegEx": "He et al\\.,? \\Q2012\\E", "shortCiteRegEx": "He et al\\.", "year": 2012}, {"title": "On non-ergodic convergence rate of Douglas-Rachford alternating direction method of multipliers", "author": ["He", "Bingsheng", "Yuan", "Xiaoming"], "venue": "Numerische Mathematik,", "citeRegEx": "He et al\\.,? \\Q2015\\E", "shortCiteRegEx": "He et al\\.", "year": 2015}, {"title": "Alternating direction method with self-adaptive penalty parameters for monotone variational inequalities", "author": ["He", "Bingsheng", "Yang", "Hai", "Wang", "Shengli"], "venue": "Jour. Optim. Theory and Appl.,", "citeRegEx": "He et al\\.,? \\Q2000\\E", "shortCiteRegEx": "He et al\\.", "year": 2000}, {"title": "Accelerated alternating direction method of multipliers", "author": ["Kadkhodaie", "Mojtaba", "Christakopoulou", "Konstantina", "Sanjabi", "Maziar", "Banerjee", "Arindam"], "venue": "In Proceedings of the 21th ACM SIGKDD,", "citeRegEx": "Kadkhodaie et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kadkhodaie et al\\.", "year": 2015}, {"title": "Learning multiple layers of features from tiny images", "author": ["Krizhevsky", "Alex", "Hinton", "Geoffrey"], "venue": null, "citeRegEx": "Krizhevsky et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2009}, {"title": "Gradient-based learning applied to document recognition", "author": ["LeCun", "Yann", "Bottou", "L\u00e9on", "Bengio", "Yoshua", "Haffner", "Patrick"], "venue": "Proceedings of the IEEE,", "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "Linearized alternating direction method with adaptive penalty for low-rank representation", "author": ["Lin", "Zhouchen", "Liu", "Risheng", "Su", "Zhixun"], "venue": "In NIPS,", "citeRegEx": "Lin et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2011}, {"title": "On the limited memory bfgs method for large scale optimization", "author": ["Liu", "Dong C", "Nocedal", "Jorge"], "venue": "Mathematical programming,", "citeRegEx": "Liu et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Liu et al\\.", "year": 1989}, {"title": "Large-scale sparse logistic regression", "author": ["Liu", "Jun", "Chen", "Jianhui", "Ye", "Jieping"], "venue": "In ACM SIGKDD,", "citeRegEx": "Liu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2009}, {"title": "A general analysis of the convergence of ADMM", "author": ["R. Nishihara", "L. Lessard", "B. Recht", "A. Packard", "M. Jordan"], "venue": "In ICML,", "citeRegEx": "Nishihara et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Nishihara et al\\.", "year": 2015}, {"title": "Stochastic alternating direction method of multipliers", "author": ["Ouyang", "Hua", "He", "Niao", "Tran", "Long", "Gray", "Alexander G"], "venue": "ICML (1),", "citeRegEx": "Ouyang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ouyang et al\\.", "year": 2013}, {"title": "Alternating direction method of multipliers for strictly convex quadratic programs: Optimal parameter selection", "author": ["Raghunathan", "Arvind", "Di Cairano", "Stefano"], "venue": "In American Control Conf.,", "citeRegEx": "Raghunathan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Raghunathan et al\\.", "year": 2014}, {"title": "Convex Analysis", "author": ["R. Rockafellar"], "venue": null, "citeRegEx": "Rockafellar,? \\Q1970\\E", "shortCiteRegEx": "Rockafellar", "year": 1970}, {"title": "Fast ADMM algorithm for distributed optimization with adaptive penalty", "author": ["Song", "Changkyu", "Yoon", "Sejong", "Pavlovic", "Vladimir"], "venue": null, "citeRegEx": "Song et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Song et al\\.", "year": 2016}, {"title": "Training neural networks without gradients: A scalable ADMM approach", "author": ["Taylor", "Gavin", "Burmeister", "Ryan", "Xu", "Zheng", "Singh", "Bharat", "Patel", "Ankit", "Goldstein", "Tom"], "venue": null, "citeRegEx": "Taylor et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Taylor et al\\.", "year": 2016}, {"title": "Faster alternating direction method of multipliers with a worst-case o (1/n) convergence", "author": ["Tian", "Wenyi", "Yuan", "Xiaoming"], "venue": null, "citeRegEx": "Tian et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Tian et al\\.", "year": 2016}, {"title": "Adaptive ADMM with spectral penalty parameter selection", "author": ["Xu", "Zheng", "Figueiredo", "Mario AT", "Goldstein", "Tom"], "venue": null, "citeRegEx": "Xu et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2017}, {"title": "Adaptive relaxed ADMM: Convergence theory and practical implementation", "author": ["Xu", "Zheng", "Figueiredo", "Mario AT", "Yuan", "Xiaoming", "Studer", "Christoph", "Goldstein", "Tom"], "venue": null, "citeRegEx": "Xu et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2017}, {"title": "Asynchronous distributed ADMM for consensus optimization", "author": ["Zhang", "Ruiliang", "Kwok", "James T"], "venue": "In ICML, pp", "citeRegEx": "Zhang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2014}, {"title": "Gradient methods with adaptive step-sizes", "author": ["Zhou", "Bin", "Gao", "Li", "Dai", "Yu-Hong"], "venue": "Computational Optimization and Applications,", "citeRegEx": "Zhou et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2006}, {"title": "Regularization and variable selection via the elastic net", "author": ["Zou", "Hui", "Hastie", "Trevor"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),", "citeRegEx": "Zou et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Zou et al\\.", "year": 2005}], "referenceMentions": [{"referenceID": 1, "context": "ADMM was first introduced in (Glowinski & Marroco, 1975) and (Gabay & Mercier, 1976), and has found applications in many optimization problems in machine learning, distributed computing and many other areas (Boyd et al., 2011).", "startOffset": 207, "endOffset": 226}, {"referenceID": 1, "context": "Consensus ADMM (Boyd et al., 2011) solves minimization problems involving a composite objective f(v) = \u2211 i fi(v), where worker i stores the data needed to compute fi, and so is well suited for distributed model fitting problems (Boyd et al.", "startOffset": 15, "endOffset": 34}, {"referenceID": 1, "context": ", 2011) solves minimization problems involving a composite objective f(v) = \u2211 i fi(v), where worker i stores the data needed to compute fi, and so is well suited for distributed model fitting problems (Boyd et al., 2011; Zhang & Kwok, 2014; Song et al., 2016; Chang et al., 2016; Goldstein et al., 2016; Taylor et al., 2016).", "startOffset": 201, "endOffset": 324}, {"referenceID": 29, "context": ", 2011) solves minimization problems involving a composite objective f(v) = \u2211 i fi(v), where worker i stores the data needed to compute fi, and so is well suited for distributed model fitting problems (Boyd et al., 2011; Zhang & Kwok, 2014; Song et al., 2016; Chang et al., 2016; Goldstein et al., 2016; Taylor et al., 2016).", "startOffset": 201, "endOffset": 324}, {"referenceID": 4, "context": ", 2011) solves minimization problems involving a composite objective f(v) = \u2211 i fi(v), where worker i stores the data needed to compute fi, and so is well suited for distributed model fitting problems (Boyd et al., 2011; Zhang & Kwok, 2014; Song et al., 2016; Chang et al., 2016; Goldstein et al., 2016; Taylor et al., 2016).", "startOffset": 201, "endOffset": 324}, {"referenceID": 15, "context": ", 2011) solves minimization problems involving a composite objective f(v) = \u2211 i fi(v), where worker i stores the data needed to compute fi, and so is well suited for distributed model fitting problems (Boyd et al., 2011; Zhang & Kwok, 2014; Song et al., 2016; Chang et al., 2016; Goldstein et al., 2016; Taylor et al., 2016).", "startOffset": 201, "endOffset": 324}, {"referenceID": 30, "context": ", 2011) solves minimization problems involving a composite objective f(v) = \u2211 i fi(v), where worker i stores the data needed to compute fi, and so is well suited for distributed model fitting problems (Boyd et al., 2011; Zhang & Kwok, 2014; Song et al., 2016; Chang et al., 2016; Goldstein et al., 2016; Taylor et al., 2016).", "startOffset": 201, "endOffset": 324}, {"referenceID": 26, "context": "In theory, ADMM converges for any constant penalty parameter (Eckstein & Bertsekas, 1992; He & Yuan, 2012; Ouyang et al., 2013).", "startOffset": 61, "endOffset": 127}, {"referenceID": 25, "context": "In practice, however, the efficiency of ADMM is highly sensitive to this parameter choice (Nishihara et al., 2015; Ghadimi et al., 2015), and can be improved via adaptive penalty selection methods (He et al.", "startOffset": 90, "endOffset": 136}, {"referenceID": 8, "context": "In practice, however, the efficiency of ADMM is highly sensitive to this parameter choice (Nishihara et al., 2015; Ghadimi et al., 2015), and can be improved via adaptive penalty selection methods (He et al.", "startOffset": 90, "endOffset": 136}, {"referenceID": 18, "context": ", 2015), and can be improved via adaptive penalty selection methods (He et al., 2000; Song et al., 2016; Xu et al., 2017a).", "startOffset": 68, "endOffset": 122}, {"referenceID": 29, "context": ", 2015), and can be improved via adaptive penalty selection methods (He et al., 2000; Song et al., 2016; Xu et al., 2017a).", "startOffset": 68, "endOffset": 122}, {"referenceID": 18, "context": "One such approach, residual balancing (RB) (He et al., 2000), adapts the penalty parameter so that the residuals (derivatives of the Lagrangian with respect to primal and dual variables) have similar magnitudes.", "startOffset": 43, "endOffset": 60}, {"referenceID": 29, "context": "Consensus residual balancing (CRB) (Song et al., 2016) extends residual balancing to consensusbased ADMM for distributed optimization by balancing the local primal and dual residuals on each node.", "startOffset": 35, "endOffset": 54}, {"referenceID": 18, "context": "Our theory is more general than the convergence guarantee in (He et al., 2000; Xu et al., 2017a) that only shows convergence when the scalar penalty parameter is adapted.", "startOffset": 61, "endOffset": 96}, {"referenceID": 11, "context": "ADMM is known to have aO(1/k) convergence rate under mild conditions for convex problems (He & Yuan, 2012; 2015), while a O(1/k) rate is possible when at least one of the functions is strongly convex or smooth (Goldfarb et al., 2013; Goldstein et al., 2014; Kadkhodaie et al., 2015; Tian & Yuan, 2016).", "startOffset": 210, "endOffset": 301}, {"referenceID": 13, "context": "ADMM is known to have aO(1/k) convergence rate under mild conditions for convex problems (He & Yuan, 2012; 2015), while a O(1/k) rate is possible when at least one of the functions is strongly convex or smooth (Goldfarb et al., 2013; Goldstein et al., 2014; Kadkhodaie et al., 2015; Tian & Yuan, 2016).", "startOffset": 210, "endOffset": 301}, {"referenceID": 19, "context": "ADMM is known to have aO(1/k) convergence rate under mild conditions for convex problems (He & Yuan, 2012; 2015), while a O(1/k) rate is possible when at least one of the functions is strongly convex or smooth (Goldfarb et al., 2013; Goldstein et al., 2014; Kadkhodaie et al., 2015; Tian & Yuan, 2016).", "startOffset": 210, "endOffset": 301}, {"referenceID": 25, "context": "Linear convergence can be achieved with strong convexity assumptions (Davis & Yin, 2014; Nishihara et al., 2015; Giselsson & Boyd, 2016).", "startOffset": 69, "endOffset": 136}, {"referenceID": 18, "context": "All of these results assume constant parameters; to the best of our knowledge, no convergence rate has been proven for ADMM with an adaptive penalty: (He et al., 2000; Xu et al., 2017b) proves convergence without providing a rate, and (Lin et al.", "startOffset": 150, "endOffset": 185}, {"referenceID": 22, "context": ", 2017b) proves convergence without providing a rate, and (Lin et al., 2011; Banert et al., 2016; Goldstein et al., 2015) prove convergence for some particular variants of ADMM (\u201clinearized\u201d or \u201cpreconditioned\u201d).", "startOffset": 58, "endOffset": 121}, {"referenceID": 0, "context": ", 2017b) proves convergence without providing a rate, and (Lin et al., 2011; Banert et al., 2016; Goldstein et al., 2015) prove convergence for some particular variants of ADMM (\u201clinearized\u201d or \u201cpreconditioned\u201d).", "startOffset": 58, "endOffset": 121}, {"referenceID": 14, "context": ", 2017b) proves convergence without providing a rate, and (Lin et al., 2011; Banert et al., 2016; Goldstein et al., 2015) prove convergence for some particular variants of ADMM (\u201clinearized\u201d or \u201cpreconditioned\u201d).", "startOffset": 58, "endOffset": 121}, {"referenceID": 8, "context": "To improve practical convergence of ADMM, fixed optimal parameters are discussed in (Raghunathan & Di Cairano, 2014; Ghadimi et al., 2015; Nishihara et al., 2015; Fran\u00e7a & Bento, 2016).", "startOffset": 84, "endOffset": 184}, {"referenceID": 25, "context": "To improve practical convergence of ADMM, fixed optimal parameters are discussed in (Raghunathan & Di Cairano, 2014; Ghadimi et al., 2015; Nishihara et al., 2015; Fran\u00e7a & Bento, 2016).", "startOffset": 84, "endOffset": 184}, {"referenceID": 29, "context": "Additionally, adaptive methods have been proposed; the most closely related work to our own is (Song et al., 2016), which extends the results of (He et al.", "startOffset": 95, "endOffset": 114}, {"referenceID": 18, "context": ", 2016), which extends the results of (He et al., 2000) to consensus problems, where communication is controlled by predefined network structure and the regularizer g(v) is absent.", "startOffset": 38, "endOffset": 55}, {"referenceID": 1, "context": "The residuals in (6) and stopping criterion in (7) are adopted from the general problem (Boyd et al., 2011) to the consensus problem.", "startOffset": 88, "endOffset": 107}, {"referenceID": 18, "context": "The observation that residuals r, d can be decomposed into \u201clocal residuals\u201d r i , d k i has been exploited to generalize the residual balancing method (He et al., 2000) for distributed consensus problems (Song et al.", "startOffset": 152, "endOffset": 169}, {"referenceID": 29, "context": ", 2000) for distributed consensus problems (Song et al., 2016).", "startOffset": 43, "endOffset": 62}, {"referenceID": 18, "context": "Our proof is inspired by the variational inequality (VI) approach in (He et al., 2000; He & Yuan, 2012; 2015).", "startOffset": 69, "endOffset": 109}, {"referenceID": 28, "context": "where \u03bb denotes the dual variable, while f\u2217, g\u2217 denote the Fenchel conjugate of f, g (Rockafellar, 1970).", "startOffset": 85, "endOffset": 104}, {"referenceID": 35, "context": "(Zhou et al., 2006) recommend using a hybrid of these two estimators, and choosing", "startOffset": 0, "endOffset": 19}, {"referenceID": 1, "context": "Application Dataset #samples \u00d7 #features 1 CADMM (Boyd et al., 2011) RB-ADMM (He et al.", "startOffset": 49, "endOffset": 68}, {"referenceID": 18, "context": ", 2011) RB-ADMM (He et al., 2000) AADMM (Xu et al.", "startOffset": 16, "endOffset": 33}, {"referenceID": 29, "context": ", 2017a) CRB-ADMM (Song et al., 2016) Proposed ACADMM", "startOffset": 18, "endOffset": 37}, {"referenceID": 15, "context": "Support Vector Machines (SVMs) minimize the distributed objective function (Goldstein et al., 2016)", "startOffset": 75, "endOffset": 99}, {"referenceID": 24, "context": "We also acquire large empirical datasets from the LIBSVM webpage (Liu et al., 2009), as well as MNIST digital images (LeCun et al.", "startOffset": 65, "endOffset": 83}, {"referenceID": 21, "context": ", 2009), as well as MNIST digital images (LeCun et al., 1998), and CIFAR10 object images (Krizhevsky & Hinton, 2009).", "startOffset": 41, "endOffset": 61}, {"referenceID": 1, "context": "Consensus ADMM (CADMM) (Boyd et al., 2011), residual balancing (RB-ADMM) (He et al.", "startOffset": 23, "endOffset": 42}, {"referenceID": 18, "context": ", 2011), residual balancing (RB-ADMM) (He et al., 2000), adaptive ADMM (AADMM) (Xu et al.", "startOffset": 38, "endOffset": 55}, {"referenceID": 29, "context": ", 2017a), and consensus residual balancing (CRB-ADMM) (Song et al., 2016) are implemented and reported for comparison.", "startOffset": 54, "endOffset": 73}, {"referenceID": 1, "context": "CADMM with default penalty \u03c4 = 1 (Boyd et al., 2011) is often slow to converge.", "startOffset": 33, "endOffset": 52}], "year": 2017, "abstractText": "The alternating direction method of multipliers (ADMM) is commonly used for distributed model fitting problems, but its performance and reliability depend strongly on userdefined penalty parameters. We study distributed ADMM methods that boost performance by using different fine-tuned algorithm parameters on each worker node. We present a O(1/k) convergence rate for adaptive ADMM methods with node-specific parameters, and propose adaptive consensus ADMM (ACADMM), which automatically tunes parameters without user oversight.", "creator": "LaTeX with hyperref package"}}}