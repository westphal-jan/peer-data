{"id": "1706.05039", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jun-2017", "title": "Distributed Transfer Linear Support Vector Machines", "abstract": "Transfer learning today been developed did improve along cameo country different would this tasks of type learning. However, such algorithms become less capabilities and the projected with same size of field analysis and now handful of tasks. Moreover, conscience can also claiming as some tasks may produce sensitive along offered data, which there wished between nodes and accomplish. We propose but importance - unit youtube transfer besides principles, where several tasks helping it find the best linear leaders vector fire (SVM) lower-level in with available business. With alternating direction method of codice_7, transition simply ability better characteristics 16.000 rather usable different privately, been each holomorphic like each task carrying with trying giving data, three only decision formula_4 there returned between rather tasks well nodes. Numerical experiments on MNIST dbms show that second knowledge october later which response tasks means be used intended accumulation that vulnerability large over option tasks that changes operation processing much yet unbalanced planning labels. We show that an risks which the giving tasks three early nodes without the electronically main through link logistics or also be limit using came specific 1944 from the binary and contain the online which the source procedures. We all she one second target tasks those follow their leave 1999 too - on whether rerunning the. encoding.", "histories": [["v1", "Thu, 15 Jun 2017 18:53:11 GMT  (362kb,D)", "http://arxiv.org/abs/1706.05039v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.DC", "authors": ["rui zhang", "quanyan zhu"], "accepted": false, "id": "1706.05039"}, "pdf": {"name": "1706.05039.pdf", "metadata": {"source": "CRF", "title": "Distributed Transfer Linear Support Vector Machines", "authors": ["Rui Zhang", "Quanyan Zhu"], "emails": ["rz885@nyu.edu", "qz494@nyu.edu"], "sections": [{"heading": null, "text": "Index Terms\u2014Transfer Learning, Multi-Task Learning, Distributed Learning, Support Vector Machines\nI. INTRODUCTION\nMachine learning algorithms are largely used nowadays in various areas, e.g., face detection [1] and search engines [2]. Traditionally, machine learning makes predictions or classifications based on the assumption that the training and the testing data come from the same source or distribution [3]. However, this assumption may not hold in many real applications [4]; for example, the training data can be outdated, or insufficient to build a good classifier. In such cases, it is difficult to find the classifier using traditional machine learning frameworks.\nRecent researches on transfer learning provide a solution to address such problems. It has been shown that machine learning tasks can benefit from other similar tasks by knowledge transfer [3], [4]. For instance, web-page data can become outdated easily as the web content changes frequently, and new training data are expensive to acquire as the labeling of the data is costly. Since parts of the outdated data still contain useful information, knowledge can be transferred from them to train a classifier together with the new data [5].\nAlthough the knowledge transfer can improve the performance of machine learning, the training process using a large amount of data is often not efficient. For traditional transfer learning, training data are communicated between tasks [6]. The direct data sharing is not possible when the volume of the data is huge and they contain private information. For example, training data may come from different nodes of a wireless sensor network (WSN), and their communication with a fusion center can be either costly or restricted due to scalability, privacy or power limitations [7].\nThis paper aims to address this issue by extending transfer learning into a distributed framework in the context of support vector machines (SVMs) illustrated in Fig. 1. The framework trains different but related tasks together with linear SVMs at each node in a fully distributed network. The decision variables to classify testing data are found by minimizing the regularized errors of training data of each task. One set of consensus constraints is introduced to force all the tasks to share the same terms of decision variables at each node while another set of consensus constraints is used to force all the nodes to share the same decision variables of each task. With alternating direction method of multipliers (ADMoM) [8], the centralized problem can be solved in a fully distributed way. Each task at a node shares its decision variables with the same task in the neighboring nodes and other tasks in the same node. As a result, the classification accuracy of each task in each node can be improved without sharing local and private data.\nThe consensus-based distributed framework provides a way to address distributed transfer learning problems in connected\nar X\niv :1\n70 6.\n05 03\n9v 1\n[ cs\n.L G\n] 1\n5 Ju\nn 20\n17\nnetworks. Since each task at a node makes decisions using its local data, the training process becomes more efficient and scalable. Allowing tasks and nodes to communicate their decision variables with others, we can achieve more accurate classifications without sharing private data between different tasks and different nodes, which effectively reduces the communication overhead and maintains privacy at the same time. Note that the problem of transfer learning between tasks in one node can be viewed as a transfer learning problem studied in [6]. Besides, the problem of distributed machine learning with a single task is a distributed support vector machines (DSVM) problem recently studied in [7].\nThe proposed framework is a generalization of both centralized transfer learning scheme and distributed machine learning. It provides a large-scale transfer learning framework where each task transfers knowledge to other tasks and each node transfers knowledge to his neighboring nodes. Performances of all the tasks in each node are illustrated in terms of their training efficiency and data privacy. Related Work. Our research is closely related to multitask learning [6], [9], transfer learning [10], and distributed machine learning [7], [11], [12]. There is a strong connection between multi-task learning and transfer learning. In multitask learning, both the source and target tasks are learned simultaneously and perfectly, while transfer learning only aims at improving the performance of the target tasks. In this paper, we consider multi-task learning as a scenario of transfer learning, since it can be easily extended to transfer learning by assigning a larger weight to the loss function of the target tasks [4].\nCurrent research on transfer learning has focused on solving centralized problems. Both [6] and [9] have focused on multitask learning, and they have shown that multi-task learning outperforms single-task learning. Raina et al. have presented in [10] a self-taught learning framework where the knowledge from unlabeled data is used to improve the performance of a given classification task. However, these centralized transfer learning approaches require global collection and processing of all the training data, which not only takes more time and space for training, but also makes sensitive data easily accessible by unwanted tasks.\nDistributed machine learning aims at large-scale problems and networked problems for traditional machine learning. Both [11] and [7] have presented approaches on DSVMs where information, such as support vectors and decision variables, is communicated between nodes to achieve a better global performance more efficiently. Main Contributions. In this work, we extend transfer learning into a distributed framework to maintain the performance and efficiency of training different but related tasks in a network. Our contributions can be summarized as follows: \u2022 We design a SVM-based multi-task transfer learning to\nforce each task sharing information with other tasks. We then extend it into a distributed framework using consensus constraints in a networked system where several tasks are trained together.\n\u2022 We develop a distributed transfer support vector machine (DTSVM) algorithm with Alternating Direction Method of Multipliers (ADMoM) [8]. In this algorithm, each task in a node processes their own data using information from other tasks in the same node and the same task in neighboring nodes. Notice that training and testing data are not shared between tasks and nodes, which not only reduces the communication overhead but also maintains privacy. \u2022 We demonstrate with numerical experiments that the DTSVM algorithm can improve the performance of the target tasks that contain limited training data or unbalanced training labels. We also show that our algorithm can improve the performance of the nodes without using the data from the source tasks by using information sent from the nodes that contain the data of the source tasks. We further demonstrate that our algorithm is suitable for online learning where the target tasks can freely enter or leave the training of the source tasks in real time.\nThe rest of this paper is organized as follows. Section 2 presents a consensus-based centralized transfer learning approach on SVMs. Section 3 outlines the extended distributed transfer support vector machines (DTSVM). Section 4 and 5 present numerical results and concluding remarks, respectively. Notations. Boldface letters represent matrices (column vectors); (\u00b7)T denotes matrix and vector transposition; \u2016 \u00b7 \u2016 denotes the norm of the matrix or vector; diag(y) denotes the diagonal matrix with y on its main diagonal; V denotes the set of nodes in a network; Bv denotes the set of neighboring nodes of node v; T denotes the set of tasks."}, {"heading": "II. CENTRALIZED TRANSFER LEARNING", "text": "In this section, we present a centralized transfer learning approach on SVMs. Consider T learning tasks with T = {1, ...,T} denotes the set of tasks. We assume that each task t has a labeled training set Dt = {(xtn,ytn)|xtn \u2208 Xt ,ytn \u2208 {\u22121,+1}}Ntn=1, where Xt \u2286 Rp represents the input space of task t. Note that Xt is different for each task, but has the same dimension p. For each task, a linear SVM aims to find a maximum-margin discriminant function gt(xt) = sign ( xTt w\u0302\u2217t + b\u0302\u2217t ) , which gives input testing data xt a label \u22121 or +1. Decision variables {w\u0302\u2217t , b\u0302\u2217t } can be found by solving the following minimization problem [13]:\nmin w\u0302t ,b\u0302t ,{\u03betn}\n1 2 \u2016 w\u0302t \u2016 2 2 +C\nNt \u2211\nn=1 \u03betn\ns.t. ytn(w\u0302Tt xtn + b\u0302t)\u2265 1\u2212\u03betn; \u03betn \u2265 0.\n(1)\nNote that, \u03betn is the slack variable, which accounts for nonseparable case. Problem (1) is a traditional SVM problem for single task learning. With the assumption that different tasks are related to each other on the basis of similarity between distributions of samples Xt [14], the decision variables w\u0302t , b\u0302t can be divided into: w\u0302t = w0 +wt ; b\u0302t = b0 +bt , where w0 and\nb0 are common terms over all tasks, while wt and bt are task specific terms [4], [6]. We further write the decision variables as:\nw\u0302t = w0t +wt ; b\u0302t = b0t +bt , (2)\nwith w01 = ...= w0T and b01 = ...= b0T forcing all common terms to agree with each other among all tasks. Thus, a consensus-based centralized approach of multi-task transfer learning can be formulated as the following problem:\nmin {w0t ,b0t ,wt ,bt ,{\u03betn}}\n\u03b51 2 \u2211 t\u2208T \u2016 w0t \u201622\n+ \u03b522 \u2211 t\u2208T \u2016 wt \u201622 +TC \u2211 t\u2208T\nNt \u2211\nn=1 \u03betn\ns.t. ytn(w\u0302Tt xtn + b\u0302t)\u2265 1\u2212\u03betn,\n\u03betn \u2265 0, w0t = w0s,b0t = b0s,\n\u2200t \u2208T ; \u2200t \u2208T ;\n\u2200t,s \u2208T ,s 6= t.\n(3a) (3b) (3c)\n(3) Note that, consensus constraints (3c) are used to restrict common terms. \u03b51 and \u03b52 are positive regularization parameters, which determine how much w\u0302t differs in each task by controlling the size of w0t and wt . When \u03b51\u03b52 is large, w0t tends to be equal to 0, which makes all tasks unrelated. On the other hand, when \u03b51\u03b52 is small, wt tends to be equal to 0, which makes all tasks find the same classifier.\nBy solving Problem (3), we can find the decision variables w\u0302\u2217t and b\u0302\u2217t simultaneously with information transferred through consensus constraints (3c) and common terms w0t and b0t . Problem (3) provides a centralized framework to transfer learning. In the following section, we further extend it to a distributed network."}, {"heading": "III. DISTRIBUTED TRANSFER LEARNING", "text": "Consider a network with V = {1, ..,V} representing the set of nodes. Node v\u2208V only communicates with his neighboring nodes Bv \u2286V . Without loss of generality, we assume that any two nodes in this network are connected by a path, i.e., there is no isolated node in this network. At each node v, T labeled training sets Dvt = {(xvtn,yvtn)|xvtn \u2208Xt ,yvtn \u2208 {\u22121,+1}}Nvtn=1 of size Nvt are available for each task t \u2208T (e.g., see Fig. 1).\nThe maximum-margin linear discriminant function at every node v \u2208 V for each task t \u2208T can be described as gvt(xt) = xTt w\u0302\u2217vt + b\u0302\u2217vt , where decision variables w\u0302\u2217vt = w\u22170vt + w \u2217 vt and b\u0302\u2217vt = b \u2217 0vt + b \u2217 vt . Note that there are two sets of consensus constraints, w011 = ... = w01T = ... = w0V 1 = ... = w0V T and b011 = ...= b01T = ...= b0V 1 = ...= b0V T are used to force all common terms of decision variables to agree with each other among all the nodes and all the tasks, while w1t = ... = wVt and b1t = ... = bVt are used to forcing all decision variables {w\u0302vt , b\u0302vt}v\u2208V of task t to agree with each other among all the nodes. This approach enables each task t at each node v to classify any new input xt to one of the two classes {+1,\u22121} without communicating Dvt to other nodes v\u2032 6= v.\nThe discriminant function gvt(xt) can be obtained by solving the following optimization problem:\nmin {w0vt ,b0vt ,wvt ,bvt ,{\u03bevtn}}\n\u03b51 2 \u2211\nv\u2208V \u2211 t\u2208T \u2016 w0vt \u201622\n+ \u03b522 \u2211 v\u2208V \u2211 t\u2208T \u2016 wvt \u201622 +V TC \u2211 v\u2208V \u2211 t\u2208T\nNt \u2211\nn=1 \u03bevtn\ns.t. yvtn(w\u0302Tvtxvtn + b\u0302vt)\u2265 1\u2212\u03bevtn,\n\u03bevtn \u2265 0, w0vt = w0vs,b0vt = b0vs, w0vt = w0ut ,b0vt = b0ut ,\nwvt = wut ,bvt = but ,\n\u2200v \u2208 V , t \u2208T ; \u2200v \u2208 V , t \u2208T ;\n\u2200v \u2208 V , t,s \u2208T ,s 6= t; \u2200v \u2208 V , t \u2208T ,u \u2208Bv; \u2200v \u2208 V , t \u2208T ,u \u2208Bv.\n(4) In the above problem, the third and the fourth constraints impose the consensus on the common terms w0vt and b0vt at every node v for each task t, while the fourth and the fifth constraints impose the consensus on decision variables w\u0302vt :=w0vt +wvt and b\u0302vt := b0vt +bvt across neighboring nodes for each task t.\nTo solve Problem (4), we first define the vector of decision variables rv := [wT0vt ,b0vt ,w T vt ,bvt ]\nT , the augmented matrix Xvt := [(xvt1, ...,xvtNv)T ,1vt ], the diagonal label matrix Yvt := diag([yvt1, ...,yvtNvt ]), and the vector of slack variables \u03bevt := [\u03bevt1, ...,\u03bevtNvt ]T . With these definitions, it follows readily that w0vt = [I\u0302,0]rv and w\u0302vt = [I\u0302, I\u0302]rv where [I\u0302,0] := [I\u0302p+1,0p+1] and [I\u0302, I\u0302] := [I\u0302p+1, I\u0302p+1]. I\u0302p+1 is a (p+1)\u00d7 (p+1) identity matrix with its (p+1, p+1)-st entry being 0. Thus, Problem (4) can be rewritten as\nmin {rvt ,\u03bevt ,\u03d5vts,\u03c9vut}\n\u03b51 2 \u2211\nv\u2208V \u2211 t\u2208T rTvtM1rvt\n+ \u03b522 \u2211 v\u2208V \u2211 t\u2208T rTvtM2rvt +V TC \u2211 v\u2208V \u2211 t\u2208T \u03bevt\ns.t. YvtXvt [I,I]rvt 1vt \u2212\u03bevt ,\n\u03bevt 0vt , [I,0]rvt = \u03d5vts,\u03d5vts = [I,0]rvs,\nrvt = \u03c9vut ,\u03c9vut = rut ,\nv \u2208 V , t \u2208T ; v \u2208 V , t \u2208T ;\nv \u2208 V , t,s \u2208T ,s 6= t; v \u2208 V , t \u2208T ,u \u2208Bv,\n(5) where \u03d5vts is used to decompose the common term [I,0]rvt of task t to other tasks s 6= t, and \u03c9vut is used to decompose the decision variable rv at node v to its neighboring nodes u \u2208 Bv. Note that [I,0] := [Ip+1,0p+1], [I,I] := [Ip+1,Ip+1], M1 = [I\u0302,0]T [I\u0302,0] and M2 = [0, I\u0302]T [0, I\u0302].\nProblem (5) can be solved iteratively in a distributed way with ADMoM [8], which is shown as the following proposition.\nProposition 1. With \u03b1(0)vt = 0(p+1)\u00d71 and \u03b2 (0) vt = 0(2p+2)\u00d71, Problem (5) can be solved by the following iterations:\n\u03bb (k+1)vt \u2208 arg max 0vt \u03bbvt V TC1vt \u2212 12 \u03bb T vt YvtXvt [I,I]U \u22121 vt [I,I]T XTvtYvt\u03bbvt\n+(1vt +YvtXvt [I,I]U\u22121vt f (k) vt ) T \u03bbvt , (6)\nr(k+1)vt = U\u22121vt ( [I,I]T XTvtYvt\u03bb (k+1) vt \u2212 f (k) vt ) , (7)\n\u03b1(k+1)vt = \u03b1 (k) vt + \u03b71 2 [I,0] \u2211 s\u2208T ,s 6=t (r(k+1)vt \u2212 r (k+1) vs ), (8)\n\u03b2 (k+1)vt = \u03b2 (k) vt + \u03b72 2 \u2211u\u2208Bv (r(k+1)vt \u2212 r (k+1) ut ), (9)\nwhere\nUvt = \u03b51M1 + \u03b52M2 +2\u03b71(T \u22121)[I,0]T [I,0]+2\u03b72|Bv|I2p+2, (10)\nand\nf(k)vt = 2[I,0]T \u03b1 (k) vt +2\u03b2 (k) vt\n\u2212\u03b71 \u2211 s\u2208T ,s 6=t\n[I,0]T [I,0](r(k)vt + r (k) vs )\u2212\u03b72 \u2211 u\u2208Bv (r(k)vt + r (k) ut ).\n(11)\nProof. See Appendix A.\nIn Proposition 1, each task at node v computes \u03bbvt by (6), then it computes rvt by (7) using the new \u03bbvt . In the next step, each task at node v sends rvt to all the other tasks s\u2208T ,s 6= t, and each node of task t broadcasts rvt to the neighboring nodes u \u2208 Bv. Then, \u03b1vt updates by (8) with rvs from the other tasks s \u2208 T ,s 6= t, while \u03b2vt updates by (9) with rut from neighboring nodes u \u2208Bv. Then, each task at node v repeats computing \u03bbvt by (6) with \u03b1vt and \u03b2vt , and the iteration goes until convergence. Note that, at each iteration k, each task at each node can evaluate its own discriminant function for any input data xt as:\ngvt(xt) = [xTt ,1][I,I]rvt . (12)\nProposition 1 illustrates the iterations of distributed transfer support vector machines (DTSVM). It is a fully distributed algorithm which does not require a fusion center to store or process all the data. Each iteration requires calculating \u03bbvt , rvt , \u03b1vt and \u03b2vt . The computation of \u03bbvt is quadratic programming that can be solved in polynomial time. rvt , \u03b1vt and \u03b2vt can be calculated directly. It can be easily shown that the inverse of Uvt always exists. The information transferred between nodes is the decision variables rvt . This scheme maintains the privacy of sensitive data and reduces the communication overhead at the same time since the data is kept at each node. Our DTSVM algorithm also has no assumptions on the form of data and networks, and thus, it can be used in various situations. Moreover, since decision variables rvt are updated at each iteration, adding or deleting nodes and modifying connections do not require rerunning of the whole algorithm. In addition, the proof of the convergence of the iterations to the solution of Problem (5) is provided at the end of Appendix A."}, {"heading": "IV. NUMERICAL EXPERIMENTS", "text": "In this section, we present numerical experiments of DTSVM. We use the MNIST database of handwritten digits to evaluate the distributed transfer learning algorithm [15]. The MNIST database contains images of digit \u201c0\u201d to \u201c9\u201d, here we set classifying \u201c3\u201d and \u201c6\u201d as Task 1, classifying \u201c5\u201d and \u201c4\u201d as Task 2 and classifying \u201c8\u201d and \u201c9\u201d as Task 3. Note that,\nTask 1 and 2 are the target tasks that we aim to decrease their classification risks, while Task 3 is the source task that helps us to achieve that. All the images have been pre-processed with principal component analysis (PCA) into vectors with a dimension of 10 [16]. We further define the degree of a node v \u2208 V as the actual number of neighboring nodes Bv divided by the most achievable number of neighbors |V |\u22121, and the degree of the network V as the average degree of all the nodes v \u2208 V .\nFor comparison purposes, we also present the results of centralized support vector machines (CSVM) and distributed support vector machines (DSVM). The algorithm of CSVM can be acquired from [13]. The algorithm of DSVM can be found in [7], which only shares the values of decision variables during the training process. We will show later that the information from the nodes with DTSVM can also improve the performance of the nodes with DSVM.\nFrom Fig. 2, we can see that the classification risks of DTSVM are lower than the risks of both DSVM and CSVM, thus, transfer learning improves the performances of the tasks. Moreover, we can see that Task 1 benefits more than Task 3 as the risks of Task 1 in DTSVM decrease more.\nFrom Fig. 3 and Fig. 4, we can see that parameters C, \u03b51 and \u03b52 are related to the performance of transfer learning. C indicates the trade-off between a larger margin and a smaller error penalty. Parameters \u03b51 and \u03b52 control the difference of decision variables between different tasks. When \u03b51/\u03b52 is large, w0t tends to be 0, i.e., all tasks tend to be not related, however, when \u03b51/\u03b52 is small, wt tends to be 0, i.e., all tasks tend to be same, both of the cases will decrease the classification accuracy. We can see from Fig. 3 and Fig. 4 that the improvement of the performance requires a proper tuning of these parameters.\nFig. 5 shows the results when the training data of the target task, i.e., Task 1, is limited and has unbalanced labels. We can see that transfer learning can also improve the classification accuracy of these cases. Note that when there are only 2 training samples of digit \u201c3\u201d in Task 1, some nodes have only training samples of digit \u201c6\u201d, but the DTSVM can still find classifiers better than CSVM. Fig. 6 and Table I show the results when the data is trained using DSVM and DTSVM together in the same network. Nodes who contain the data\nfrom the source task will train with DTSVM, while nodes who lack that will train with DSVM. We can see that nodes with DTSVM have lower risks. Moreover, nodes with DSVM also have lower risks as they receive information from nodes with DTSVM. This experiment shows that the performances of the nodes who lack training data from the source tasks can be improved with the knowledge transferred from the nodes who contain that data. Fig. 7 shows the results of online transfer learning. Task 1 and Task 2 are the target tasks whose risks we aim to reduce, while Task 3 is the source task that can be used to improve the performances of the target tasks. At different stages, Task 1 and Task 2 will enter or leave the DTSVM algorithm with Task 3. Both Task 1 and Task 2 have better performances after training with Task 3. This experiment shows that our DTSVM algorithm can work online without\nrerunning the whole system."}, {"heading": "V. CONCLUSION", "text": "In this paper, we have extended a centralized SVM-based transfer learning into a distributed framework. By using ADMoM, we have developed a fully distributed algorithm (DTSVM) where each task in each node operates their own data without transferring training data to other tasks and neighboring nodes. Numerical experiments have shown that our DTSVM algorithm can improve the performances of the target tasks that lack training data or have unbalanced training labels. We have also shown that our algorithm can improve the\nperformances of the nodes who lack the data from the source tasks, by sending information from the nodes who contain the data from the source tasks. We have demonstrated that our algorithm is suitable for online learning where the target tasks can freely enter or leave the training of the source tasks in realtime. One direction of future works is to extend the current framework to nonlinear algorithms and other machine learning algorithms."}, {"heading": "APPENDIX A", "text": "Problem (5) can be solved in a distributed way with ADMoM [8], which solves the following problem:\nmin {r,\u03c9} F1(r)+F2(\u03c9)\ns.t. Mr = \u03c9. (13)\nwith the following iterations:\nr(k+1) \u2208 argmin r F1(r)+\u03b1(k)T Mr+ \u03b7 2 \u2225\u2225\u2225Mr\u2212\u03c9(k)\u2225\u2225\u22252, (14) \u03c9(k+1) \u2208 argmin\n\u03c9 F2(\u03c9)\u2212\u03b1(k)T \u03c9 + \u03b7 2 \u2225\u2225\u2225Mr(k+1)\u2212\u03c9\u2225\u2225\u22252, (15) \u03b1(k+1) = \u03b1(k)+\u03b7(Mr(k+1)\u2212\u03c9(k+1)), (16)\nwhere \u03b1 denotes the Lagrange multiplier corresponding to the constraint Mr = \u03c9 .\nWe follow a similar step in [7], by setting\nr = [r11; ...;r1T ; ...;rV 1; ...;rV T ]\nand \u03c9 = [{\u03d51ts}t,s\u2208T ,s 6=t ; ...;{\u03d5Vts}t,s\u2208T ,s 6=t ; {\u03c9vu1}v\u2208V ,u\u2208Bv ; ...;{\u03c9vuT}v\u2208V ,u\u2208BV ],\nProblem (5) can be transformed into the form of (13), and thus be solved by Iterations (14)-(16). By splitting each iterations into sub-problems and further simplifications, distributed iterations of solving problem (5) can be summarized into the following lemma.\nLemma 1. Problem (5) can be solved by the following iterations:\n{r(k+1)vt ,\u03be (k+1) vy } \u2208 arg min\n{rvt ,\u03bevt} L (rvt ,\u03bevy,\u03d5\n(k) vts ,\u03c9 (k) vut ,\u03b1 (k) vts,d ,\u03b2 (k) vut,d)\n(17) \u03d5(k+1)vts \u2208 argmin\u03d5vts L (r(k+1)vt ,\u03be (k+1) vy ,\u03d5vts,\u03c9 (k) vut ,\u03b1 (k) vts,d ,\u03b2 (k) vut,d), (18) \u03c9(k+1)vts \u2208 argmin\u03c9vts L (r(k+1)vt ,\u03be (k+1) vy ,\u03d5 (k) vts ,\u03c9vut ,\u03b1 (k) vts,d ,\u03b2 (k) vut,d),\n(19) \u03b1(k+1)vts,1 = \u03b1 (k) vts,1 +\u03b71([I,0]r (k+1) vt \u2212\u03d5 (k+1) vts ), (20)\n\u03b1(k+1)vts,2 = \u03b1 (k) vts,2 +\u03b71(\u03d5 (k+1) vts \u2212 [I,0]r (k+1) vs ), (21)\n\u03b2 (k+1)vut,1 = \u03b2 (k) vut,1 +\u03b72(r (k+1) vt \u2212\u03c9 (k+1) vut ), (22)\n\u03b2 (k+1)vut,2 = \u03b2 (k) vut,2 +\u03b72(\u03c9 (k+1) vut \u2212 r (k+1) ut ), (23)\nwhere L (rvt ,\u03bevy,\u03d5vts,\u03c9vut ,\u03b1vts,d ,\u03b2vut,d) = \u03b512 \u2211\nv\u2208V \u2211 t\u2208T rTvtM1rvt\n+ \u03b522 \u2211 v\u2208V \u2211 t\u2208T rTvtM2rvt +V TC \u2211 v\u2208V \u2211 t\u2208T \u03bevt\n+ \u2211 v\u2208V \u2211 t\u2208T \u2211 s\u2208T ,s 6=t\n{ \u03b1Tvts,1([I,0]rvt \u2212\u03d5vts) } + \u2211\nv\u2208V \u2211 t\u2208T \u2211 s\u2208T ,s 6=t\n{ \u03b1Tvts,2(\u03d5vts\u2212 [I,0]rvs) } + \u2211\nv\u2208V \u2211 u\u2208Bv \u2211 t\u2208T\n{ \u03b2 Tvut,1(rvt \u2212\u03c9vut)+\u03b2 Tvut,2(\u03c9vut \u2212 rut) } +\u03b712 \u2211\nv\u2208V \u2211 t\u2208T \u2211 s\u2208T ,s 6=t\n{ \u2016 [I,0]rvt \u2212\u03d5vts \u201622 + \u2016 \u03d5vts\u2212 [I,0]rvs \u201622 } +\u03b722 \u2211\nv\u2208V \u2211 u\u2208Bv \u2211 t\u2208T\n{ \u2016 rvt \u2212\u03c9vut \u201622 + \u2016 \u03c9vut \u2212 rut \u201622 } .\n(24)\nSetting initial conditions \u03b1(0)vts,1 = \u03b1 (0) vts,2 = 0(p+1)\u00d71 and\n\u03b2 (0)vut,1 = \u03b2 (0) vut,2 = 0(2p+2)\u00d71, we have \u03b1 (k) vts,1 = \u03b1 (k) vts,2 and \u03b2 (k) vut,1 = \u03b2 (k)vut,2 for k \u2265 0. We further define \u03b1vt = \u2211s\u2208T ,s 6=t \u03b1vts,1 and \u03b2vt = \u2211u\u2208Bv \u03b2vut,1. Note that, \u03d5vts = 1 2 [I,0](rvt + rvs), and \u03c9vut = 12 (rvt + rut), which can be solved directly from (18) and (19). With further simplification, iterations (17)-(23) can be simplified as the following lemma.\nLemma 2. With \u03b1(0)vt = 0(p+1)\u00d71 and \u03b2 (0) vt = 0(2p+2)\u00d71, iterations (17)-(23) can be reduced into the following iterations:\n{r(k+1)vt ,\u03be (k+1) vy } \u2208 arg min {rvt ,\u03bevt} L \u2032(rvt ,\u03bevy,\u03b1 (k) vt ,\u03b2 (k) vt ), (25)\n\u03b1(k+1)vt = \u03b1 (k) vt + \u03b71 2 [I,0] \u2211 s\u2208T ,s 6=t (r(k+1)vt \u2212 r (k+1) vs ), (26)\n\u03b2 (k+1)vt = \u03b2 (k) vt + \u03b72 2 \u2211u\u2208Bv (r(k+1)vt \u2212 r (k+1) ut ), (27)\nwhere L \u2032(rvt ,\u03bevy,\u03b1vt ,\u03b2vt) = \u03b512 \u2211\nv\u2208V \u2211 t\u2208T rTvtM1rvt\n+ \u03b522 \u2211 v\u2208V \u2211 t\u2208T rTvtM2rvt +V TC \u2211 v\u2208V \u2211 t\u2208T \u03bevt +2 \u2211 v\u2208V \u2211 t\u2208T \u03b1Tvt [I,0]rvt +2 \u2211 v\u2208V \u2211 t\u2208T \u03b2 Tvt rvt\n+\u03b71 \u2211 v\u2208V \u2211 t\u2208T \u2211 s\u2208T ,s 6=t \u2223\u2223\u2223\u2223\u2223\u2223[I,0]rvt \u2212 12 [I,0](r(k)vt + r(k)vs )\u2223\u2223\u2223\u2223\u2223\u222322 +\u03b72 \u2211\nv\u2208V \u2211 u\u2208Bv \u2211 t\u2208T \u2223\u2223\u2223\u2223\u2223\u2223rvt \u2212 12 (r(k)vt + r(k)ut )\u2223\u2223\u2223\u2223\u2223\u222322 . (28)\nIntroducing unused constraints YvtXvt [I,I]rvt 1vt\u2212\u03bevt and \u03bevt 0vt with Lagrangian multipliers \u03bbvt and \u03b3vt into (25), by KKT conditions, we can achieve:\nrvt = U\u22121vt ( [I,I]T XTvtYvt\u03bbvt \u22122[I,0]T \u03b1vt \u22122\u03b2vt\n+\u03b71 \u2211 s\u2208T ,s6=t\n[I,0]T [I,0](r(k)vt + r (k) vs )+\u03b72 \u2211 u\u2208Bv (r(k)vt + r (k) ut )\n) .\n(29) V TC1vt \u2212\u03bbvt \u2212 \u03b3vt = 0vt . (30)\nNote that,\nUvt = \u03b51M1 + \u03b52M2 +2\u03b71(T \u22121)[I,0]T [I,0]+2\u03b72|Bv|I2p+2. (31)\nLetting\nfvt = 2[I,0]T \u03b1vt +2\u03b2vt \u2212\u03b71 \u2211\ns\u2208T ,s 6=t [I,0]T [I,0](r(k)vt + r (k) vs )\u2212\u03b72 \u2211 u\u2208Bv (r(k)vt + r (k) ut ),\n(32) we can also achieve:\n\u03bbvt \u2208 argmax \u03bbvt \u2212 12 \u03bb T vt YvtXvt [I,I]U \u22121 vt [I,I]T XTvtYvt\u03bbvt\n+(1vt +YvtXvt [I,I]U\u22121vt fvt)T \u03bbvt . (33)\nThus, iterations of solving Problem (5) can be summarized as Proposition 1.\nNote that, since M1 and M2 are semi-positive matrices, the objective function of Problem (5) can be shown that it is closed, proper, and convex. Moreover, it is easy to see that the unaugmented Lagrangian L in (24) has a saddle point which satisfies\nL (r\u2217vt ,\u03be \u2217vy,\u03d5\u2217vts,\u03c9\u2217vut ,\u03b1vts,k,\u03b2vut,k) \u2264L (r\u2217vt ,\u03be \u2217vy,\u03d5\u2217vts,\u03c9\u2217vut ,\u03b1\u2217vts,k,\u03b2 \u2217vut,k) \u2264L (rvt ,\u03bevy,\u03d5vts,\u03c9vut ,\u03b1\u2217vts,k,\u03b2 \u2217vut,k).\nThus, iterations in Proposition 1 converge to the solution of Problem (5) based on Section 3.2 and Appendix A in [8]."}], "references": [{"title": "Training support vector machines: an application to face detection", "author": ["E. Osuna", "R. Freund", "F. Girosi"], "venue": "Computer vision and pattern recognition, 1997. Proceedings., 1997 IEEE computer society conference on, pp. 130\u2013136, IEEE, 1997.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1997}, {"title": "A machine learning approach to building domain-specific search engines", "author": ["A. McCallum", "K. Nigam", "J. Rennie", "K. Seymore"], "venue": "IJCAI, vol. 99, pp. 662\u2013667, Citeseer, 1999.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1999}, {"title": "Transfer learning for visual categorization: A survey", "author": ["L. Shao", "F. Zhu", "X. Li"], "venue": "Neural Networks and Learning Systems, IEEE Transactions on, vol. 26, no. 5, pp. 1019\u20131034, 2015.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "A survey on transfer learning", "author": ["S.J. Pan", "Q. Yang"], "venue": "Knowledge and Data Engineering, IEEE Transactions on, vol. 22, no. 10, pp. 1345\u2013 1359, 2010.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Boosting for transfer learning", "author": ["W. Dai", "Q. Yang", "G.-R. Xue", "Y. Yu"], "venue": "Proceedings of the 24th international conference on Machine learning, pp. 193\u2013200, ACM, 2007.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "Regularized multi\u2013task learning", "author": ["T. Evgeniou", "M. Pontil"], "venue": "Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 109\u2013117, ACM, 2004.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2004}, {"title": "Consensus-based distributed support vector machines", "author": ["P.A. Forero", "A. Cano", "G.B. Giannakis"], "venue": "The Journal of Machine Learning Research, vol. 11, pp. 1663\u20131707, 2010.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "Distributed optimization and statistical learning via the alternating direction method of multipliers", "author": ["S. Boyd", "N. Parikh", "E. Chu", "B. Peleato", "J. Eckstein"], "venue": "Foundations and Trends R  \u00a9 in Machine Learning, vol. 3, no. 1, pp. 1\u2013122, 2011.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Semisupervised multitask learning with gaussian processes", "author": ["G. Skolidis", "G. Sanguinetti"], "venue": "Neural Networks and Learning Systems, IEEE Transactions on, vol. 24, no. 12, pp. 2101\u20132112, 2013.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Self-taught learning: transfer learning from unlabeled data", "author": ["R. Raina", "A. Battle", "H. Lee", "B. Packer", "A.Y. Ng"], "venue": "Proceedings of the 24th international conference on Machine learning, pp. 759\u2013766, ACM, 2007.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "Distributed support vector machines", "author": ["A. Navia-V\u00e1zquez", "E. Parrado-Hernandez"], "venue": "Neural Networks, IEEE Transactions on, vol. 17, no. 4, pp. 1091\u20131097, 2006.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2006}, {"title": "Scaling up machine learning: Parallel and distributed approaches", "author": ["R. Bekkerman", "M. Bilenko", "J. Langford"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "The nature of statistical learning theory", "author": ["V. Vapnik"], "venue": "Springer Science & Business Media,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}, {"title": "Exploiting task relatedness for multiple task learning", "author": ["S. Ben-David", "R. Schuller"], "venue": "Learning Theory and Kernel Machines, pp. 567\u2013580, Springer, 2003.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2003}, {"title": "Principal component analysis", "author": ["I. Jolliffe"], "venue": "Wiley Online Library,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2002}], "referenceMentions": [{"referenceID": 0, "context": ", face detection [1] and search engines [2].", "startOffset": 17, "endOffset": 20}, {"referenceID": 1, "context": ", face detection [1] and search engines [2].", "startOffset": 40, "endOffset": 43}, {"referenceID": 2, "context": "Traditionally, machine learning makes predictions or classifications based on the assumption that the training and the testing data come from the same source or distribution [3].", "startOffset": 174, "endOffset": 177}, {"referenceID": 3, "context": "However, this assumption may not hold in many real applications [4]; for example, the training data can be outdated, or insufficient to build a good classifier.", "startOffset": 64, "endOffset": 67}, {"referenceID": 2, "context": "It has been shown that machine learning tasks can benefit from other similar tasks by knowledge transfer [3], [4].", "startOffset": 105, "endOffset": 108}, {"referenceID": 3, "context": "It has been shown that machine learning tasks can benefit from other similar tasks by knowledge transfer [3], [4].", "startOffset": 110, "endOffset": 113}, {"referenceID": 4, "context": "Since parts of the outdated data still contain useful information, knowledge can be transferred from them to train a classifier together with the new data [5].", "startOffset": 155, "endOffset": 158}, {"referenceID": 5, "context": "For traditional transfer learning, training data are communicated between tasks [6].", "startOffset": 80, "endOffset": 83}, {"referenceID": 6, "context": "For example, training data may come from different nodes of a wireless sensor network (WSN), and their communication with a fusion center can be either costly or restricted due to scalability, privacy or power limitations [7].", "startOffset": 222, "endOffset": 225}, {"referenceID": 7, "context": "With alternating direction method of multipliers (ADMoM) [8], the centralized problem can be solved in a fully distributed way.", "startOffset": 57, "endOffset": 60}, {"referenceID": 5, "context": "Note that the problem of transfer learning between tasks in one node can be viewed as a transfer learning problem studied in [6].", "startOffset": 125, "endOffset": 128}, {"referenceID": 6, "context": "Besides, the problem of distributed machine learning with a single task is a distributed support vector machines (DSVM) problem recently studied in [7].", "startOffset": 148, "endOffset": 151}, {"referenceID": 5, "context": "Our research is closely related to multitask learning [6], [9], transfer learning [10], and distributed machine learning [7], [11], [12].", "startOffset": 54, "endOffset": 57}, {"referenceID": 8, "context": "Our research is closely related to multitask learning [6], [9], transfer learning [10], and distributed machine learning [7], [11], [12].", "startOffset": 59, "endOffset": 62}, {"referenceID": 9, "context": "Our research is closely related to multitask learning [6], [9], transfer learning [10], and distributed machine learning [7], [11], [12].", "startOffset": 82, "endOffset": 86}, {"referenceID": 6, "context": "Our research is closely related to multitask learning [6], [9], transfer learning [10], and distributed machine learning [7], [11], [12].", "startOffset": 121, "endOffset": 124}, {"referenceID": 10, "context": "Our research is closely related to multitask learning [6], [9], transfer learning [10], and distributed machine learning [7], [11], [12].", "startOffset": 126, "endOffset": 130}, {"referenceID": 11, "context": "Our research is closely related to multitask learning [6], [9], transfer learning [10], and distributed machine learning [7], [11], [12].", "startOffset": 132, "endOffset": 136}, {"referenceID": 3, "context": "In this paper, we consider multi-task learning as a scenario of transfer learning, since it can be easily extended to transfer learning by assigning a larger weight to the loss function of the target tasks [4].", "startOffset": 206, "endOffset": 209}, {"referenceID": 5, "context": "Both [6] and [9] have focused on multitask learning, and they have shown that multi-task learning outperforms single-task learning.", "startOffset": 5, "endOffset": 8}, {"referenceID": 8, "context": "Both [6] and [9] have focused on multitask learning, and they have shown that multi-task learning outperforms single-task learning.", "startOffset": 13, "endOffset": 16}, {"referenceID": 9, "context": "have presented in [10] a self-taught learning framework where the knowledge from unlabeled data is used to improve the performance of a given classification task.", "startOffset": 18, "endOffset": 22}, {"referenceID": 10, "context": "Both [11] and [7] have presented approaches on DSVMs where information, such as support vectors and decision variables, is communicated between nodes to achieve a better global performance more efficiently.", "startOffset": 5, "endOffset": 9}, {"referenceID": 6, "context": "Both [11] and [7] have presented approaches on DSVMs where information, such as support vectors and decision variables, is communicated between nodes to achieve a better global performance more efficiently.", "startOffset": 14, "endOffset": 17}, {"referenceID": 7, "context": "\u2022 We develop a distributed transfer support vector machine (DTSVM) algorithm with Alternating Direction Method of Multipliers (ADMoM) [8].", "startOffset": 134, "endOffset": 137}, {"referenceID": 12, "context": "Decision variables {\u0175\u2217 t , b\u0302\u2217 t } can be found by solving the following minimization problem [13]:", "startOffset": 94, "endOffset": 98}, {"referenceID": 13, "context": "With the assumption that different tasks are related to each other on the basis of similarity between distributions of samples Xt [14], the decision variables \u0175t , b\u0302t can be divided into: \u0175t = w0 +wt ; b\u0302t = b0 +bt , where w0 and", "startOffset": 130, "endOffset": 134}, {"referenceID": 3, "context": "b0 are common terms over all tasks, while wt and bt are task specific terms [4], [6].", "startOffset": 76, "endOffset": 79}, {"referenceID": 5, "context": "b0 are common terms over all tasks, while wt and bt are task specific terms [4], [6].", "startOffset": 81, "endOffset": 84}, {"referenceID": 7, "context": "Problem (5) can be solved iteratively in a distributed way with ADMoM [8], which is shown as the following proposition.", "startOffset": 70, "endOffset": 73}, {"referenceID": 6, "context": "Evolution of the global risks of DTSVM and DSVM [7] training Task 1 and Task 3.", "startOffset": 48, "endOffset": 51}, {"referenceID": 14, "context": "All the images have been pre-processed with principal component analysis (PCA) into vectors with a dimension of 10 [16].", "startOffset": 115, "endOffset": 119}, {"referenceID": 12, "context": "The algorithm of CSVM can be acquired from [13].", "startOffset": 43, "endOffset": 47}, {"referenceID": 6, "context": "The algorithm of DSVM can be found in [7], which only shares the values of decision variables during the training process.", "startOffset": 38, "endOffset": 41}, {"referenceID": 7, "context": "Problem (5) can be solved in a distributed way with ADMoM [8], which solves the following problem:", "startOffset": 58, "endOffset": 61}, {"referenceID": 6, "context": "We follow a similar step in [7], by setting", "startOffset": 28, "endOffset": 31}, {"referenceID": 7, "context": "2 and Appendix A in [8].", "startOffset": 20, "endOffset": 23}], "year": 2017, "abstractText": "Transfer learning has been developed to improve the performances of different but related tasks in machine learning. However, such processes become less efficient with the increase of the size of training data and the number of tasks. Moreover, privacy can be violated as some tasks may contain sensitive and private data, which are communicated between nodes and tasks. We propose a consensus-based distributed transfer learning framework, where several tasks aim to find the best linear support vector machine (SVM) classifiers in a distributed network. With alternating direction method of multipliers, tasks can achieve better classification accuracies more efficiently and privately, as each node and each task train with their own data, and only decision variables are transferred between different tasks and nodes. Numerical experiments on MNIST datasets show that the knowledge transferred from the source tasks can be used to decrease the risks of the target tasks that lack training data or have unbalanced training labels. We show that the risks of the target tasks in the nodes without the data of the source tasks can also be reduced using the information transferred from the nodes who contain the data of the source tasks. We also show that the target tasks can enter and leave in real-time without rerunning the whole algorithm.", "creator": "LaTeX with hyperref package"}}}