{"id": "1706.05059", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jun-2017", "title": "Conjunctions of Among Constraints", "abstract": "Many protection future constraints else but encoded as a consists of example constraints. An addition optimization largest must when number well the variables far commercial scope prominent value becomes must a prespecified set, which nobody call creation range, is are none rather bounds. It exists based idea domain interfaces algorithms could benefit from methodology yet of interaction however among constraints so that rational why it percolates all taking into criteria groups whose necessity together. The present kayl - per reunifying away a systematic judicial making put actual under part whole is immediate to obtain efficient different complete domain filtering iterative work conjunctions to including constraints. We first he shifts that banning on the own approaches and the range of later among adjusting are necessary turn verify meaningful analysts. Then, we derive old whereby impact - industry runtime optimized already present groups electronic. In particular, it common result that the algorithm unifies has generalizes taken ago ownership report.", "histories": [["v1", "Thu, 15 Jun 2017 19:51:52 GMT  (35kb)", "http://arxiv.org/abs/1706.05059v1", "15 pages plus appendix"]], "COMMENTS": "15 pages plus appendix", "reviews": [], "SUBJECTS": "cs.AI cs.LO", "authors": ["victor dalmau"], "accepted": false, "id": "1706.05059"}, "pdf": {"name": "1706.05059.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n70 6.\n05 05\n9v 1\n[ cs\n.A I]\n1 5\nJu n\n20 17"}, {"heading": "1 Introduction", "text": "Global constraints play a major role in constraint programming. Very informally, a global constraint is a constraint, or perhaps more precisely, a family of constraints, which is versatile enough to be able to express restrictions that are encountered often in practice. For example, one of the most widely used global constraints is the \u2019All different\u2019 constraint, AllDiff(S) where S = {x1, . . . , xn} is a set of variables, which specifies that the values assigned to the variables in S must be all pairwise different. This sort of restriction arises naturally in many areas, such as for example scheduling problems, where the variables x1, . . . , xn could represent n activities that must be assigned different times of a common resource.\nBesides is usefulness in simplifying the modeling or programming task, global constraints also improve greatly the efficiently of propagation-search based solvers. This type of solver performs a tree search that constructs partial assignments and enforces some sort of propagation or local consistency that prunes the space search. Different forms of consistency, including (singleton) bounds consistency, (singleton, generalized) arc-consistency, path consistency and many others, can be used in the propagation phase. One of the most commonly used forms of local consistency is domain consistency, also called generalized arc-consistency. A domain consistency algorithm keeps, for every variable v, a list, L(v), of feasible values, which is updated, by removing a value d from it, when some constraint\nin the problem guarantees that v cannot take value d in any solution. One of the key reasons of the success of global constraints is that they enable the use of efficient filtering algorithms specifically tailored for them.\nSeveral constraints studied in the literature including AllDiff[24],GCC[27], Symmetric-GCC [21], Sequence [6], GlobalSequencing [34], OrderedDistribute [28], and CardinalityMatrix [33] can be decomposed as the conjunction of a simpler family of constraints, called among constraints [6]. An among constraint has the form Among(S,R,min,max) where S is again a set of variables called the scope, R is a subset of the possible values, called the range, and min,max are integers This constraint specifies that the number of variables in S that take a value in R must be in the range {min, . . . ,max}. For example, the constraint AllDiff(S) can be expressed as the conjunction of constraints Among(S, {d1}, 0, 1), . . . ,Among(S, {dk}, 0, 1) where d1, . . . , dk are the set of all feasible values for the variables in S.\nBesides encoding more complex global cardinality constraints, conjunctions of among constraints, (CAC), appear in many problems, such as Sudoku or latin squares. In consequence,CACs have been previously studied [10,32,38], specially the particular case of conjunctions of AllDiff constraints [2,3,9,13,22,23,25]. Although deciding the satisfiability of an arbitrary conjunction of among constraints is NP-complete [32] this body of work shows that sometimes there are benefits in reasoning about the interaction between the among constraints. Hence, it is important to understand under which circumstances among constraints can be combined in order to endow CSP solvers with the ability to propagate taking into consideration several among constraints simultaneously. The aim of the present paper is to contribute to this line of research. To this end we first observe that restrictions on both the scope and the range of the among constraints are necessary to obtain meaningful results. Then we embark in a systematic study of which such restrictions guarantee efficient propagation algorithms. In particular, we introduce a general condition such that every CAC satisfying it admits an efficient and complete domain filtering algorithm. This condition basically expresses that the matrix of a system of linear equations encoding the CAC instance belongs to a particular class of totally unimodular matrices known as network matrices. This allows to reformulate the domain filtering problem in terms of flows in a network graph and apply the methodology derived by Re\u0301gin [30,31]. The algorithm thus obtained, although simple, unifies and generalizes existing domain filtering algorithms for several global constraints, including AllDiff, GCC, Sequence, Symmetric-GCC, OrderedDistribute as well as for other problems expressed as conjunctions of among constraints in [29,32]. A nice feature of our approach is that it abstracts out the construction of the network flow problem, so that when exploring a new CAC one might leave out the usually messy details of the design of the network graph and reason purely in combinatorial terms.\nSeveral filtering methods have been obtained by decomposing a global constraint into a combination of among constraints. For example the first polynomialtime filtering algorithm for the Sequence constraint [38] is obtained explicitely\nin this way. However, there have been very few attempts to determine sistematically which particular conjunctions of among constraints allow efficient filtering algorithms. The seminal paper in this direction is [31] which identifies several combinations of among and GCC constraints that admit a complete and efficient domain filtering algorithm (see Section 6 for more details). Our approach is more general as it subsumes the tractable cases introduced in [31]. Another closely related work is [29] where two tractable combinations of boolean CACs, called TFO and 3FO, are identified. The approach in [29] differs from ours in two aspects: it deals with optimization problem and also considers restricions on the min and max parameters of the among constraints while we only consider restriction on the scope and range. A different family of CACs has been investigated in [10] although the work in [10] focuses in bound consistency instead of domain consistency.\nOther approaches to the design of filtering algorithms for combinations (but not necessarily conjunctions) of global (but not necessarily among) constraints are described in [4,7,8]. The method introduced in [4] deals with logical combinations of some primitive constraints but differs substantially from ours in the sense that it cannot capture a single among constraint. The work reported in [7,8] does not guarantee tractability.\nSeveral proofs are omiitted due to space restrictions. They can be found in the Appendix."}, {"heading": "2 Preliminaries", "text": "A conjunction of among constraints, (CAC) is a tuple (V,D,L, C) where V is a finite set whose elements are called variables, D is a finite set called domain, L : V \u2192 2D is a mapping that sends every variable v to a subset of D, which we call its list, and C is a finite set of constraints where a constraint is an expression of the form Among(S,R,min,max) where S \u2286 V is called the scope of the constraint, R \u2286 D is called range of the constraint, and min,max are integers satisfying 0 \u2264 min \u2264 max \u2264 |S|.\nA solution of (V,D,L, C) is a mapping s : V \u2192 D such that s(v) \u2208 L(v) for every variable v \u2208 V and min \u2264 |{v \u2208 S | s(v) \u2208 R}| \u2264 max for every constraint Among(S,R,min,max) in C.\nExample 1. (GCC andAllDiff constraints) The global cardinality constraint1, GCC [27] corresponds to instances (V,D,L, C) where all the constraints have the form Among(V, {d},min,max) with d \u2208 D. The AllDiff constraint is the particular case obtained when, additionally, min = 0 and max = 1.\nLet I = (V,D,L, C) be a CAC. We say that a value d \u2208 D is supported for a variable v \u2208 V if there is a solution s of I with s(v) = d. In this paper we focus in the following computational problem, which we will call domain filtering: given a CAC, compute the set of all the non supported values for each of its variables.\n1 We want to stress here that a global constraint is not a single constraint but, in fact, a family of them.\nThis definition is motivated by the following scenario: think of (V,D,L, C) as defining a constraint which is part of a CSP instance that is being solved by a search-propagation algorithm that enforces domain consistency. Assume that at any stage of the execution of the algorithm, L encodes the actual feasible values for each variable in V . Then, the domain filtering problem is basically the task of identifying all the values that need to be pruned by considering the constraint encoded by (V,D,L, C)."}, {"heading": "3 Network hypergraphs", "text": "An hypergraph H is a tuple, (V (H), E(H)), where V (H) is a finite set whose elements are called nodes and E(H) is set whose elements are subsets of V (H), called hyperedges. An hypergraph is totally unimodular if its incidence matrixM is totally unimodular, that is, if every square submatrix of M has determinant 0, +1, or \u22121. In this paper we are concerned with a subset of totally unimodular hypergraphs called network hypergraphs. In order to define network hypergraph we need to introduce a few definitions.\nAn oriented tree T is any directed tree obtained by orienting the edges of an undirected tree. A path p in T is any sequence x1, e1, x2, . . . , en\u22121, xn where x1, . . . , xn are different vertices of T , e1, . . . , en\u22121 are edges in T and for every 1 \u2264 i < n, either ei = (xi, xi+1) or ei = (xi+1, xi). The polarity of an edge e \u2208 E(T ) wrt. p is defined to be +1 (or positive) if e = (xi, xi+1) for some 1 \u2264 i < n, \u22121 (or negative) if e = (xi+1, xi) for some 1 \u2264 i < n, and 0 if e does not appear in p. A path p has positive (resp. negative) polarity if all its edges have positive (resp. negative) polarity. Paths with positive polarity are also called directed paths. Since an oriented tree does not contain symmetric edges, we might represent a path by giving only its sequence of nodes x1, . . . , xn.\nWe say that an oriented tree T defines an hypergraph H if we can associate to every hyperedge h \u2208 E(H) an edge eh \u2208 E(T ) and to every node v \u2208 V (H) a directed path pv in T such that for every v \u2208 V (H) and h \u2208 E(V ), v \u2208 h if and only if eh belongs to pv. We say that an H is a network hypergraph if there is an oriented tree that defines it.\nExample 2. The hypergraph H with variable-set {v1, . . . , v6} and hyperedge-set {h1, . . . , h5} given in Figure 1a is a network hypergraph as it is defined by tree T given in Figure 1b where we have indicated, using labels on the edges, the edge in T associated to every hyperedge in H . We associate to every variable vi, 1 \u2264 i \u2264 6 the directed path s(i\u22121 mod 2), r, t(i\u22121 mod 3) in T . It can be readily checked that under this assignment T defines H .\nSometimes, it will be convenient to assume that the tree T defining H is minimal in the sense that no tree with fewer nodes defines H . Minimal trees have the nice property that every edge e in T is associated with some hyperedge ofH . Indeed, assume that some edge e = (x, y) is not associated to any hyperedge in H , then one could find an smaller tree T defining H by contracting edge e, that is, by merging x and y into a new node z that has as in-neighbours the\nunion of all in-neighbours of x and y and, as out-neighbours, the union of all out-neighbours of x and y.\nSince the vast majority of the trees defined in this paper will be oriented we shall usually drop \u2019oriented\u2019. So, unless, otherwise explicitly stated, a tree is always an oriented tree. Finally, we note that one can decide whether a given hypergraph is a network hypergraph in time O(e3v2) where e is the number of hyperedges and v is the number of nodes (see chapter 20 in [35] for example)."}, {"heading": "4 Restricting only the scope or the range", "text": "It has been shown by Re\u0301gin [32] that the domain filtering problem for CACs is NP-hard. Still, efficient algorithms are known for some particular cases. It seems natural to start by asking which tractable subcases of the problem can be explained by considering only the scopes of the constraints. This question has a close similarity to the study of the so-called structural restrictions of the CSP (see, for example [18] for a survey) and, not surprisingly, it can be solved by applying results developed there. Indeed, it follows easily from a result of Fa\u0308rnquivst and Jonsson [12] that, modulo some mild technical assumptions, if one allows arbitrary ranges in constraints, then the domain filtering problem is solvable in polynomial time if and only if the hypergraph of the scopes of the constraints has bounded tree-width (see Appendix A for precise statement and the proof). This result, although delineates exactly the border between tractability and intractability, turns out to be not very useful in explaining the tractability of global constraints. This is due to the fact that global cardinality constraints defined by conjunctions of among constraints usually have constraints with large scopes and the cardinality of the scope in a constraint is a lower bound on the tree-width of its scope hypergraph.\nOne can also turn the attention to the range of constraints and inquiry whether there are tractable subcases of the problem that can be explained only by the range of the constraints. Here, again the response is not too useful. Indeed, it is very easy to show (see again Appendix A) that as soon as we allow some non-trivial range R (that is some range different than the empty set and than the whole domain) and arbitrary scopes in the among constraints, then the domain filtering problem becomes NP-complete.\nIn view of this state of affairs it is meaningful to consider families of conjunctions of among constraints that are obtained by restricting simultaneously\nthe scope and the range of the constraints occurring in them. This is done in the next section."}, {"heading": "5 A flow-based algorithm", "text": "Let I = (V,D,L, C) be conjunction of among constraints. We will deal first with the case in which D is a boolean, say D = {0, 1}. Hence, we can assume that every constraint Among(S,R,min,max) in C satisfies R = {1} since, if R = {0} it can be reformulated as Among(S, {1}, |S|\u2212max, |S| \u2212min). We also assume that L(v) = {0, 1} for every v \u2208 V since if L(v) 6= {0, 1} we could obtain easily an equivalent instance without variable v.\nIt is easy to construct a system of linear equations whose feasible integer solutions encode the solutions of I. Let v1, . . . , vn be the variables of I and let Cj = (Sj , {1},minj,maxj), j = 1, . . . ,m, be its constraints. The system has variables xi(1 \u2264 i \u2264 n), yj(1 \u2264 j \u2264 m) and the following equations:\nyj + \u2211\nvi\u2208Sj\nxi = maxj j = 1, . . . ,m\n0 \u2264 yj \u2264 maxj \u2212minj j = 1, . . . ,m\n0 \u2264 xi \u2264 1 i = 1, . . . , n\nwhich we express in matrix form as\nMz = a\n0 \u2264 z \u2264 c\nwith zT = (x1, . . . , xn, y1, . . . , ym) (see Example 3). If M is totally unimodular then one can perform domain filtering in polynomial time. Indeed, for every vi \u2208 V and d \u2208 L(v), we might decide whether d is a supported value for v as follows: add equation xi = d to the system and decide whether there exists a feasible solution of its linear relaxation using a LP solver. It follows from total unimodularity (see Theorem 19.1 in [35] for example) that such a feasible solution exists if and only if d is a support for v.\nHowever, this approach implies invoking O(n) times a LP solver, which might be too expensive to be practical, since, in addition, a propagation-based algorithm might call a domain filtering algorithm many times during its execution. To overcome this difficulty we shall require further conditions on the matrix M . To this end, we define the hypergraph associated to instance I to be the hypergraph H with V (H) = V and E(H) = {Sj | 1 \u2264 j \u2264 m}.\nNow, assume that H is a network hypergraph defined by a tree T . In this case, one can use specific and more efficient methods like the network simplex algorithm (see for example [1]) instead of a general purpose LP solver. However, it is still possible to do better (and avoid the O(n) calls to the network simplex algorithm) by transforming it into a maximum flow problem. This idea has been used in [26] to obtain a domain filtering algorithm for the Sequence constraint.\nMore precisely, [26] deals with the particular case of network matrices defined by a directed path. Our approach draws upon [26] and generalizes it to network matrices defined by arbitrary trees. This is done as follows.\nLet P be the incidence matrix of T . That is, let t1, . . . , tm+1 be an arbitrary ordering of nodes in T and define P to be the ((m+ 1)\u00d7m)-matrix where Pi,j is +1 if edge eSj starts at ti, \u22121 if eSj ends at ti, and 0 otherwise.\nLet r be a m-ary (column) vector and let p be a path in T . We say that r is the indicator vector of p if for every j = 1, . . . ,m, rj is the polarity of eSj wrt. p. The next observation follows directly from the definitions.\nObservation 1 Let p be a path in T and let r be its indicator vector. Then, the ith entry, (Pr)i, of Pr, is +1 if ti is the first node in p, \u22121 if ti is the last node in p, and 0 otherwise.\nThe next two lemmas follow directly from the previous observation.\nLemma 1. P has full rank.\nProof. Let P \u2032 be the (m \u00d7 m) matrix obtained by removing the last row (corresponding to vertex tm+1) and consider the (m \u00d7 m)-matrix Q such that for every i = 1, . . . ,m, the ith column of Q, which we shall denote as Q\u2217,i, is the indicator vector of the unique path in T starting at ti and entding at tm+1. It follows from Observation 1 that P \u2032Q is the identity matrix.\nThen, since P has full rank we can obtain an equivalent system PMz = Pa by multiplying both sides of Mz = a by P . Let N = PM and b = Pa (see Example 3).\nLemma 2. In every column of N one entry is +1, one entry is \u22121, and all the other entries are 0.\nProof. It is only necessary to show that every column, M\u2217,k, k = 1, . . . ,m+n of M is the indicator vector of some directed path in T . If the variable corresponding to the k-column is xi for some 1 \u2264 i \u2264 n then by construction M\u2217,k is the indicator column of the path associated to vi in T . Otherwise, if the variable corresponding to column k is yj for some 1 \u2264 j \u2264 m then M\u2217,k is the indicator vector of the directed path containing only edge eSj . Hence, matrix N is the incidence matrix of a directed graph G. Note that, by definition, G contains an edge ek, k = 1, . . . ,m + n for each variable zk and a node uj, j = 1, . . . ,m + 1 for each row in N (that is, for every node in T ). Define the capacity of every edge ek to be ck. Then, feasible solutions of the system correspond precisely to flows where every node uj has a supply/demand specified by bj (more precisely, node uj has a demand of bj units if bj > 0 and a suply of \u2212bj units if bj < 0). It is well know that this problem can be reduced to the (standard) maximum flow problem by adding new source and sink nodes s, t and edges from s to uj with capacity bj whenever bj > 0 and from uj to t with capacity \u2212bj whenever bj < 0.\nExample 3. Let I be a boolean instance with variables {v1, . . . , v6} and constraints: C1 = Among({v1, v4}, {1}, 0, 1), C2 = Among({v2, v5}, {1}, 0, 1), C3 = Among({v3, v6}, {1}, 0, 1), C4 = Among({v1, v3, v5}, {1}, 1, 1), C5 = Among({v2, v4, v6}, {1}, 1, 1).\nThe specific values for M , a and c of the ILP formulation of I are:\ny1 y2 y3 x1 x2 x3 x4 x5 x6 \n  \n\n  \n\n  \n\n  \nC1 1 0 0 1 0 0 1 0 0 1 C2 0 1 0 0 1 0 0 1 0 1\nM = C3 0 0 1 0 0 1 0 0 1 a = 1 C4 0 0 0 1 0 1 0 1 0 1 C5 0 0 0 0 1 0 1 0 1 1\n( )\ncT = 1 1 1 1 1 1 1 1 1\nNote that since mini = maxi for i = 4, 5 we did not need to add the slack variables y4 and y5. The hypergraph of this instance is precisely the hypergraph H in Example 2. In particular, hi is the hypererdge corresponding to the scope of constraint Ci for i = 1, . . . , 5. The matrix P obtained from the tree T defining H is:\nh1 h2 h3 h4 h5 \n    \n\n     t0 \u22121 0 0 0 0 t1 0 \u22121 0 0 0 t2 0 0 \u22121 0 0 s0 0 0 0 1 0 s1 0 0 0 0 1 r 1 1 1 \u22121 \u22121\nMultiplying M and c by P we obtain:\ny1 y2 y3 x1 x2 x3 x4 x5 x6 \n    \n\n    \n\n    \n\n    \nt0 \u22121 0 0 \u22121 0 0 \u22121 0 0 \u22121 t1 0 \u22121 0 0 \u22121 0 0 \u22121 0 \u22121\nN = PM = t2 0 0 \u22121 0 0 \u22121 0 0 \u22121 b = Pa = \u22121 s0 0 0 0 1 0 1 0 1 0 1 s1 0 0 0 0 1 0 1 0 1 1 r 1 1 1 0 0 0 0 0 0 1\nThe feasible solutions of the previous LP correspond to the feasible flows of the network in Figure 2a, where nodes s0, s1 and r have a supply of one unit of flow and nodes y0, y1, y2 have a demand of one unit of flow. Figure 2b contains the result of transforming the network in Figure 2a to a (standard) max flow problem. In both networks all edges have capacity 1.\nIt follows from this construction that for every 1 \u2264 i \u2264 n and every d = {0, 1}, there is a solution s of I with s(vi) = d if and only if there is a saturating flow (that is, a flow where all the edges leaving s or entering t are at full capacity) such that the edge associated to xi carries d units of flow. Re\u0301gin [30,31] has shown that this later condition can be tested simultaneously for all 1 \u2264 i \u2264 n and d \u2208 {0, 1} by finding a maximal flow and computing the strongly connected components of its residual graph. Finding a maximal flow of a network with\n\u22121\n\u22121\n\u22121\n1\n1\n1r\ns0\ns1\nt0\nt1\nt2\nFig. 2a: Network with suppies/demands\nr\ns0\ns1\nt0\nt1\nt2\ns t\nFig. 2b: Standard flow network obtained from (2a)\nintegral capacities can be done in time O(min(v2/3, e1/2)e log(v2/e) log u) using Goldberg and Rao\u2019s algorithm [17] where v is the number of vertices, e is the number of edges, and u is the maximum capacity of an edge. Computing the strongly connected components of the residual graph takes O(v + e) time using Tarjan\u2019s algorithm [36]. By construction, the network derived by our algorithm satisfies e \u2264 n+ 2m and v \u2264 m+ 1. Furthermore, it is not difficult to see that u \u2264 mn. Indeed, note that the capacity of any edge is either some entry, ci, of vector c or the absolute value of some entry, bi, of vector b. It follows directly from the definition of c, that all its entries are at most n. As for b, the claim follows from the fact that b = Pa where, by construction, a has m entries where every entry is in the range {1, . . . , n} and every entry in P is in {\u22121, 0, 1}.\nHence, if we define f(n,m) to be min(m2/3, (n+m)1/2)(n+m) log(m2/(n+ m)) logmn) we have:\nLemma 3. There is a domain filtering algorithm for conjunctions of boolean among constraints whose associated hypergraph is a network hypergraph, which runs in time O(f(n,m)) where n is the number of variables and m is the number of constraints, assuming the instance is presented as a network flow problem.\nIt is customary, when analizying the time complexity of domain filtering to report, additionally, the so-called time complexity \u2019down a branch of a search tree\u2019 which consists in the aggregate time complexity of successive calls to the algorithm, when at each new call, the list of some of the variables has been decreased (as in the execution of a propagation-search based solver). It was observed again by Re\u0301gin [31] that, in this setting, it is not necessary, to solve the flow problem from scratch at each call, leading to a considerable redution in total time. Applying the scheme in [31], we obtain that the time complexity down a branch of a search tree of our algorithm is O(n(n+m)). We ommit the details because they are faily standard (see [31]).\nThere are minor variants (leading to the same asymptotic complexity) obtained by modifying the treatment of the slack variables. Here we will discuss two of them. In the first variant, used in [26], one encodes a constraint Cj = (Sj , {1},minj,maxj) with two equations yj + \u2211 vi\u2208Sj xi = maxj , and\n\u2212zj + \u2211\nvi\u2208Sj xi = minj where yj and zj are new slack variables satisfying\n0 \u2264 yj, zj . This encoding produces a network that has m more nodes and edges. In a second variant, one encodes a constraint Cj with the equation \u2212yj + \u2211 vi\u2208Sj\nxi = 0 where yj satisfies minj \u2264 yj \u2264 maxj . Under this encoding, our approach produces a network problem where, instead of having nodes\nwith specified suply or demand, we have edges with minimum demand. The asymptotic time bounds in all variants are identical.\nIf the instance is not presented as a network flow problem then one would need to add the cost of transforming the instance into it. However this cost would be easily amortized as a domain filtering algorithm is invoked several times during the execution of a constraint solver2. Furthermore, in practical scenarios, the conjunction of among constraints will encode a global constraint from a catalog of available global constraints. Hence, it is reasonable to assume that the formulation of the global constraint as a network flow problem can be precomputed.\nThis approach can be generalized to non-boolean domains via boolean encoding. The choice of boolean encoding might depend on the particular instance at hand but for concreteness we will fix one. The canonical booleanization (see Example 4) of a conjunction I = (V,D,L, C) of among constraints with |D| \u2265 3 is the boolean instance (V \u00d7D,{0,1}, Lb, Cb) where Lb(v, d) = {0, 1} if d \u2208 L(v) and {0} otherwise, and Cb contains:\n\u2013 Among(S\u00d7R, {1},min,max) for every constraintAmong(S,R,min,max) \u2208 C, and \u2013 Among({v}\u00d7D, {1}, 1, 1) for every variable v \u2208 V . This family of constraints are called non-empty assignment constraints.\nThat is, the intended meaning of the encoding is that (v, d) \u2208 V \u00d7 D is true whenever v takes value d.\nWe define the hypergraph H associated to I to be the hypergraph associated to the canonical booleanization of I. That is, V (H) is V \u00d7 D and E(H) contains hyperedge {(v, d) | v \u2208 S, d \u2208 R} = S \u00d7 R for every constraint Among(S,R,min,max) in C, and hyperedge {(v, d) | d \u2208 D} = {v} \u00d7 D for every variable v \u2208 V . Thus, for arbitrary domains, we have:\nCorollary 1. There is a domain filtering algorithm for conjunctions (V,D,L, C) of among constraints whose associated hypergraph is a network hypergraph, which runs in time O(f(n,m)) where n = \u2211 v\u2208V |L(v)| and m = |C| + |V |, assuming the instance is presented as a network flow problem.\nProof. It just follows from observing that the canonical booleanization of instance (V,D,L, C) has n = \u2211 v\u2208V |L(v)| variables and m = |C|+ |V | constraints."}, {"heading": "6 Some applications", "text": "The aim of this section is to provide evidence that the kind of CACs covered by the approach developped in Section 5 are often encountered in practice. To\n2 In fact, as shown in [30,31], it is only necessary to solve the max flow problem during the first invocation so it could be argued that a more realistic bound on the running time of the algorithm is O(n+m).\nthis end, we shall revisit several families of CACs for which domain filtering have been previously introduced and show how they can solved and, in some cases generalized, using our algorithm. Furthermore, we shall compare, whenever possible, the time complexity bounds of our algorithm with other state-of-the-art algorithms for the same problem. Like other flow-based algorithms, the algorithm proposed here has very good time complexity down a branch of the search tree. However, we will only consider in our comparison the cost of calling the algorithm just once. This is due to the fact that, once the size of the network produced is under a certain threshold, the total cost down a branch of the search tree is dominated by the cost of the incremental updates and, hence, it cannot be used to assess the comparative quality of different flow-based algorithms. Furthermore, we will try to compare, whenever possible, the parameteres of the obtained network flow problem (number of nodes, edges, capacities of the edges) instead of the actual running time since the latter is dependend on the choice of the maxflow algorithm. Somewhat surprisingly, in many of the cases, even if we did not attempt any fine-tuning, the network produced by the algorithm is essentially equivalent to the network produced by specific algorithms."}, {"heading": "6.1 Disjoint constraints", "text": "As a warm up we shall consider the GCC and AllDiff constraints. We have seen in Example 1 that both can be formulated as a conjunction (V,D,L, C) of among constraints of the form Cd = Among(V, {d},mind,maxd), d \u2208 D. Note that both have the same associated hypergraph H with node-set, V \u00d7D, and edge set E(H) containing hyperedge hv = {v} \u00d7 D for every v \u2208 V , and hyperedge hd = V \u00d7 {d}, for every d \u2208 D.\nIt is not difficult to see (see Example 4) that H is defined by the tree T defined as follows: The node-set of T consists of {r} \u222a V \u222aD where r is a new node. The edge-set of T contains an edge from every v \u2208 V to r (associated to hv) and from r to every node d \u2208 D (associated to hd). Consequently, both GCC and AllDiff are solvable by our algorithm. The network for the GCC using the abovementioned tree T has e = O(|V ||D|) edges, v = |V | + |D| + 3 nodes, and the maximum capacity, u, of an edge is at most |D||V |. Hence, it follows that the total running time of our algorithm for the GCC constraint is O(min(v2/3, e1/2)e log(v2/e) logu). Re\u0301gin\u2019s algorithm [31] has a O(|V |2|D|) complexity which is better when |V | \u2208 O(|D|2/3) but the comparison between the two bounds is not very meaningfull because it mainly reflects a different choice max flow algorithm. Indeed, the network produced by both algorithms are very similar. In particular, the network obtained using the second variant discussed after Lemma 3 is essentially the same described in [31]. The only difference is that the network obtained by our algorithm contains one extra node. In the particular case of the AllDiff constraint, [30] shows how to produce a bipartite matching problem that can be solved using specialized algorithms, such as [20], leading to a total time complexity of O(|V |5/2) which is better than ours.\nExample 4. Consider the constraint AllDiff(s0, s1) where the list of each variable contains the following three values: t0, t1, t2. Then, AllDiff(s0, s1) is encoded as a CAC I with the following constraints: Among({s0, s1}, {t0}, 0, 1), Among({s0, s1}, {t1}, 0, 1), Among({s0, s1}, {t2}, 0, 1).\nThe canonical booleanization of I has variables {s0, s1} \u00d7 {t0, t1, t2} and constraints C1 = Among({s0, s1} \u00d7 {t0}, {1}, 0, 1), C2 = Among({s0, s1} \u00d7 {t1}, {1}, 0, 1), C3 = Among({s0, s1} \u00d7 {t2}, {1}, 0, 1), C4 = Among({s0} \u00d7 {t0, t1, t2}, {1}, 1, 1), and C5 = Among({s1}\u00d7{t0, t1, t2}, {1}, 1, 1). Observe that this instance is, under the renaming vi 7\u2192 (si\u22121 mod 2, ti\u22121 mod 3), the same instance than we have considered previously in Example 3. The network flow problem that our algorithm derives for this instance (see Example 3) is almost identical to the one derived in [31]. Indeed, the network obtained in [31] does not have node r and, instead, requires that the demand of nodes t0, t1, t2 is at most one (instead of exactly one).\nA simple analysis reveals that the same approach can be generalized to instances (V,D,L, C) satisfying the following disjointedness condition: for every pair of constraints Among(S,R,min,max) and Among(S\u2032, R\u2032,min\u2032,max\u2032) in C, (S \u00d7 R) \u2229 (S\u2032 \u00d7 R\u2032) = \u2205. The tractability of such instances was, to the best of our knowledge, not known before. The particular case in which R \u2229 R\u2032 = \u2205 has been previously shown in [32] using a different approach. The proof given in [32] does not construct a flow problem nor gives run-time bounds so we ommit a comparison."}, {"heading": "6.2 Domains consisting of subsets", "text": "Consider the following generalization of our setting where in a CAC (V,D,L, C) every variable v must be assigned to a subset of L(v) (instead of a single element). In this case, the semantics of the among constraint need to be generalized as well. Instead, we will say a constraint Among(S,R,min,max) is satisfied by a mapping s : V \u2192 2D if min \u2264 \u2211 v\u2208S |s(v) \u2229 R| \u2264 max. To avoid confusion we shall refer to this variant of the among constraint as set among constraint. For example, the Symmetric-GCC constraint [21] is precisely a conjunction (V,D,L, C) of set among constraints of the form Among(V, {d},min,max) where d is a singleton which, additionally, might contain constraints of the form Among({v}, D,min,max) restricting the size of the image of a variable v.\nIt is fairly easy to reduce a conjunction of set among constraints I = (V,D,L, C) to a conjunction of (ordinary) among constraints over a boolean domain. Indeed, one only needs to construct the instance (V \u00d7 D,{0,1}, Lb, Cb) where Lb(v, d) = {0, 1} if d \u2208 L(v) and {0} otherwise, and Cb contains Among(S \u00d7 R, {1},min,max) for every constraint Among(S,R,min,max) \u2208 C. Note that the instance thus constructed corresponds exactly to the result of removing the non-empty assignment constraints to the canonical booleanization of I (now regarded as a conjunction of ordinary among constraints). It is then easy to observe that if (V,D,L, C) encodes a Symmetric-GCC constraint then the resulting boolean instance has the same hypergraph, H , than the GCC constraint\nand hence, H is a network matrix. The algorithm in [21] follows closely that in [31] for the GCC constraints, and, in particular, has the same time bounds. Consequently the network flow derived by our algorithm is obtained, again, by adding one extra node with small capacities in the edges to the network introduced in [21]."}, {"heading": "6.3 The sequence constraint", "text": "The Sequence constraint [6] corresponds to instances ({v1, . . . , vn}, D, L, C) with constraints Among({vi, . . . , vi+k}, R,min,max), i = 1, . . . , n\u2212 k for some fixed integers min,max, k, and fixed R \u2286 D. It is not difficult to see that the hypergraph of the canonical booleanization of the Sequence constraint is not a network hypergraph. However, as shown in [26] one obtains an equivalent instance with a network hypergraph using a different encoding in which for every original variable vi \u2208 V , we have a boolean variable xi which is intended to be true whenever vi takes a value in R and false otherwise. Under this alternative encoding we obtain a boolean instance I which consists of constraints Among({xi, . . . , xi+k}, {1},min,max), i = 1, . . . , n\u2212 k. It is shown in [26] that the hypergraph H of the boolean instance I obtained under this encoding satisfies the so-called consecutive-ones property which implies that H is defined by a tree T consisting of a single directed path. Indeed, the network flow obtained by our approach is identical to the one derived in [26] if one encodes Among constraints using the first variant discussed after Lemma 3. Applying Lemma 3 and noting that, in the particular case of the Sequence constraint, we have m = O(n) we obtain the bound O(n3/2 log2 n). By inspecting closely the proof of Lemma 3 this bound can be slightly improved (see Appendix C) to O(n3/2 logn logmax) coinciding with the bound given in [26], which is not surprising since both networks are essentially equivalent. To the best of our knowledge O(n3/2 logn logmax) is the best bound among all complete domain consisteny algorithms for the problem, jointly with the algorithm proposed in [37] which, with time complexity O(n2k), offers gives better bounds when k \u226a n."}, {"heading": "6.4 TFO model", "text": "The TFO model was introduced by Razgon et al. [29] as a generalization of several common global constraints. Formally, a TFO model is a triple (V, F1, F2) where V is a finite set of vertices and F1 and F2 are nonempty families of subsets of V such that two sets that belong to the same family are either disjoint or contained in each other. Each set Y in F1 \u222a F2 is associated with two nonnegative integers minY ,maxY \u2264 |Y |. A subset X of V is said to be valid if minY \u2264 X \u2229 Y \u2264 maxY for every Y \u2208 F1 \u222a F2. The task is to find the largest valid subset. Although the methods introduced in the present paper can be generalized to deal as well with optimization version we will consider only now the feasibility problem consisting in finding a valid subset (or report that none exists).\nFirst, note that the existence of a valid subset in a TFO model can be formulated naturally as a satisfiability problem for a combination of among constraints. Indeed, there is a one-to-one correspondence between the valid subsets of (V, F1, F2) and the solutions of the instance (V, {0, 1}, L, C) where C contains the constraints Among(Y, {1},minY ,maxY ), Y \u2208 F1 \u222a F2, and the list L(v) of every variable v \u2208 V is {0, 1}. The hypergraph H associated to this instance is (V, F1\u222aF2). It follows directly from Lemmas 4 and 5 (see Appendix) that H is a network hypergraph and hence one can use our approach to decide the existence of a feasible solution of a TFO model. It turns out that the network introduced in [29] is essentially equivalent to the network flow problem that would be obtained by our approach using the second variant described after Lemma 3. It is not meaningfull to compare the running time of our algorithm with that of [29] since it deals with an optimization variant."}, {"heading": "6.5 Conjunction of among constraints with full domain", "text": "Some global constraints studied in the literature correspond to conjunctions (V,D,L, C) of among constraints where the scope of every constraint is the full set V of variables. This class contains, of course, the GCC constraint and also several others, since we do not require R to be a singleton. For example, the OrderedDistribute constraint introduced by Petit and Re\u0301gin [28] can be encoded as conjunction (V,D,L, C) of among constraint where where the domain D has some arbitrary (but fixed) ordering d1, . . . , d|D| and in every constraint Among(S,R,min,max), S = V and R is of the form {di, . . . , d|D|}.\nWe shall show that the hypergraph of the conjunction of among constraints defining OrderedDistribute is a network hypergraph. Indeed, with some extra work we have managed to completely characterize allCAC instances containing only constraints with full scope that have an associated network hypergraph.\nTheorem 1. Let I = (V,D,L, C) be a conjunction of among constraints with |D| \u2265 3 such that the scope of each constraint is V . Then, the following are equivalent:\n1. The hypergraph of the canonical booleanization of I is a network hypergraph.\n2. For every pair of constraints in C, their ranges are disjoint or one of them contained in the other.\nIn the particular case of OrderedDistribute constraint, the network obtained by our approach is very related to the network introduced in section ([28], Section V.A). More precisely, the abovementioned network is essentially equivalent to the network that would be obtained by our approach using the second variant described after Lemma 3. However, our algorithm is far from optimal. In particular, a complete filtering algorithm with time complexity O(|V |+ |D|) is given also in [28]."}, {"heading": "6.6 Adding new among constraints to a GCC constraint", "text": "Let (V,D,L, C) be a conjunction of among constraints encoding the GCC constraint (see Example 1) and assume that we are interested in adding several new among constraints to it. In general, we might end up with a hard instance but depending on the shape of the new constraints we might perhaps still preserve tractability. Which among constraint we might safely add? This question has been addressed by Re\u0301gin [32]. In particular, [32] shows that the domain filtering problem is still tractable whenever:\n(a) every new constraint added has scope V and, furthermore, the ranges of every pair of new constraints are disjoint, or (b) every new constraint added has rangeD and furthermore, the scopes of every pair of new constraints are disjoint.\nWe can explore this question by inquiring which families of constraints can be added to an instance (V,D,L, C) encoding GCC such that its associate hypergraph is still a network hypergraph. Somewhat surprisingly we can solve completely this question (see Theorem 2). This is due to the fact that the presence of the global cardinality constraint restricts very much the shape of the tree defining the hypergraph of the instance.\nTheorem 2. Let I = (V,D,L, C) be a conjunction of among constraints containing a global cardinality constraint with scope V with |D| \u2265 3. Then the following are equivalent:\n1. The hypergraph of the canonical booleanization of I is a network hypergraph. 2. In every constraint in C, the scope is a singleton or V , or the range is a\nsingleton or D. Furthermore, for every pair Among(S1, R1,min1,max1), Among(S2, R2,min2,max2) of constraints in C the following two conditions hold: (a) If S1 = S2 = V or S1 = S2 = {v} for some v \u2208 V then R1 and R2 are\ndisjoint or one of them is contained in the other. (b) If R1 = R2 = D or R1 = R2 = {d} for some d \u2208 D then S1 and S2 are\ndisjoint or one of them is contained in the other.\nNote that the previous theorem covers cases (a) and (b) from [32] described at the beginning of this section. The network produced in [32] for the case (a) is essentially equivalent to the one derived by our approach using the second variant described after Lemma 3. For the case (b) [32] does not construct a flow problem nor gives run-time bounds so we ommit a comparison."}, {"heading": "Acknowledgments", "text": "The author would like to thank the anonimous referees for many useful comments. This work was supported by the MEIC under grant TIN2016-76573-C21-P and the MECD under grant PRX16/00266."}, {"heading": "23. Fre\u0301de\u0301ric Lardeux, Eric Monfroy, and Fre\u0301de\u0301ric Saubion. Interleaved alldifferent", "text": "constraints: CSP vs. SAT approaches. In Proceedings of AIMSA\u201908, pages 380\u2013 384, 2008. 24. Jean-Louis Laurie\u0300re. A language and a program for stating and solving combinatorial problems. Artif. Intell., 10(1):29\u2013127, 1978. 25. Dimitris Magos, Ioannis Mourtos, and Gautam Appa. A polyhedral approach to the alldifferent system. Math. Program., 132(1-2):209\u2013260, 2012. 26. Michael J. Maher, Nina Narodytska, Claude-Guy Quimper, and Toby Walsh. Flowbased propagators for the SEQUENCE and related global constraints. In Proceedings of CP\u201908, pages 159\u2013174, 2008. 27. A. Oplobedu, J. Marcovitch, and Y. Toubier. Charme: Un langage industriel de programmation par contraintes, illustrp\u0301ar une application chez renault. In Proceedings of 9th International Workshop on Expert Systems and their Applications, pages 55\u201370, 1989. 28. Thierry Petit and Jean-Charles Re\u0301gin. The ordered distribute constraint. International Journal on Artificial Intelligence Tools, 20(4):617\u2013637, 2011. 29. Igor Razgon, Barry O\u2019Sullivan, and Gregory M. Provan. Generalizing global constraints based on network flows. In Proceedings of CSCLP\u201907, pages 127\u2013141, 2007. 30. Jean-Charles Re\u0301gin. A filtering algorithm for constraints of difference in csps. In Proceedings of AAAI\u201994, pages 362\u2013367, 1994. 31. Jean-Charles Re\u0301gin. Generalized arc consistency for global cardinality constraint. In Proceedings of AAAI\u201996, pages 209\u2013215, 1996. 32. Jean-Charles Re\u0301gin. Combination of among and cardinality constraints. In Proceedings of CPAIOR\u201905, pages 288\u2013303, 2005. 33. Jean-Charles Re\u0301gin and Carla P. Gomes. The cardinality matrix constraint. In Proceedings of CP\u201904, pages 572\u2013587, 2004. 34. Jean-Charles Re\u0301gin and Jean-Francois Puget. A filtering algorithm for global sequencing constraints. In Proceedings of CP\u201997, pages 32\u201346, 1997. 35. Alexander Schrijver. Theory of Linear and Integer Programming. Wiley, 1998. 36. Robert Endre Tarjan. Depth-first search and linear graph algorithms. SIAM J.\nComput., 1(2):146\u2013160, 1972. 37. Willem Jan van Hoeve, Gilles Pesant, Louis-Martin Rousseau, and Ashish Sabhar-\nwal. Revisiting the sequence constraint. In Proceedings of CP\u201906, pages 620\u2013634, 2006. 38. Willem Jan van Hoeve, Gilles Pesant, Louis-Martin Rousseau, and Ashish Sabharwal. New filtering algorithms for combinations of among constraints. Constraints, 14(2):273\u2013292, 2009."}, {"heading": "Appendix A: Tractable subcases of the domain filtering problem restricting only the scope or the range in the constraints", "text": "If I is a set of conjunctions of among constraints, we shall denote byDomFilter(I) the restriction of the domain filtering problem to instances in I. Our ultimate goal would be to characterize precisely for which sets I, DomFilter(I) has efficient algorithms.\nThe first question that we address is the following: which subcases of the problem can be explained by considering only the scopes of the constraints? The\nscopes occurring in an instance can be characterized by an hypergraph. More precisely, let I = (V,D,L, C) be a conjunction of among constraints. The scope hypergraph of I is the hypergraph H with node set V (H) = V and that contains an hyperedge for every scope occurring in a constraint in C. Formally,\nE(H) = {S | Among(S,R,min,max) \u2208 C}\nLet H be a (possibly infinite) set of hypergraphs. We denote by Scope(H) the collection of instances I of the domain filtering problem whose scope hypergraph belongs to H. Our question can be formalized in the following manner: for which sets,H, of hypergraphs, is DomFilter(Scope(H)) efficiently solvable? Note that if I is an instance whose scope hypergraphH is a subhypergraph of someH \u2032 \u2208 H then we can construct, by adding superfluous new constraints to I, an equivalent new instance whose scope hypergraph is H \u2032. Hence, we can assume that H is closed under taking subhypergraphs.\nWe shall solve completely this question assuming some mild technical assumptions. In order to state our result we need a few definitions from graph theory and parameterized complexity. The Gaifman graph of a hypergraph H , denoted Gaifman(H) is the graph where the node-set is V (H) and the edge-set contains all pairs {u, v} such that there is an hyperedge h in H with {u, v} \u2286 h. A tree-decomposition of a graph G is a pair (T, \u03b2) where T is an (ordinary, not oriented) tree and \u03b2 : V (T ) \u2192 2V (G) is a mapping such that the following conditions are satisfied:\n1. For every node v \u2208 V (G), the set {x \u2208 V (T ) | v \u2208 \u03b2(x)} is non-empty and connected in T . 2. For every edge {u, v} \u2208 E(G), there is a node x \u2208 V (T ) such that {u, v} \u2208 \u03b2(x).\nThe width of a tree-decomposition (T, \u03b2) is max{|\u03b2(x)| \u2212 1 | x \u2208 V (T )} and the tree-width of G is defined to be the minimum w such that G has a treedecomposition of width w.\nWe will also need some notions and basic facts from parameterized complexity theory. A parameterized problem over some alphabet \u03a3 is a pair (P, \u03ba) consisting of a problem P \u2286 \u03a3\u2217 and a polynomial time mapping \u03ba : \u03a3\u2217 \u2192 N, called its parameter. A parameterized problem (P, \u03ba) over \u03a3 is fixed-parameter tractable if there is a computable function f : N \u2192 N and an algorithm that decides if a given instance x \u2208 \u03a3\u2217 belongs to P in time f(\u03ba(x)) \u00b7 |x|O(1). FPT denotes the class of fixed-parameter tractable problems. Hence, the notion of fixed-parameter tractability relaxes the classical notion of polynomial-time solvability, by admitting running times that are exponential in the parameter, which is expected to be small.\nThe analogous of NP in parameterized complexity is the class W[1] which is conjectured to contain strictly FPT. We will omit the definition of W[1] since it is not needed in our proofs and refer the reader to [14].\nTheorem 3. Assume FPT 6= W[1]. For every recursively class of hypergraphs H, DomFilter(Scope(H)) is polynomial-time solvable if and only if there exists\nsome natural number w such that the tree-width of the Gaifman graph of every hypergraph in H is at most w.\nProof. It is well know [11,15] that the set of all CSP instances whose scope hypergraph has tree-width at most w for some fixed w is solvable in polynomial time. Hence it only remains to show the \u2019only if\u2019 part. This follows from a result of Fa\u0308rnquivst and Jonsson [12]. In order to state it, we need to introduce some background.\nIn the list homomorphism problem (for graphs), we are given two graphs G, J and a mapping L : V (G) \u2192 2V (J) called list. The goal is to decide whether there exists a mapping h : V (G) \u2192 V (J) satisfying the following two conditions:\n1. h(v) \u2208 L(v) for every v \u2208 V (G). 2. (h(v1), h(v2)) \u2208 E(J) for every (v1, v2) \u2208 E(G).\nSuch a mapping is called a solution of (G, J, L). Fa\u0308rnquivst and Jonsson have shown that the parameterized version of the problem (parameterized by the size of V (G)) is W[1]-hard. Indeed, the problem is W[1]-hard even if the input graph, G, is guaranteed to belong to a previously fixed G of graphs, provided G has unbounded tree-width. Formally, let G be a set of graphs and define p-LHom(G, ) to be the problem:\n\u2013 INPUT: graphs G, J with G \u2208 G, and a mapping L : V (G) \u2192 2V (J). \u2013 PARAMETER: |V (G)|. \u2013 GOAL: Decide whether (G, J, L) has a solution.\nWe are finally ready to state the theorem from [12] that we shall use.\nTheorem 4. (Lemma 3 in [12]) Let C be a recursively class of graphs that does not have bounded tree-width. Then p-LHom(C, ) is W[1]-hard.\nWe note here that, in order to simplify the exposition, we have taken the liberty to adapt the statement in [12]. We are now ready to complete our proof. Assume, towards a contradiction, that H is a set of hypergraphs with unbounded tree-width such that DomFilter(Scope(H)) is solvable in polynomial time. Let G = {Gaifman(H) | H \u2208 H}. It follows directly by the assumptions on H that G has unbounded tree-width and is recursively enumerable. We shall give an FPT algorithm for p-LHom(G, ).\nThe algorithm is as follows. Let (G, J, L) be any instance of the list homomorphism problem with G \u2208 G. Enumerate the hypergraphs in H until finding an hypergraph H \u2208 H whose Gaifman graph is G. Construct the instance I in Scope(H) where the set of variables is V (H)(= V (G)), the domain is V (H)\u00d7V (J), the list of every node v \u2208 V (H) is {v}\u00d7L(v), and the constraints are defined as follows:\n\u2013 For every (v1, v2) \u2208 E(G), and for every (a1, a2) 6\u2208 E(H), include the constraint Among(h,R, 0, 1) where h is any hyperedge in H containing {v1, v2} and R = {(v1, a1), (v2, a2)}.\nNote that, by construction, the scope hypergraph of I is a subhypergraph of H and, hence, I is an instance of Scope(H). Since DomFilter(Scope(H)) is, by assumption, solvable in polynomial time then one can also decide the satisfiability of I is polynomial time. Finally, return \u2019yes\u2019 if I is satisfiable and \u2019no\u2019 otherwise. Note that the time required in finding H depends only on G whereas the time required in constructing and solving I is polynomial on the size of (G, J, L). Hence, the algorithm just defined is FPT. It is easy to see that it correctly solves (G, J, L). Indeed, let s be any mapping s : V (H) \u2192 V (H)\u00d7 V (J) which we can write as s(v) = (s1(v), s2(v)) with s1 : V (H) \u2192 V (H) and s2 : V (H) \u2192 V (J). It follows directly from the construction of I that s is a solution of I if and only if s1 is the identity (formally, s(v) = v for every v \u2208 V (H)) and s2 is a solution of instance (G, J, L). Hence, I is satisfiable if and only if so is (G, J, L).\nIt is not difficult to show, following [19], that the condition FPT 6= W[1] cannot be weakened (for example by requiring, instead, only P 6=NP). Indeed, if FPT = W[1] then there exists a family H of hypergraphs of unbounded treewidth such that DomFilter(H) is polynomial-time solvable.\nFinally, note that the hardness part of Theorem 3 holds even for conjunctions of among constraint whose range has cardinality 2. Note, that the hardness direction does not hold any more if one requires that the among constraints have range of cardinality 1. Indeed, the AllDiff constraint is encoded by a conjunction of among constrains whose scope hypergraph can have arbitrary large tree-width and the range of every constraint is a singleton.\nSecondly, we turn our attention to the range and investigate which restrictions on the range of among constraints guarantee that the domain filtering problem is solvable in polynomial time. To this end we can define the range hypergraph in a similar way to the scope hypergraph and define, for every set H of hypergraphs, Range(H) to be the set of all conjunctions of among constraints whose range hypergraph belongs to H. The next theorem, which is straightforward, shows that all non-trivial hypergraphs give rise to hard problems.\nTheorem 5. Assume P6=NP. For every hypergraph H, DomFilter(Range(H)) is polynomial-time solvable if and only every hypergraph H \u2208 H has only trivial hyperedges (that is, if for every H \u2208 H and every h \u2208 E(H), h = \u2205 or h = V (H)).\nProof. The \u2019if\u2019 direction is trivial. Indeed, if the range hypergraph of an instance I has only trivial hyperedges it follows that every among constraint in it is either superfluous (in the sense that it does not enforce any restriction) or unsatisfiable. For the \u2019only if\u2019 direction, assume that H has an hypergraph H with a non trivial hyperedge h. We define a reduction from One-In-Three Sat which is the following NP-complete [16] problem:\n\u2013 INPUT: An hypergraph J where all the hyperedges have cardinality 3. \u2013 GOAL: Decide whether there exists some X \u2286 V (J) such that h \u2229 X = 1\nfor every h \u2208 E(J).\nThe reduction is as follows: given an instance J , of One-In-Three Sat, construct the instance I = (V,D,L, C) \u2208 Range(H) where V = V (J), D = V (H), L(v) = V (H) for every v \u2208 V , and C contains the constraints (S, h, 1, 1) for every S \u2208 E(J). It is easy to see that the range hypergraph of I is H and that J is satisfiable if and only if so is I."}, {"heading": "Appendix B: Proofs of section 6", "text": "Basic concepts and results about network hypergraphs\nIf T is an oriented tree and x \u2208 V (T ) we denote by T\u2212(x) (respectively T+(x)) the subtree of T containing all those nodes appear in some directed path ending (respectively, starting) at x.\nA rooted tree is an oriented tree that is obtained from un undirected tree by fixing a node r, called the root, and orienting all the edges away from the root or all the edges towards the root.\nLemma 4. For every hypergraph H the following are equivalent:\n1. Every pair of hyperedges in H are either disjoint or contained in each other. 2. There exists a rooted tree T that defines H such that the path associated to\nevery variable ends at the root.\nFurthermore, when condition (2) holds we can assume that in every edge e = (x, y) associated to a minimal hyperedge of H, x has in-degree zero.\nProof. (1 \u21d2 2). Let H be an hypergraph satisfying (1). Let T be the oriented tree defined in the following way. The node-set of T is E(H) \u222a {r} where r is a fresh node. For every h \u2208 H(T ), T contains an edge from h to h\u2032 where h\u2032 = r if h is not contained in any other hyperedge of H and h\u2032 is the smallest hyperedge in H containing h otherwise. Note that T has root r and that if e = (x, y) is an edge associated to a minimal hyperedge of H , then x has in-degree zero. It is not difficult to verify that T satisfies condition (2). (2 \u21d2 1). Assume that T is a tree satisfying condition (2). Let h and h\u2032 be hyperedges in H and let eh = (x, y) and eh\u2032 = (x\n\u2032, y\u2032) be their associated edges in T . Consider three cases: (a) there is a directed path from x to x\u2032, (b) there is a directed path from x\u2032 to x, (c) none of the previous holds. In case (a) it follows from the fact that the path associated to every variable ends at the root that every path containing eh contains also eh\u2032 and hence h \u2286 h\u2032. By the same argument, case (b) implies that h\u2032 \u2286 h. Finally, in case (c) there is no directed path containing both eh and eh\u2032 and, consequently, h \u2229 h\u2032 = \u2205.\nOriented trees can be combined by gluing some of their nodes. Formally, let T1 and T2 be trees and let r1 and r2 be nodes in T1 and T2 respectively. Assume, renaming nodes if necessary, that V (T1) \u2229 V (T2) = \u2205. Then, the result of gluing r1 and r2 is obtained by, first, computing the disjoint union of T1 and T2 and, then, merging r1 and r2 into a new node w that has as in-neighbours the union of all in-neighbours of r1 and r2 and, as out-neighbours, the union of\nall out-neighbours of r1 and r2. It is not difficult to see that the result is again an oriented tree.\nThe following technical lemma, which follows directly from the definitions, will be useful.\nLemma 5. For i = 1, 2, let Hi be an hypergraph, let Ti be a tree defining Hi and let ri \u2208 V (Ti). Assume that V (H1) = V (H2) and that for every v \u2208 V (H1) the following holds: if v \u2208 h1 \u2229 h2 with h1 \u2208 H1 and h2 \u2208 H2 then the last node of the path associated to v in T1 is r1 and the first node of the path associated to v in T2 is r2. Then, the result of gluing r1 and r2 defines H1 \u222aH2.\nProof. Straightforward.\nLemma 6. Let H be an network hypergraph defined by tree T and let J be a subhypergraph of H with the property that for every a, b \u2208 E(J) there exists some c \u2208 J with a \u2229 c 6= \u2205 and b \u2229 c 6= \u2205. Then there exists an element r \u2208 V (T ) such that for every h \u2208 E(J), eh \u2208 E(T \u2212(r)) \u222a E(T+(r))\nProof. For every h \u2208 H1 \u222aH2, let eh = (x, y) be its associated edge in T and let us define Th to be the subtree of T with node-set V (T\n\u2212(x)) \u222a V ((T+(y)). It follows that V (Ta) \u2229 V (Tb) 6= \u2205 for every a, b \u2208 J . Indeed, let c be the hyperedge in J such that a \u2229 c 6= \u2205 and b \u2229 c 6= \u2205. Then both endpoints of the edge ec associated to c belong to V (Ta) \u2229 V (Tb).\nNext we shall use the 2-Helly property of the subtrees of a tree (see for example [5]).\nLemma 7. (2-Helly property of subtrees) Let T1, . . . , Tn be a collection of subtrees of an (undirected) tree T such that for every 1 \u2264 i, j \u2264 n, V (Ti)\u2229V (Tj) 6= \u2205. It follows that \u22c2 1\u2264i\u2264n V (Ti) 6= \u2205.\nNote that the 2-Helly property stated deals with undirected trees (instead of oriented trees). However it easily implies that the same property holds for oriented trees. Hence, it follows that \u22c2 h\u2208J V (Th) 6= \u2205. To complete the proof\nnote that any vertex r in \u22c2\nh\u2208J V (Th) satisfies the conditions of the Lemma.\nLemma 8. Let I = (V,D,L, C) be a conjunction of among constraints with |D| \u2265 3, let H be the hypergraph of its canonical booleanization, let H1 be a set of at least 2 hyperedges in E(H) where every hyperedge, S \u00d7 R, in H1 satisfies S = V and let H2 to be the subset of E(H) containing, for every v \u2208 V , the hyperedge {v} \u00d7D. Then, if H is a network hypergraph then there exists a tree T defining H and a node r \u2208 V (T ) such that for every h \u2208 H1, eh \u2208 E(T\u2212(r)) and for every h \u2208 H2, eh \u2208 E(T+(r)).\nProof. Assume that H is a network hypergraph and let T be a tree defining it. We shall use the following claim.\nClaim 1 Let x1, e1, x2, . . . , en\u22121, xn be a directed path in T , and let ei, ej, ek, i < j < k be different edges such two of their associated hyperedges belong to H2 and the remaining one to H1. Then, the edge whose associated hyperedge belongs to H1 is ej.\nProof. Let hi, hj, hk be the hyperedges associated to ei, ej , and ek respectively and assume, towards a contradiction, that hi \u2208 H1 (the case hk \u2208 H1 is symmetric). Let (v, d) \u2208 hi \u2229hk and let p be its associated path. Clearly, p, contains both ei and ek and hence it must contain also ej in contradiction with the fact that hj \u2229 hk = \u2205\nFor every directed path p = x1, . . . , xn define T (p) to be the subtree of T induced by V (T\u2212(x1))\u222a{x1, . . . , xn}\u222aV (T +(xn)). We define J \u2212 (resp. J+) to be the set containing all h \u2208 H1\u222aH2 with eh \u2208 E(T\u2212(x1)) (resp. eh \u2208 E(T+(xn))). The proof proceeds by showing that there exists a tree T defining H and a directed path p in T satisfying all the following properties:\n1. eh \u2208 E(T (p)) for every h \u2208 H1 \u222aH2. 2. J\u2212 \u2229H1 = \u2205 or J\u2212 \u2229H2 = \u2205. Also, J+ \u2229H1 = \u2205 or J+ \u2229H2 = \u2205. 3. J\u2212 and J+ are non empty. 4. J+ = H2.\nNote that if T and p satisfy (1)\u2212 (4) then T and r = xn satisfy the Lemma. Let us show the existence of T and p satisfying the above-mentioned properties in increasing order:\n(1). First, note that J = H1 \u222a H2 satisfies the hypothesis of Lemma 6 and, hence, it follows that there exists an element r in T such that for every h \u2208 H1 \u222aH2, eh belongs to T\u2212(r) or T+(r). Hence, the path p consisting of single node r satisfies (1).\n(1) \u2192 (2). We claim that every path p = x1, . . . , xn of maximal length satisfying (1) must satisfy (2) as well. Assume, towards a contradiction, that ai \u2208 J\u2212 \u2229Hi for i = 1, 2 (the proof for J+ is analogous). For every h \u2208 J\u2212 let qh be a directed path in T containing eh and ending at x1. It follows that the last edge in qa1 and qa2 must be identical since otherwise there could not be a directed path containing both ea1 and ea2 , which would imply that a1 \u2229 a2 = \u2205. Let (y, x1) be the common last edge of qa and qb. Then, applying the same argument it follows that (y, x1) is also the last edge of qh for every h \u2208 J\u2212. Hence, by adding y at the beginning of y, x1, . . . , xn we obtain another path p satisfying (1) contradicting the maximality of p.\n(1, 2) \u2192 (3). It is easy to see that every path p satisfying (1) and (2) has a subpath that satisfies, additionally, (3).\n(1, 2, 3) \u2192 (4). It follows from Claim 1 that J\u2212 \u2229 H2 6= \u2205 or J+ \u2229 H2 6= \u2205. We can assume, by reversing the direction of the edges in T if necessary, that J+ \u2229 H2 6= \u2205. Since, by (2), J+ \u2229 H1 = \u2205, in order to show (4) it is only necessary to prove that H2 \u2286 J+. Assume towards a contradiction that there exists h \u2208 H2 \\J\n+. It follows again by Claim 1 and the fact that H1 is nonempty that h \u2208 J\u2212 and hence that H1 \u2229 J\u2212 = \u2205. Let a = V \u00d7 A, b = V \u00d7 B be two different hyperedges in H1. It follows that ea and eb appear in path p and we can assume wlog. that ea appears before eb in p. We shall prove that B \u2286 A. Let d \u2208 B and let v \u2208 V be such that h = {v} \u00d7D. Consider the directed path q associated to (v, d). Clearly q contains eh and eb and hence q contains ea as well. Hence (v, d) belongs to (V,A), and hence, d \u2208 A. A similar reasoning, using\nnow any arbitrary hyperedge in J+ shows that A \u2286 B. Hence we have A = B, a contradiction. This completes the proof of (4).\nProof of Theorem 1\nLet H be the hypergraph of the canonical booleanization of I. Define H1 to be the set of all hyperedges S \u00d7 R in H with S = V . Define H2 to be the hypergraph associated to the non-empty assignment constraints. That is, H2 contains for every v \u2208 V , the hyperedge {v}\u00d7D. Note that h1\u2229h2 6= \u2205 for every h1 \u2208 H1 and h2 \u2208 H2.\n(1) \u21d2 (2). In what follows we shall assume that |H1| > 1 since otherwise (2) follows directly. Assume that H is a network hypergraph. It follows that H1 and H2 satisfy the hypothesis of Lemma 8. Then, let T the tree defining H and r the node in T given by Lemma 8. Note that for every node occurring in any hyperedge in H1, its associated path p must contain some edge in T\n+(r) and, hence, must necessarily contain r as well. Then, condition (2) follows by applying Lemma 4 to T\u2212(r).\n(2) \u21d2 (1). We note that this is a particular case of direction (2) \u21d2 (1) in Theorem 2. Still we include a proof since we think it might help the reader to understand the basic idea before embarking in the more complicated proof in 2. This direction follows easily from Lemma 4 and Lemma 5. Assume that (2) holds. Then it follows from Lemma 4 that there exists a rooted tree T1 defining H1 such that, additionally, the path associated to every variable in V (H) ends at the root, r1, of T1. Also, note that every two hyperedges in H2 have an empty intersection which implies again by Lemma 4 that there exists a rooted tree T2 defining H2 such that the path associated to every variable v \u2208 V (H) starts at the root, r2, of T2. Then, it follows from Lemma 5 that by gluing r1 and r2 in T1 and T2 we obtain the tree defining H .\nProof of Theorem 2\nLet H be the hypergraph of the canonical booleanization of I. (1) \u21d2 (2). Define H1 to be the set containing, for every d \u2208 D, the hyperedge V \u00d7{d}. Every such hyperedge is in H because we are assuming that the instance contains a global cardinality constraint. Furthermore, define H2 to be the set containing all non-empty assignment constraints. That is H2 contains for every v \u2208 V , the hyperedge {v} \u00d7 D. Notice that if a = V \u00d7 {d} belongs to H1 and b = {v}\u00d7D belongs to H2 then a\u2229 b is non empty as it contains (v, d). Assume that H is a network hypergraph. It follows that H1 and H2 satisfy the hypothesis of Lemma 8 and let T be the tree defining H and r the vertex in V (T ) given by Lemma 8.\nWe claim that for every hyperedge h \u2208 H , eh belongs to E(T\u2212(r))\u222aE(T\u2212(r)) Indeed, if it is not the case then there exists some hyperedge h = S\u00d7R such that\nits associated edge eh has one endpoint y in V (T \u2212(r))\u222aV (T+(r)) and the other, x, outside. Assume that y \u2208 V (T\u2212(r)) (the case y \u2208 V (T+(r)) is symmetric). It follows that eh = (y, x) since otherwise eh would be included in E(T\n\u2212(r)). Let (v, d) \u2208 S \u00d7 R and let p be the direct path in T associated to (v, d). This path must include eh and also the edge associated to V \u00d7 {d}, but this is impossible since both edges must appear with different polarity because the edge associated to V \u00d7 {d} belongs to V (T+(r)).\nFor every d \u2208 D, let (xd, yd) be the edge in T associated to hyperedge V \u00d7{d} and let Td be T\n\u2212(xd). Also, define T1 to be the subtree of T that contains all the nodes x that belong to a path starting at xd for some d \u2208 D and ending at r.\nFor every v \u2208 V , let (xv , yv) be the edge in T associated to hyperedge {v}\u00d7D and let Tv be T\n+(yv). Also, define T2 to be the subtree of T that contains all the nodes x that belong to a path starting at r and ending at yv for some v \u2208 D.\nLet (v, d) \u2208 V \u00d7D and let p be the directed path in T associated to (v, d). Clearly p must contain the edges associated to V \u00d7{d} and {v}\u00d7D and, hence, also r. It also follows that for every hyperedge, h \u2208 E(H), containing (v, d), eh belongs to Ti with i \u2208 {d, v, 1, 2}. It follows that every edge e \u2208 E(T ) is contained in some of the trees Ti, i \u2208 D \u222a V \u222a {1, 2} we have just defined and hence we can infer the shape of H by considering separately the shape of the hypergraphs defined by each one of the trees. Then (1) \u21d2 (2) follows from the following lemma.\nLemma 9. Let e (resp. e\u2032) be an edge in T , let h = S \u00d7R (resp. h\u2032 = S\u2032 \u00d7R\u2032) be the hyperedge in H associated to e (resp. e\u2032). Then the following holds:\n1. If there exists d \u2208 D such that e, e\u2032 \u2208 E(Td) then R = R\u2032 = {d}. Furthermore, S and S\u2032 are disjoint or contained one in another. 2. If e, e\u2032 \u2208 E(T1) then S = S\u2032 = V . Furthermore, R and R\u2032 are disjoint or contained one in another. 3. If there exists v \u2208 V such that e, e\u2032 \u2208 E(Tv) then S = S\u2032 = {v}. Furthermore, R and R\u2032 are disjoint or contained one in another. 4. If e, e\u2032 \u2208 E(T2) then R = R \u2032 = D. Furthermore, S and S\u2032 are disjoint or\ncontained one in another.\nProof. By symmetry we only need to prove the first two cases:\n1. We first show that R = {d} (the same argument shows that R\u2032 = {d}. Let (v, d\u2032) be any node in h and let p be its associated directed path in T . Since p contains r, it must contain the edge associated to V \u00d7 {d}, which implies that d\u2032 = d. Hence, R = {d}. The fact that S and S\u2032 are disjoint or contained one in another follows from applying Lemma 4 to Td. Note that we use that the path associated to every node in V \u00d7 {d} must necessarily include xd. 2. We first show that S = V (the same argument shows that S\u2032 = V ). Let p be the directed path associated to any variable (v, d) \u2208 S \u00d7 R. This path contains xd and r which implies that every path associated to a variable in V \u00d7 {d} contains also eh. It follows that V \u00d7 {d} \u2286 S \u00d7 R and, hence,\nS = V . The fact S and S\u2032 are disjoint or contained one in another follows by applying Lemma 4 to T1. Note that we use that the associated path of every node in V \u00d7D must necessarily include r.\n(1) \u21d0 (2). This follows easily from Lemma 4 and Lemma 5. For every d, let Hd be the subhypergraph of H containing all the hyperedges S \u00d7 R \u2208 E(H) with R = {d} and S 6= V . It follows from Lemma 4 that there is a rooted tree Td defining Hd such that, additionally, all the paths associated to variables in V (H) finish at the root of Td, which we will denote by rd. Similarly, let H1 be the subhypergraph of H containing all the hyperedges S \u00d7 R \u2208 E(H) with S = V . Again, by Lemma 4 there is a rooted tree T1 with root, say, r1 defining H1. For every d \u2208 D, let us denote by (xd, yd) the edge in T1 associated to V \u00d7 {d}. Lemma 4 guarantees that xd has in-degree 0 which implies that the paths associated to every node in V \u00d7 {d} start at xd and end at r1. It follows then from Lemma 5 that we can obtain a tree defining H1 \u222a \u22c3 d\u2208D Hd (that is, the subgraph of H containing all hyperedges S \u00d7 R \u2208 E(H) where S = V or R is a singleton) by taking the disjoint union of T1 along with all the trees Td and gluing rd with xd for every d \u2208 D. The obtained tree, which we will call T \u20321 is rooted at r1 and has the additional property that every path in T \u2032 1 associated to a variable in V (H) ends at the root r1. A symmetric argument shows that there exists a tree T \u20322 with root r2 that defines the subhypergraph of H containing all hyperedges S \u00d7 R \u2208 E(H) where R = D or V is a singleton such that, additionally, every path in T \u20321 associated to a variable in V (H) starts at the root r2. Then, it follows that by gluing r1 and r2 in T \u2032 1 and T \u2032 2 we obtain a tree defining H . This finishes the proof. We note that direction (1 \u21d2 2) in Theorems 1 and 2 does not hold for boolean domains due to the fact that the proof assumes the canonical encoding. However, the direction (2 \u21d2 1) holds also for boolean domains.\nAppendix C: Proof of the O(n3/2 logn logmax) bound for the Sequence constraint\nRecall from Section 6.3 that a Sequence constraint is encoded as a boolean CACwith constraints:Among({xi, . . . , xi+k}, {1},min,max) where i = 1, . . . , n\u2212 k andmin,max, k are fixed integers. Our goal is to improve the boundO(n3/2 log2 n) given in Section 6.3 to O(n3/2 logn logmax).To this end we note, inspecting the proof of Lemma 3, that in the logmn factor appearing in the function f(n,m), mn is has been obtained by bounding the quantity u (where u is the maximum capacity of the edges in the network constructed by the algorithm) by O(log n). We shall show that in the particular case of the Sequence constraint we can obtain a better bound. In particular, we will see that u \u2264 max (and hence log u \u2264 logmax), which suffices to obtain our desired bound.\nRecall the definitions of a, b, c, T , and P from the proof of Lemma 3 and recall also that the capacity of every edge in the network constructed by our\nalgorithm is either an entry of vector c, which in the particular case of the Sequence constraint, is either max \u2212 min or 1 (and, hence, at most max), or the absolute value of an entry of vector b = Pa. In the particular case of the Sequence constraint, all entries of a are max. Also, recall that the tree T defining a the hypergraph of a Sequence constraint is a directed path which implies that every row of P has at most one +1, at most one \u22121, and the rest of entries are 0. It follows that every entry in b is in {\u2212max, 0,max} and we are done."}], "references": [{"title": "Network flows theory, algorithms and applications", "author": ["Ravindra K. Ahuja", "Thomas L. Magnanti", "James B. Orlin"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1993}, {"title": "LP relaxations of multiple all different predicates", "author": ["Gautam Appa", "Dimitris Magos", "Ioannis Mourtos"], "venue": "In Proceedings of CPAIOR\u201904,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2004}, {"title": "On the system of two all different predicates", "author": ["Gautam Appa", "Dimitris Magos", "Ioannis Mourtos"], "venue": "Inf. Process. Lett.,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2005}, {"title": "Propagating logical combinations of constraints", "author": ["Fahiem Bacchus", "Toby Walsh"], "venue": "In Proceedings of IJCAI\u201905,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2005}, {"title": "A Textbook of Graph Theory", "author": ["R. Balakrishnan", "K Ranganathan"], "venue": "SpringerVerlag (New York),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2000}, {"title": "Introducing global constraints in chip", "author": ["N. Beldiceanu", "E. Contejean"], "venue": "Mathematical and Computer Modelling,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1994}, {"title": "SLIDE: A useful special case of the CARDPATH constraint", "author": ["Christian Bessiere", "Emmanuel Hebrard", "Brahim Hnich", "Zeynep Kiziltan", "Toby Walsh"], "venue": "In Proceedings of ECAI\u201908,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2008}, {"title": "Range and roots: Two common patterns for specifying and propagating counting and occurrence constraints", "author": ["Christian Bessiere", "Emmanuel Hebrard", "Brahim Hnich", "Zeynep Kiziltan", "Toby Walsh"], "venue": "Artif. Intell.,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2009}, {"title": "Propagating conjunctions of alldifferent constraints", "author": ["Christian Bessiere", "George Katsirelos", "Nina Narodytska", "Claude-Guy Quimper", "Toby Walsh"], "venue": "In Proceedings of AAAI\u201910,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "The conjunction of interval among constraints", "author": ["Gilles Chabert", "Sophie Demassey"], "venue": "In Proceedings of CPAIOR\u201912,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "Tree clustering for constraint networks", "author": ["R. Dechter", "J. Pearl"], "venue": "Artificial Intelligence,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1989}, {"title": "Bounded tree-width and csp-related problems", "author": ["Tommy F\u00e4rnqvist", "Peter Jonsson"], "venue": "In Proceedings of ISAAC\u201907,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2007}, {"title": "Constraint satisfaction problems: Convexity makes alldifferent constraints tractable", "author": ["Michael R. Fellows", "Tobias Friedrich", "Danny Hermelin", "Nina Narodytska", "Frances A. Rosamond"], "venue": "Theor. Comput. Sci.,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}, {"title": "Parameterized Complexity Theory. Texts in Theoretical Computer Science", "author": ["J\u00f6rg Flum", "Martin Grohe"], "venue": "An EATCS Series. Springer,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2006}, {"title": "Complexity of k-structurated constraint satisfaction problems", "author": ["E.C. Freuder"], "venue": "In Proceedings of AAAI-90,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1990}, {"title": "Computers and Intractability: A Guide to the Theory of NP-Completeness", "author": ["M.R. Garey", "David S. Johnson"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1979}, {"title": "Beyond the flow decomposition barrier", "author": ["Andrew V. Goldberg", "Satish Rao"], "venue": "J. ACM,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1998}, {"title": "A comparison of structural CSP decomposition methods", "author": ["Georg Gottlob", "Nicola Leone", "Francesco Scarcello"], "venue": "Artif. Intell.,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2000}, {"title": "The complexity of homomorphism and constraint satisfaction problems seen from the other side", "author": ["Martin Grohe"], "venue": "J. ACM,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2007}, {"title": "An n5/2 algorithm for maximum matchings in bipartite graphs", "author": ["John E. Hopcroft", "Richard M. Karp"], "venue": "SIAM J. Comput.,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1973}, {"title": "Filtering methods for symmetric cardinality constraint", "author": ["Waldemar Kocjan", "Per Kreuger"], "venue": "In Proceedings of CPAIOR\u201904,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2004}, {"title": "Simultaneous matchings: Hardness and approximation", "author": ["Martin Kutz", "Khaled M. Elbassioni", "Irit Katriel", "Meena Mahajan"], "venue": "J. Comput. Syst. Sci.,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2008}, {"title": "Interleaved alldifferent constraints: CSP vs. SAT approaches", "author": ["Fr\u00e9d\u00e9ric Lardeux", "Eric Monfroy", "Fr\u00e9d\u00e9ric Saubion"], "venue": "In Proceedings of AIMSA\u201908,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2008}, {"title": "A language and a program for stating and solving combinatorial problems", "author": ["Jean-Louis Lauri\u00e8re"], "venue": "Artif. Intell.,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1978}, {"title": "A polyhedral approach to the alldifferent system", "author": ["Dimitris Magos", "Ioannis Mourtos", "Gautam Appa"], "venue": "Math. Program.,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2012}, {"title": "Flowbased propagators for the SEQUENCE and related global constraints", "author": ["Michael J. Maher", "Nina Narodytska", "Claude-Guy Quimper", "Toby Walsh"], "venue": "In Proceedings of CP\u201908,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2008}, {"title": "Toubier. Charme: Un langage industriel de programmation par contraintes, illustr\u1e55ar une application chez renault", "author": ["A. Oplobedu", "J. Marcovitch"], "venue": "In Proceedings of 9th International Workshop on Expert Systems and their Applications,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1989}, {"title": "The ordered distribute constraint", "author": ["Thierry Petit", "Jean-Charles R\u00e9gin"], "venue": "International Journal on Artificial Intelligence Tools,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2011}, {"title": "Generalizing global constraints based on network flows", "author": ["Igor Razgon", "Barry O\u2019Sullivan", "Gregory M. Provan"], "venue": "In Proceedings of CSCLP\u201907,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2007}, {"title": "A filtering algorithm for constraints of difference in csps", "author": ["Jean-Charles R\u00e9gin"], "venue": "In Proceedings of AAAI\u201994,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 1994}, {"title": "Generalized arc consistency for global cardinality constraint", "author": ["Jean-Charles R\u00e9gin"], "venue": "In Proceedings of AAAI\u201996,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1996}, {"title": "Combination of among and cardinality constraints", "author": ["Jean-Charles R\u00e9gin"], "venue": "In Proceedings of CPAIOR\u201905,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2005}, {"title": "The cardinality matrix constraint", "author": ["Jean-Charles R\u00e9gin", "Carla P. Gomes"], "venue": "In Proceedings of CP\u201904,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2004}, {"title": "A filtering algorithm for global sequencing constraints", "author": ["Jean-Charles R\u00e9gin", "Jean-Francois Puget"], "venue": "In Proceedings of CP\u201997,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 1997}, {"title": "Depth-first search and linear graph algorithms", "author": ["Robert Endre Tarjan"], "venue": "SIAM J. Comput.,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 1972}, {"title": "Revisiting the sequence constraint", "author": ["Willem Jan van Hoeve", "Gilles Pesant", "Louis-Martin Rousseau", "Ashish Sabharwal"], "venue": "In Proceedings of CP\u201906,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2006}], "referenceMentions": [{"referenceID": 23, "context": "Several constraints studied in the literature including AllDiff[24],GCC[27], Symmetric-GCC [21], Sequence [6], GlobalSequencing [34], OrderedDistribute [28], and CardinalityMatrix [33] can be decomposed as the conjunction of a simpler family of constraints, called among constraints [6].", "startOffset": 63, "endOffset": 67}, {"referenceID": 26, "context": "Several constraints studied in the literature including AllDiff[24],GCC[27], Symmetric-GCC [21], Sequence [6], GlobalSequencing [34], OrderedDistribute [28], and CardinalityMatrix [33] can be decomposed as the conjunction of a simpler family of constraints, called among constraints [6].", "startOffset": 71, "endOffset": 75}, {"referenceID": 20, "context": "Several constraints studied in the literature including AllDiff[24],GCC[27], Symmetric-GCC [21], Sequence [6], GlobalSequencing [34], OrderedDistribute [28], and CardinalityMatrix [33] can be decomposed as the conjunction of a simpler family of constraints, called among constraints [6].", "startOffset": 91, "endOffset": 95}, {"referenceID": 5, "context": "Several constraints studied in the literature including AllDiff[24],GCC[27], Symmetric-GCC [21], Sequence [6], GlobalSequencing [34], OrderedDistribute [28], and CardinalityMatrix [33] can be decomposed as the conjunction of a simpler family of constraints, called among constraints [6].", "startOffset": 106, "endOffset": 109}, {"referenceID": 33, "context": "Several constraints studied in the literature including AllDiff[24],GCC[27], Symmetric-GCC [21], Sequence [6], GlobalSequencing [34], OrderedDistribute [28], and CardinalityMatrix [33] can be decomposed as the conjunction of a simpler family of constraints, called among constraints [6].", "startOffset": 128, "endOffset": 132}, {"referenceID": 27, "context": "Several constraints studied in the literature including AllDiff[24],GCC[27], Symmetric-GCC [21], Sequence [6], GlobalSequencing [34], OrderedDistribute [28], and CardinalityMatrix [33] can be decomposed as the conjunction of a simpler family of constraints, called among constraints [6].", "startOffset": 152, "endOffset": 156}, {"referenceID": 32, "context": "Several constraints studied in the literature including AllDiff[24],GCC[27], Symmetric-GCC [21], Sequence [6], GlobalSequencing [34], OrderedDistribute [28], and CardinalityMatrix [33] can be decomposed as the conjunction of a simpler family of constraints, called among constraints [6].", "startOffset": 180, "endOffset": 184}, {"referenceID": 5, "context": "Several constraints studied in the literature including AllDiff[24],GCC[27], Symmetric-GCC [21], Sequence [6], GlobalSequencing [34], OrderedDistribute [28], and CardinalityMatrix [33] can be decomposed as the conjunction of a simpler family of constraints, called among constraints [6].", "startOffset": 283, "endOffset": 286}, {"referenceID": 9, "context": "In consequence,CACs have been previously studied [10,32,38], specially the particular case of conjunctions of AllDiff constraints [2,3,9,13,22,23,25].", "startOffset": 49, "endOffset": 59}, {"referenceID": 31, "context": "In consequence,CACs have been previously studied [10,32,38], specially the particular case of conjunctions of AllDiff constraints [2,3,9,13,22,23,25].", "startOffset": 49, "endOffset": 59}, {"referenceID": 1, "context": "In consequence,CACs have been previously studied [10,32,38], specially the particular case of conjunctions of AllDiff constraints [2,3,9,13,22,23,25].", "startOffset": 130, "endOffset": 149}, {"referenceID": 2, "context": "In consequence,CACs have been previously studied [10,32,38], specially the particular case of conjunctions of AllDiff constraints [2,3,9,13,22,23,25].", "startOffset": 130, "endOffset": 149}, {"referenceID": 8, "context": "In consequence,CACs have been previously studied [10,32,38], specially the particular case of conjunctions of AllDiff constraints [2,3,9,13,22,23,25].", "startOffset": 130, "endOffset": 149}, {"referenceID": 12, "context": "In consequence,CACs have been previously studied [10,32,38], specially the particular case of conjunctions of AllDiff constraints [2,3,9,13,22,23,25].", "startOffset": 130, "endOffset": 149}, {"referenceID": 21, "context": "In consequence,CACs have been previously studied [10,32,38], specially the particular case of conjunctions of AllDiff constraints [2,3,9,13,22,23,25].", "startOffset": 130, "endOffset": 149}, {"referenceID": 22, "context": "In consequence,CACs have been previously studied [10,32,38], specially the particular case of conjunctions of AllDiff constraints [2,3,9,13,22,23,25].", "startOffset": 130, "endOffset": 149}, {"referenceID": 24, "context": "In consequence,CACs have been previously studied [10,32,38], specially the particular case of conjunctions of AllDiff constraints [2,3,9,13,22,23,25].", "startOffset": 130, "endOffset": 149}, {"referenceID": 31, "context": "Although deciding the satisfiability of an arbitrary conjunction of among constraints is NP-complete [32] this body of work shows that sometimes there are benefits in reasoning about the interaction between the among constraints.", "startOffset": 101, "endOffset": 105}, {"referenceID": 29, "context": "This allows to reformulate the domain filtering problem in terms of flows in a network graph and apply the methodology derived by R\u00e9gin [30,31].", "startOffset": 136, "endOffset": 143}, {"referenceID": 30, "context": "This allows to reformulate the domain filtering problem in terms of flows in a network graph and apply the methodology derived by R\u00e9gin [30,31].", "startOffset": 136, "endOffset": 143}, {"referenceID": 28, "context": "The algorithm thus obtained, although simple, unifies and generalizes existing domain filtering algorithms for several global constraints, including AllDiff, GCC, Sequence, Symmetric-GCC, OrderedDistribute as well as for other problems expressed as conjunctions of among constraints in [29,32].", "startOffset": 286, "endOffset": 293}, {"referenceID": 31, "context": "The algorithm thus obtained, although simple, unifies and generalizes existing domain filtering algorithms for several global constraints, including AllDiff, GCC, Sequence, Symmetric-GCC, OrderedDistribute as well as for other problems expressed as conjunctions of among constraints in [29,32].", "startOffset": 286, "endOffset": 293}, {"referenceID": 30, "context": "The seminal paper in this direction is [31] which identifies several combinations of among and GCC constraints that admit a complete and efficient domain filtering algorithm (see Section 6 for more details).", "startOffset": 39, "endOffset": 43}, {"referenceID": 30, "context": "Our approach is more general as it subsumes the tractable cases introduced in [31].", "startOffset": 78, "endOffset": 82}, {"referenceID": 28, "context": "Another closely related work is [29] where two tractable combinations of boolean CACs, called TFO and 3FO, are identified.", "startOffset": 32, "endOffset": 36}, {"referenceID": 28, "context": "The approach in [29] differs from ours in two aspects: it deals with optimization problem and also considers restricions on the min and max parameters of the among constraints while we only consider restriction on the scope and range.", "startOffset": 16, "endOffset": 20}, {"referenceID": 9, "context": "A different family of CACs has been investigated in [10] although the work in [10] focuses in bound consistency instead of domain consistency.", "startOffset": 52, "endOffset": 56}, {"referenceID": 9, "context": "A different family of CACs has been investigated in [10] although the work in [10] focuses in bound consistency instead of domain consistency.", "startOffset": 78, "endOffset": 82}, {"referenceID": 3, "context": "Other approaches to the design of filtering algorithms for combinations (but not necessarily conjunctions) of global (but not necessarily among) constraints are described in [4,7,8].", "startOffset": 174, "endOffset": 181}, {"referenceID": 6, "context": "Other approaches to the design of filtering algorithms for combinations (but not necessarily conjunctions) of global (but not necessarily among) constraints are described in [4,7,8].", "startOffset": 174, "endOffset": 181}, {"referenceID": 7, "context": "Other approaches to the design of filtering algorithms for combinations (but not necessarily conjunctions) of global (but not necessarily among) constraints are described in [4,7,8].", "startOffset": 174, "endOffset": 181}, {"referenceID": 3, "context": "The method introduced in [4] deals with logical combinations of some primitive constraints but differs substantially from ours in the sense that it cannot capture a single among constraint.", "startOffset": 25, "endOffset": 28}, {"referenceID": 6, "context": "The work reported in [7,8] does not guarantee tractability.", "startOffset": 21, "endOffset": 26}, {"referenceID": 7, "context": "The work reported in [7,8] does not guarantee tractability.", "startOffset": 21, "endOffset": 26}, {"referenceID": 26, "context": "(GCC andAllDiff constraints) The global cardinality constraint, GCC [27] corresponds to instances (V,D,L, C) where all the constraints have the form Among(V, {d},min,max) with d \u2208 D.", "startOffset": 68, "endOffset": 72}, {"referenceID": 31, "context": "It has been shown by R\u00e9gin [32] that the domain filtering problem for CACs is NP-hard.", "startOffset": 27, "endOffset": 31}, {"referenceID": 17, "context": "This question has a close similarity to the study of the so-called structural restrictions of the CSP (see, for example [18] for a survey) and, not surprisingly, it can be solved by applying results developed there.", "startOffset": 120, "endOffset": 124}, {"referenceID": 11, "context": "Indeed, it follows easily from a result of F\u00e4rnquivst and Jonsson [12] that, modulo some mild technical assumptions, if one allows arbitrary ranges in constraints, then the domain filtering problem is solvable in polynomial time if and only if the hypergraph of the scopes of the constraints has bounded tree-width (see Appendix A for precise statement and the proof).", "startOffset": 66, "endOffset": 70}, {"referenceID": 0, "context": "In this case, one can use specific and more efficient methods like the network simplex algorithm (see for example [1]) instead of a general purpose LP solver.", "startOffset": 114, "endOffset": 117}, {"referenceID": 25, "context": "This idea has been used in [26] to obtain a domain filtering algorithm for the Sequence constraint.", "startOffset": 27, "endOffset": 31}, {"referenceID": 25, "context": "More precisely, [26] deals with the particular case of network matrices defined by a directed path.", "startOffset": 16, "endOffset": 20}, {"referenceID": 25, "context": "Our approach draws upon [26] and generalizes it to network matrices defined by arbitrary trees.", "startOffset": 24, "endOffset": 28}, {"referenceID": 29, "context": "R\u00e9gin [30,31] has shown that this later condition can be tested simultaneously for all 1 \u2264 i \u2264 n and d \u2208 {0, 1} by finding a maximal flow and computing the strongly connected components of its residual graph.", "startOffset": 6, "endOffset": 13}, {"referenceID": 30, "context": "R\u00e9gin [30,31] has shown that this later condition can be tested simultaneously for all 1 \u2264 i \u2264 n and d \u2208 {0, 1} by finding a maximal flow and computing the strongly connected components of its residual graph.", "startOffset": 6, "endOffset": 13}, {"referenceID": 16, "context": "integral capacities can be done in time O(min(v, e)e log(v/e) log u) using Goldberg and Rao\u2019s algorithm [17] where v is the number of vertices, e is the number of edges, and u is the maximum capacity of an edge.", "startOffset": 104, "endOffset": 108}, {"referenceID": 34, "context": "Computing the strongly connected components of the residual graph takes O(v + e) time using Tarjan\u2019s algorithm [36].", "startOffset": 111, "endOffset": 115}, {"referenceID": 30, "context": "It was observed again by R\u00e9gin [31] that, in this setting, it is not necessary, to solve the flow problem from scratch at each call, leading to a considerable redution in total time.", "startOffset": 31, "endOffset": 35}, {"referenceID": 30, "context": "Applying the scheme in [31], we obtain that the time complexity down a branch of a search tree of our algorithm is O(n(n+m)).", "startOffset": 23, "endOffset": 27}, {"referenceID": 30, "context": "We ommit the details because they are faily standard (see [31]).", "startOffset": 58, "endOffset": 62}, {"referenceID": 25, "context": "In the first variant, used in [26], one encodes a constraint Cj = (Sj , {1},minj,maxj) with two equations yj + \u2211 vi\u2208Sj xi = maxj , and \u2212zj + \u2211 vi\u2208Sj xi = minj where yj and zj are new slack variables satisfying 0 \u2264 yj, zj .", "startOffset": 30, "endOffset": 34}, {"referenceID": 29, "context": "2 In fact, as shown in [30,31], it is only necessary to solve the max flow problem during the first invocation so it could be argued that a more realistic bound on the running time of the algorithm is O(n+m).", "startOffset": 23, "endOffset": 30}, {"referenceID": 30, "context": "2 In fact, as shown in [30,31], it is only necessary to solve the max flow problem during the first invocation so it could be argued that a more realistic bound on the running time of the algorithm is O(n+m).", "startOffset": 23, "endOffset": 30}, {"referenceID": 30, "context": "R\u00e9gin\u2019s algorithm [31] has a O(|V ||D|) complexity which is better when |V | \u2208 O(|D|) but the comparison between the two bounds is not very meaningfull because it mainly reflects a different choice max flow algorithm.", "startOffset": 18, "endOffset": 22}, {"referenceID": 30, "context": "In particular, the network obtained using the second variant discussed after Lemma 3 is essentially the same described in [31].", "startOffset": 122, "endOffset": 126}, {"referenceID": 29, "context": "In the particular case of the AllDiff constraint, [30] shows how to produce a bipartite matching problem that can be solved using specialized algorithms, such as [20], leading to a total time complexity of O(|V |) which is better than ours.", "startOffset": 50, "endOffset": 54}, {"referenceID": 19, "context": "In the particular case of the AllDiff constraint, [30] shows how to produce a bipartite matching problem that can be solved using specialized algorithms, such as [20], leading to a total time complexity of O(|V |) which is better than ours.", "startOffset": 162, "endOffset": 166}, {"referenceID": 30, "context": "The network flow problem that our algorithm derives for this instance (see Example 3) is almost identical to the one derived in [31].", "startOffset": 128, "endOffset": 132}, {"referenceID": 30, "context": "Indeed, the network obtained in [31] does not have node r and, instead, requires that the demand of nodes t0, t1, t2 is at most one (instead of exactly one).", "startOffset": 32, "endOffset": 36}, {"referenceID": 31, "context": "The particular case in which R \u2229 R = \u2205 has been previously shown in [32] using a different approach.", "startOffset": 68, "endOffset": 72}, {"referenceID": 31, "context": "The proof given in [32] does not construct a flow problem nor gives run-time bounds so we ommit a comparison.", "startOffset": 19, "endOffset": 23}, {"referenceID": 20, "context": "For example, the Symmetric-GCC constraint [21] is precisely a conjunction (V,D,L, C) of set among constraints of the form Among(V, {d},min,max) where d is a singleton which, additionally, might contain constraints of the form Among({v}, D,min,max) restricting the size of the image of a variable v.", "startOffset": 42, "endOffset": 46}, {"referenceID": 20, "context": "The algorithm in [21] follows closely that in [31] for the GCC constraints, and, in particular, has the same time bounds.", "startOffset": 17, "endOffset": 21}, {"referenceID": 30, "context": "The algorithm in [21] follows closely that in [31] for the GCC constraints, and, in particular, has the same time bounds.", "startOffset": 46, "endOffset": 50}, {"referenceID": 20, "context": "Consequently the network flow derived by our algorithm is obtained, again, by adding one extra node with small capacities in the edges to the network introduced in [21].", "startOffset": 164, "endOffset": 168}, {"referenceID": 5, "context": "The Sequence constraint [6] corresponds to instances ({v1, .", "startOffset": 24, "endOffset": 27}, {"referenceID": 25, "context": "However, as shown in [26] one obtains an equivalent instance with a network hypergraph using a different encoding in which for every original variable vi \u2208 V , we have a boolean variable xi which is intended to be true whenever vi takes a value in R and false otherwise.", "startOffset": 21, "endOffset": 25}, {"referenceID": 25, "context": "It is shown in [26] that the hypergraph H of the boolean instance I obtained under this encoding satisfies the so-called consecutive-ones property which implies that H is defined by a tree T consisting of a single directed path.", "startOffset": 15, "endOffset": 19}, {"referenceID": 25, "context": "Indeed, the network flow obtained by our approach is identical to the one derived in [26] if one encodes Among constraints using the first variant discussed after Lemma 3.", "startOffset": 85, "endOffset": 89}, {"referenceID": 25, "context": "By inspecting closely the proof of Lemma 3 this bound can be slightly improved (see Appendix C) to O(n logn logmax) coinciding with the bound given in [26], which is not surprising since both networks are essentially equivalent.", "startOffset": 151, "endOffset": 155}, {"referenceID": 35, "context": "To the best of our knowledge O(n logn logmax) is the best bound among all complete domain consisteny algorithms for the problem, jointly with the algorithm proposed in [37] which, with time complexity O(n2), offers gives better bounds when k \u226a n.", "startOffset": 168, "endOffset": 172}, {"referenceID": 28, "context": "[29] as a generalization of several common global constraints.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "It turns out that the network introduced in [29] is essentially equivalent to the network flow problem that would be obtained by our approach using the second variant described after Lemma 3.", "startOffset": 44, "endOffset": 48}, {"referenceID": 28, "context": "It is not meaningfull to compare the running time of our algorithm with that of [29] since it deals with an optimization variant.", "startOffset": 80, "endOffset": 84}, {"referenceID": 27, "context": "For example, the OrderedDistribute constraint introduced by Petit and R\u00e9gin [28] can be encoded as conjunction (V,D,L, C) of among constraint where where the domain D has some arbitrary (but fixed) ordering d1, .", "startOffset": 76, "endOffset": 80}, {"referenceID": 27, "context": "In the particular case of OrderedDistribute constraint, the network obtained by our approach is very related to the network introduced in section ([28], Section V.", "startOffset": 147, "endOffset": 151}, {"referenceID": 27, "context": "In particular, a complete filtering algorithm with time complexity O(|V |+ |D|) is given also in [28].", "startOffset": 97, "endOffset": 101}, {"referenceID": 31, "context": "Which among constraint we might safely add? This question has been addressed by R\u00e9gin [32].", "startOffset": 86, "endOffset": 90}, {"referenceID": 31, "context": "In particular, [32] shows that the domain filtering problem is still tractable whenever:", "startOffset": 15, "endOffset": 19}, {"referenceID": 31, "context": "Note that the previous theorem covers cases (a) and (b) from [32] described at the beginning of this section.", "startOffset": 61, "endOffset": 65}, {"referenceID": 31, "context": "The network produced in [32] for the case (a) is essentially equivalent to the one derived by our approach using the second variant described after Lemma 3.", "startOffset": 24, "endOffset": 28}, {"referenceID": 31, "context": "For the case (b) [32] does not construct a flow problem nor gives run-time bounds so we ommit a comparison.", "startOffset": 17, "endOffset": 21}], "year": 2017, "abstractText": "Many existing global constraints can be encoded as a conjunction of among constraints. An among constraint holds if the number of the variables in its scope whose value belongs to a prespecified set, which we call its range, is within some given bounds. It is known that domain filtering algorithms can benefit from reasoning about the interaction of among constraints so that values can be filtered out taking into consideration several among constraints simultaneously. The present paper embarks into a systematic investigation on the circumstances under which it is possible to obtain efficient and complete domain filtering algorithms for conjunctions of among constraints. We start by observing that restrictions on both the scope and the range of the among constraints are necessary to obtain meaningful results. Then, we derive a domain flowbased filtering algorithm and present several applications. In particular, it is shown that the algorithm unifies and generalizes several previous", "creator": "LaTeX with hyperref package"}}}