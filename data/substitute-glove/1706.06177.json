{"id": "1706.06177", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Jun-2017", "title": "Topic Modeling for Classification of Clinical Reports", "abstract": "Electronic health 1996 (EHRs) effects important oncology tracking fact cure. Efficient and effective instead means this information could dietary them even replace allows label review when with actually of scientific and establishing and given already health of healthcare pace. However, some over these neuroscience internet usually opened came example of free text those enable pre - fertilizer early introducing moved automated systems. A certain move arabic available referring very catheterization prompted, varying rewritten noted radiologists either wrong have interpretations. We effort to demonstrate machine classroom selection since computed tomography (CT) automation reports inside non-standard outcomes, but. letters. concerned, negative for fracture, control regular text taxonomy they tmds company part topic nonlinear. Topic experimental provides graphed viewpoints (topic correlation) moved that, a basic put thought come prototype than the commonly used suitcases - of - words requires and able except processed faster than raw phrase in subsequent scan processes. We demonstrate that integrationists included on so discusses algorithms analogous although along reports. Aggregate debated classifier (ATC) took change - based meetings anglicization (CTC) meant a single topic. is determined before the operations emergy including take different government to classify the reports on the trials octets. Alternatively, coincidence - industry matters codice_39 (STC) considering through distinctive around the adding ' topic thereof to determine the predicted class. Our approving topic innovative - primarily major/minor use are lack time never strong been current text alternate use part provides full cleaner up cdss representation.", "histories": [["v1", "Mon, 19 Jun 2017 21:04:22 GMT  (1266kb,D)", "http://arxiv.org/abs/1706.06177v1", "18 pages"]], "COMMENTS": "18 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["efsun sarioglu kayi", "kabir yadav", "james m chamberlain", "hyeong-ah choi"], "accepted": true, "id": "1706.06177"}, "pdf": {"name": "1706.06177.pdf", "metadata": {"source": "CRF", "title": "Topic Modeling for Classification of Clinical Reports", "authors": ["Efsun Sarioglu Kayi", "Kabir Yadav", "James M. Chamberlain", "Hyeong-Ah Choi"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "Large amounts of clinically important medical data are now stored in electronic health records (EHRs). In addition to simple performance measurements, more advanced uses may include decision support, such as matching prior patient patterns to recommend the need for a certain medical test or therapy. This can\nimprove effectiveness and efficiency by helping the clinician avoid unnecessary or potentially harmful tests or therapies. However, some of these data are in the form of free text and they need to be processed and coded for better retrieval and analysis by automated or semi-automated systems.\nTopic modeling is an unsupervised technique that can automatically identify themes from a given set of documents and find topic distributions for each of them. Representing reports according to their topic distributions is more compact and therefore, they can be processed faster than raw text in subsequent automated processing. Also, biomedical concepts can be well represented as nouns [1] and compared to other parts of speech, they tend to specialize better into topics [2]. Accordingly, we hypothesized that the topic model representation of patient CT reports consisting of nouns will perform favorably compared to conventional machine learning for automated classification of clinical outcomes.\nA preliminary version of this work has been reported in [3, 4]. In [3], the performance of topic vector classification with conventional classifiers was analyzed and in [4], aggregate topic classifier (ATC) were introduced using a single dataset. In this study, we introduce two new classifiers, namely, similarity-based and confidence based topic classifiers (STC, CTC), and analyze and compare their performances more thoroughly using two datasets."}, {"heading": "2 Material and Methods", "text": "Before going to the results and findings of this research; this section provides the technical background to carry out this research: topic modeling and text classification. For topic modeling, we go over the historical progress in the field by explaining the mainly utilized models and how they differ from each other in Section 2.1. After that, the two popular classification techniques namely, SVM and decision tree, are explained in Section 2.2."}, {"heading": "2.1 Topic Modeling", "text": "Topic modeling is an unsupervised learning algorithm that can automatically discover themes of a document collection. Several techniques can be used for this purpose including Latent Semantic Analysis (LSA) [5], Probabilistic Latent Semantic Analysis (PLSA) [6], and Latent Dirichlet Allocation (LDA) [7]. LSA is a way of representing hidden semantic structure of a term-document matrix in which rows are documents and columns are words/tokens [5] based on Singular Value Decomposition (SVD). One limitation of LSA is that each word is represented as a single point with the same meaning; therefore in this representation, polysemes of words cannot be differentiated. Also, the final output of LSA, which consists of axes in Euclidean space, is not interpretable or descriptive [8].\nPLSA is considered to be a probabilistic version of LSA where an unobserved class variable is associated with each occurrence of a word in a particular document [6]. These classes/topics are then inferred from the input text collection. PLSA solves the polysemy problem; however it is not considered a fully generative model of documents which can lead to overfitting [7].\nLDA, first defined by Blei et al [7], defines a topic as a distribution over a fixed vocabulary, where each document can exhibit topics with different proportions. LDA performs better than PLSA for small datasets because it avoids overfitting and it also supports polysemy [7]. Also, in contrast to PLSA, LDA is also considered a fully generative system for documents. Accordingly, LDA is used to generate topic distributions of clinical reports in this study."}, {"heading": "2.2 Text Classification", "text": "Text classification is a supervised machine learning algorithm where each document\u2019s category is learned from a pre-labeled set of documents. Decision trees and support vector machines (SVM) are two such classification algorithms. In a decision tree, internal nodes are the selected terms from the vocabulary, the branches are the criteria on the weight of the terms and the leaves represent the classes. SVM, on the other hand, attempts to find a decision boundary between classes that is the farthest from any point in the training dataset. Given labeled training data (xt, yt), t = 1, ..., N where xt \u2208 RM and yt \u2208 {1,\u22121}, it tries to find a separating hyperplane with the maximum margin [9]. In this study, decision tree and SVM are chosen as classification techniques: Decision tree is preferred due to its explicit rule based output that can be easily evaluated for content validity and SVM performs well in text classification tasks [10, 11]."}, {"heading": "3 Calculation", "text": "Our proposed text classification techniques can be used for various domains. However, our main goal for this study was to utilize such techniques for effective classification of clinical reports. As such, radiology reports from various emergency medicine departments were used to evaluate the proposed classifiers performance. The datasets are computed tomography (CT) imaging reports done for head traumas and they are further explained in the Section 3.1. The preprocessing that they go through before any classification is explained in Section 3.3 and the measures that are used to evaluate the performance of these classifiers are explained in Section 3.2. Finally, after explaining the raw text classification of these clinical reports in Section 3.4, the proposed topic modeling-based classifiers are explained in Section 3.5."}, {"heading": "3.1 Dataset", "text": "This study used prospectively collected patient CT report data previously collected for derivation of a traumatic orbital fracture clinical risk score [12] and a pediatric traumatic brain injury clinical prediction rule [13]. Staff radiologists dictated each CT report and the outcome of interest (either acute orbital fracture or findings consistent with traumatic brain injury) was extracted by a trained data abstractor. Among the 3,705 orbital CT reports, 3,242 were negative and 463 were positive. Among the 2,126 pediatric head CT reports, 1,973 were negative and 153 were positive. Figures 1 and 2 show sample reports from the orbital and pediatric datasets respectively."}, {"heading": "3.2 Evaluation", "text": "In this section, the measures used to evaluate the classification algorithms are explained. Once a classifier is built, its performance is evaluated on a separate dataset. To prevent overfitting, only a subset of the dataset, called the training dataset was used to train the classifier. Its effectiveness was then measured in the remaining unseen documents in the testing set. Also, to effectively measure a classifiers success, training and testing datasets with different proportions were prepared: 75%, 66%, 50%, 34%, and 25%. These training and test datasets were randomized and stratified to make sure each subset is a good representation of the original dataset in terms of class distribution. The orbital dataset has a positive class ratio of 12,5% and the pediatric dataset has a positive class ratio of 7,2%. To evaluate the classification performance, precision, recall, and F-score measures were used. For binary classification, possible cases are summarized in\nTable 1 and Equations 1 and 2 present how precision and recall are calculated.\nF-score is calculated as an equally weighted harmonic mean of precision and recall (See Equation 3):\nF-score = 2\u00d7 Precision\u00d7Recall Precision+Recall\n(3)"}, {"heading": "3.3 Preprocessing", "text": "Text data must be converted to a suitable format for automated processing. One common way of doing this is bag-of-words (BoW) representation where each document becomes a vector of its words/tokens. The entries in this matrix could be binary stating the existence or absence of a word in a document or it could be weighted according to the number of times a word exists in a document. For this study, using term weights produced slightly better classification results than other options. Frequent words were also removed from the vocabulary to limit its size. In addition, these frequent words typically do not add much information; most were stop words such as is, am, are, the, of, at, and. Other preprocessing tasks such as stemming was also explored; however, they did not have a significant effect on the classification performance."}, {"heading": "3.4 Raw Text Classification of Clinical Reports", "text": "Raw text of clinical reports were classified by conventional classification techniques as shown in Figure 3. After preprocessing, the raw text files were combined with their associated outcomes and classified using SVM and decision tree in Weka. Weka is a collection of machine learning algorithms for data mining tasks written in Java [14]."}, {"heading": "3.5 Topic Modeling-based Classification of Clinical Reports", "text": "Clinical reports were classified by topic modeling-based classification techniques as shown in Figure 4. As discussed Section 2.1, we chose LDA to generate the\ntopic models of clinical reports because it is a generative probabilistic system for documents and it is robust to overfitting. The Stanford Topic Modeling Toolbox (TMT) [15] was used to conduct the experiments. It is an open source software providing ways to train and infer topic models for text data."}, {"heading": "3.5.1 Topic Vector Classifier", "text": "In topic vector classifier, a topic model of all of the reports were built and the topic distribution of each report was used to represent them in the form of topic vectors. This could be considered as an alternative representation to bagof-words (BoW), in which terms are replaced with topics and entries for each report show the probability of a specific topic for that report. Representation as topic vectors is more compact than BoW because the vocabulary for a text collection usually has thousands of entries, whereas a topic model is typically\nbuilt with a maximum of hundreds of topics. These topic vectors were then classified via conventional classification algorithms, e.g., SVM and decision tree (See Algorithm 1).\nAlgorithm 1 Topic Vector Classifier\nlearn the topic model for the documents merge the documents in topic vector representation with their classes train decision tree and SVM using documents represented as topic vectors"}, {"heading": "3.5.2 Confidence-based Topic Classifier (CTC)", "text": "In this classifier, after the topic model is learned, a single topic is chosen that has the biggest confidence [16] for a class. The confidence (4) of a topic X for a class Y is calculated as the support (5) of the topic and the class together divided by the support of the topic itself. Using this topic, the predictions for the test dataset are made as shown in Algorithm 2.\nAlgorithm 2 Confidence-based Topic Classifier (CTC)\nlearn the topic model for the documents in the training dataset merge the documents in topic vector representation with their classes calculate the conf(T \u21d2 C) for each topic T and class C in the training dataset find the topic t with the biggest confidence for the positive class pick a threshold for th for the chosen topic t for all documents in the testing dataset do\ninfer the document\u2019s topic distribution find its value v for the chosen topic t if v >th then\npredict as positive else\npredict as negative end if\nend for\nconf(X \u21d2 Y ) = supp(X \u222a Y ) supp(X)\n(4)\nsupp(X) = NX N\n(5)"}, {"heading": "3.5.3 Similarity-based Topic Classifier (STC)", "text": "In this classifier, the topic model was learned on the training datasets and the average of topic distributions for each class was calculated. For a document in\nthe testing dataset, its topic distributions were inferred and the class that was the most similar to it was assigned as its predicted class (See Algorithm 2). To calculate the similarity, the cosine measure was used. Given two vectors x and y, the cosine of the angle between them can be calculated as in Equation 6. Its value ranges between 0 and 1 and the more similar the vectors the higher the cosine score is. In this case, one vector represents the average topic distribution for a given class and another vector represents the topic distribution of a test document.\nAlgorithm 3 Similarity-based Topic Classifier (STC)\nlearn the topic model for the documents in the training dataset merge the documents in topic vector representation with their classes calculate the average topic distribution of each class for all documents in the testing dataset do\ninfer the document\u2019s topic distribution for all classes do\ncalculate the similarity between the document\u2019s topic distribution and average topic distribution of the class\nend for assign the class that is most similar to the document as predicted class\nend for\nSimilarity = cos(\u03b8) = x \u00b7 y |x||y|\n(6)"}, {"heading": "3.5.4 Aggregate Topic Classifier (ATC)", "text": "With this approach, a representative topic vector for each class was composed by averaging their corresponding topic distributions in the training dataset. A discriminative topic was then chosen so that the difference between positive and negative representative vectors is maximum as shown in Algorithm 4. The reports in the test datasets were then classified by analyzing the values of this topic and a threshold was chosen to determine the predicted class. This threshold could be chosen automatically based on class distributions if the dataset is skewed or cross validation methods can be applied to pick a threshold that gives the best classification performance in a validation dataset. This approach is called Aggregate Topic Classifier (ATC) since training labels were utilized in an aggregate fashion using an average function rather than individually."}, {"heading": "4 Results", "text": "The main goal of this study is to analyze and optimize clinical text classification. As a starting point, raw text of clinical reports were classified by well-known conventional classification algorithms. Alternatively, topic modeling of the corpora was used as a compact representation of the clinical reports and classifiers were built using this representation in various ways. The classification results\nAlgorithm 4 Aggregate Topic Classifier (ATC)\nlearn the topic model for the documents in the training dataset merge the documents in topic vector representation with their classes calculate the average of topic distributions of each class pick the topic t whose difference between the average of classes is maximum pick a threshold th on the selected topic t for all documents in the testing dataset do\ninfer the document\u2019s topic distribution find its value v for the chosen topic t if v >th then\npredict as positive else\npredict as negative end if\nend for\nusing the proposed topic model-based classifiers are presented according to the evaluation techniques explained in Section 3.2 ."}, {"heading": "4.1 Raw Text Classification Results", "text": "Raw text of clinical reports were preprocessed and classified using decision tree (DT) and SVM and they are graphically illustrated in Figures 5 and 6 for the orbital and pediatric datasets respectively. SVM performs better than decision tree consistently for different training and testing proportions and for both datasets."}, {"heading": "4.2 Topic Modeling-based Classification Results", "text": "One of the advantages of switching from using the entire vocabulary to represent documents to using topics as explained in Section 2.1 is the dimension reduction (7) achieved by this transformation.\nDimensionReduction(%) =\n\u2211 attributes\u2212 \u2211 topics\u2211\nattributes (7)\nTypically, the vocabulary of a text corpora has a vocabulary in thousands whereas the total number of topics is usually in lower hundreds. The orbital and pediatric datasets had 1,295 and 1,501 attributes respectively. These numbers reflect the total number of attributes after preprocessing such as removal of frequent and infrequent words. For topic numbers ranging from 5 to 150, a dimension reduction of 88% to 99% is achieved for the orbital dataset. Similarly, for pediatric dataset, 90% to 99% dimension reduction is achieved.\nClassification performance of ATC, STC and CTC was compared to SVM and decision tree in Figures 7 and 8 for orbital and pediatric datasets respectively.\nThey are each divided into five sections to show the result of using different training/testing proportions. These training and test datasets are randomized and stratified to make sure each subset is a good representation of the original dataset as explained in Section 3.1. Also, since the best number of topics is not known in advance, different values were considered ranging from 5 to 150. Among all techniques, topic vector classification with SVM performed the best especially with higher number of topics. However, for smaller number of topics, ATC and topic vector classification with decision tree performed better or comparable depending on the training dataset size. Having better performance with lower number of topics is desirable as it leads to faster training and testing times. CTC and STC showed varying success depending on the number of topics and training dataset size; CTC showed improvement as number of topics increased since it uses the entire topic vector for classification. ATC and STC, on the other hand, did not improve as much with the increasing number of topics; since they use a single discriminative topic. Finally, different training and testing proportions had little effect on the classifiers\u2019 performance for both datasets. This implies that the classifiers generalize well and using only small portion for the training dataset would be sufficient to build an accurate classifier. This is a great outcome as typically, it is difficult to find big labeled datasets as the labeling process is costly. To summarize, raw text classification using both decision tree and SVM performed well, with SVM performing better than decision tree for both of the datasets. Alternatively, when topic vector representation of the reports were used, the classification performance got better for both datasets. Between decision tree and SVM, SVM performed better for topic vector classification as well. Among the topic modeling-based classifiers, ATC performed the best for both datasets. ATC also performed better than raw text classification but not better than topic vector classification using SVM. Since ATC is a simpler algorithm compared to SVM, once the topic model is built it may be preferable to use ATC."}, {"heading": "5 Discussion", "text": "Other than standard topic modeling techniques, there have been studies to further enhance the capabilities of standard topic modeling. In [17], Wallach extended the LDA algorithm to handle n-grams. Griffiths et al. combined LDA with POS tagging to have both content and functional words [2]. These studies resulted in a more complex topic-modeling algorithm mostly to make topicmodeling features comparable to Natural Language Processing (NLP), which can slow down the system. Other NLP-based classification techniques, e.g., [18, 19], an be effective in classifying clinical reports as well, however they are computationally expensive and they may require customization by medical experts. As such, we wanted to build a fast and efficient solution using topic modeling without increasing the algorithmic complexity or time to generate topic models. Accordingly, our solutions are based on standard topic modeling\nalgorithms but further extended with our classification techniques.\nIn the field of text classification, topic modeling techniques have been used in various ways. Zhang et al [20] used topic modeling as a keyword selection mechanism by selecting the top words from topics based on their entropy. In our study, we removed the most frequent and infrequent words to produce a manageable vocabulary size but we did not use topic model output as a keyword selection mechanism. Sriurai [21] compares BoW representation to topic model representation for classification using varying and fixed number of topics respectively. This is similar to our topic vector classification results with SVM. However, because the number of topics typically is not known in advance, we evaluated different numbers of topics, whereas Sriurai [21] uses a fixed number of topics. In another similar study, Banerjee [22] uses topics as additional features to BoW features for the purpose of classification. In our approaches, we used topic vector representation as an alternative to BoW representation and not as additional features. This way, we can achieve greater dimension reduction.\nOther than text classification, topic modeling techniques have also been used in related tasks. Arnold et al. [23] shows an information retrieval system where patients can be queried and compared based on their topic distributions. We also used similarity measures to compute the similarity between a report and a class representative topic distribution; however, it is not query-based and it is for classification purposes."}, {"heading": "6 Conclusion", "text": "In this study, topic modeling of clinical reports was used with different classification techniques and automated clinical outcomes were compared with conventional machine learning techniques. Compared to bag-of-words representation, classification using topic vectors performed comparably with the additional benefit of dimension reduction and interpretability. Several supervised classifiers were built based on topic model of the documents in the training dataset. In confidence-based topic classifier (CTC), the topic with biggest confidence for positive class was used to classify reports in the testing dataset. Alternatively, using a similarity-based topic classifier (STC), to classify a document, its topic distribution was compared in similarity to the average topic distributions of each class Finally, in aggregate topic classifier (ATC), a single discriminative topic was chosen and used to classify the reports in the testing dataset. Among these topic modeling-based classifiers, ATC demonstrated the best classification performance, however topic vector classification using SVM was the most successful among all classifiers. Since ATC uses fewer topics and less complex than SVM, it may be still be preferable to use ATC for faster performance with comparable accuracy.\nResults from this study can have significant impacts on the quality and effi-\nciency of healthcare. First of all, the classifiers built in this study can be used to automatically predict the conditions in a clinical report. They can replace the manual review of clinical reports, which can be time consuming and error-prone. In addition, with the increased accuracy and interpretability they provide, clinicians can have more confidence in utilizing such systems in real life settings. Finally, real world datasets such as the ones used in this study could be more challenging than simulated ones. There could be human errors during manual labeling or physicians may disagree. Therefore, it is critical to get good performance on real world datasets so that the systems could be viable to be used in real world settings. Our proposed classifiers provide promising results to be utilized successfully in such settings."}], "references": [{"title": "R", "author": ["Y. Huang", "H.J. Lowe", "D. Klein"], "venue": "J. Cucina, Improved Identification of Noun Phrases in Clinical Radiology Reports Using a High-Performance Statistical Natural Language Parser Augmented with the UMLS Specialist Lexicon., J Am Med Inform Assoc 12 (3) ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2005}, {"title": "Integrating Topics and Syntax", "author": ["T.L. Griffiths", "M. Steyvers", "D.M. Blei", "J.B. Tenenbaum"], "venue": "in: NIPS", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2004}, {"title": "Clinical Report Classification Using Natural Language Processing and Topic Modeling", "author": ["E. Sarioglu", "K. Yadav", "H.-A. Choi"], "venue": "11th International Conference on Machine Learning and Applications (ICMLA) ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Topic Modeling Based Classification of Clinical Reports", "author": ["E. Sarioglu", "K. Yadav", "H.-A. Choi"], "venue": "in: 51st Annual Meeting of the Association for Computational Linguistics Proceedings of the Student Research Workshop", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Indexing by Latent Semantic Analysis", "author": ["S. Deerwester", "S.T. Dumais", "G.W. Furnas", "T.K. Landauer", "R. Harshman"], "venue": "Journal of the American Society for Information Science 41 (6) ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1990}, {"title": "Probabilistic Latent Semantic Analysis", "author": ["T. Hofmann"], "venue": "in: UAI", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1999}, {"title": "Latent Dirichlet Allocation", "author": ["D.M. Blei", "A.Y. Ng", "M.I. Jordan"], "venue": "J. Mach. Learn. Res. 3 ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2003}, {"title": "Unsupervised Learning by Probabilistic Latent Semantic Analysis", "author": ["T. Hofmann"], "venue": "Mach. Learn. 42 (1-2) ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2001}, {"title": "Sequential Minimal Optimization: A Fast Algorithm for Training Support Vector Machines", "author": ["J.C. Platt"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1998}, {"title": "Text Categorization with Suport Vector Machines: Learning with Many Relevant Features", "author": ["T. Joachims"], "venue": "in: Proceedings of the 10th European Conference on Machine Learning", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1998}, {"title": "A Re-examination of Text Categorization Methods", "author": ["Y. Yang", "X. Liu"], "venue": "in: Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1999}, {"title": "S", "author": ["K. Yadav", "E. Cowan", "J.S. Haukoos", "Z. Ashwell", "V. Nguyen", "P. Gennis"], "venue": "P. Wall, Derivation of a Clinical Risk Score for Traumatic Orbital Fracture., J Trauma Acute Care Surg 73 (5) ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Identification of Children at Very Low Risk of Clinically-Important Brain Injuries After Head Trauma: A Prospective Cohort", "author": ["N. Kuppermann"], "venue": "Study., Lancet", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "The WEKA Data Mining Software: An Update", "author": ["M. Hall", "E. Frank", "G. Holmes", "B. Pfahringer", "P. Reutemann", "I.H. Witten"], "venue": "SIGKDD Explor. Newsl. 11 (1) ", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2009}, {"title": "Mining Association Rules Between Sets of Items in Large Databases", "author": ["R. Agrawal", "T. Imieli\u0144ski", "A. Swami"], "venue": "in: Proceedings of the 1993 ACM SIG- MOD International Conference on Management of Data", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1993}, {"title": "Topic Modeling: Beyond Bag-of-Words", "author": ["H.M. Wallach"], "venue": "in: Proceedings of the 23rd International Conference on Machine Learning", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2006}, {"title": "Automated Outcome Classification of Emergency Department Computed Tomography Imaging Reports", "author": ["K. Yadav", "E. Sarioglu", "M. Smith", "H.-A. Choi"], "venue": "Academic Emergency Medicine 20 (8) ", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "An Efficient Feature Selection Using Hidden Topic in Text Categorization", "author": ["Z. Zhang", "X.-H. Phan", "S. Horiguchi"], "venue": "in: Proceedings of the 22nd International Conference on Advanced Information Networking and Applications - Workshops", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2008}, {"title": "Improving Text Classification Accuracy Using Topic Modeling over an Additional Corpus", "author": ["S. Banerjee"], "venue": "in: Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2008}, {"title": "Clinical Case-based Retrieval Using Latent Topic Analysis", "author": ["C.W. Arnold", "S.M. El-Saden", "A.A.T. Bui", "R. Taira"], "venue": "AMIA Annu Symp Proc 2010 ", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "Also, biomedical concepts can be well represented as nouns [1] and compared to other parts of speech, they tend to specialize better into topics [2].", "startOffset": 59, "endOffset": 62}, {"referenceID": 1, "context": "Also, biomedical concepts can be well represented as nouns [1] and compared to other parts of speech, they tend to specialize better into topics [2].", "startOffset": 145, "endOffset": 148}, {"referenceID": 2, "context": "A preliminary version of this work has been reported in [3, 4].", "startOffset": 56, "endOffset": 62}, {"referenceID": 3, "context": "A preliminary version of this work has been reported in [3, 4].", "startOffset": 56, "endOffset": 62}, {"referenceID": 2, "context": "In [3], the performance of topic vector classification with conventional classifiers was analyzed and in [4], aggregate topic classifier (ATC) were introduced using a single dataset.", "startOffset": 3, "endOffset": 6}, {"referenceID": 3, "context": "In [3], the performance of topic vector classification with conventional classifiers was analyzed and in [4], aggregate topic classifier (ATC) were introduced using a single dataset.", "startOffset": 105, "endOffset": 108}, {"referenceID": 4, "context": "Several techniques can be used for this purpose including Latent Semantic Analysis (LSA) [5], Probabilistic Latent Semantic Analysis (PLSA) [6], and Latent Dirichlet Allocation (LDA) [7].", "startOffset": 89, "endOffset": 92}, {"referenceID": 5, "context": "Several techniques can be used for this purpose including Latent Semantic Analysis (LSA) [5], Probabilistic Latent Semantic Analysis (PLSA) [6], and Latent Dirichlet Allocation (LDA) [7].", "startOffset": 140, "endOffset": 143}, {"referenceID": 6, "context": "Several techniques can be used for this purpose including Latent Semantic Analysis (LSA) [5], Probabilistic Latent Semantic Analysis (PLSA) [6], and Latent Dirichlet Allocation (LDA) [7].", "startOffset": 183, "endOffset": 186}, {"referenceID": 4, "context": "LSA is a way of representing hidden semantic structure of a term-document matrix in which rows are documents and columns are words/tokens [5] based on Singular Value Decomposition (SVD).", "startOffset": 138, "endOffset": 141}, {"referenceID": 7, "context": "Also, the final output of LSA, which consists of axes in Euclidean space, is not interpretable or descriptive [8].", "startOffset": 110, "endOffset": 113}, {"referenceID": 5, "context": "PLSA is considered to be a probabilistic version of LSA where an unobserved class variable is associated with each occurrence of a word in a particular document [6].", "startOffset": 161, "endOffset": 164}, {"referenceID": 6, "context": "PLSA solves the polysemy problem; however it is not considered a fully generative model of documents which can lead to overfitting [7].", "startOffset": 131, "endOffset": 134}, {"referenceID": 6, "context": "LDA, first defined by Blei et al [7], defines a topic as a distribution over a fixed vocabulary, where each document can exhibit topics with different proportions.", "startOffset": 33, "endOffset": 36}, {"referenceID": 6, "context": "LDA performs better than PLSA for small datasets because it avoids overfitting and it also supports polysemy [7].", "startOffset": 109, "endOffset": 112}, {"referenceID": 8, "context": ", N where xt \u2208 R and yt \u2208 {1,\u22121}, it tries to find a separating hyperplane with the maximum margin [9].", "startOffset": 99, "endOffset": 102}, {"referenceID": 9, "context": "In this study, decision tree and SVM are chosen as classification techniques: Decision tree is preferred due to its explicit rule based output that can be easily evaluated for content validity and SVM performs well in text classification tasks [10, 11].", "startOffset": 244, "endOffset": 252}, {"referenceID": 10, "context": "In this study, decision tree and SVM are chosen as classification techniques: Decision tree is preferred due to its explicit rule based output that can be easily evaluated for content validity and SVM performs well in text classification tasks [10, 11].", "startOffset": 244, "endOffset": 252}, {"referenceID": 11, "context": "1 Dataset This study used prospectively collected patient CT report data previously collected for derivation of a traumatic orbital fracture clinical risk score [12] and a pediatric traumatic brain injury clinical prediction rule [13].", "startOffset": 161, "endOffset": 165}, {"referenceID": 12, "context": "1 Dataset This study used prospectively collected patient CT report data previously collected for derivation of a traumatic orbital fracture clinical risk score [12] and a pediatric traumatic brain injury clinical prediction rule [13].", "startOffset": 230, "endOffset": 234}, {"referenceID": 13, "context": "Weka is a collection of machine learning algorithms for data mining tasks written in Java [14].", "startOffset": 90, "endOffset": 94}, {"referenceID": 14, "context": "2 Confidence-based Topic Classifier (CTC) In this classifier, after the topic model is learned, a single topic is chosen that has the biggest confidence [16] for a class.", "startOffset": 153, "endOffset": 157}, {"referenceID": 15, "context": "In [17], Wallach extended the LDA algorithm to handle n-grams.", "startOffset": 3, "endOffset": 7}, {"referenceID": 1, "context": "combined LDA with POS tagging to have both content and functional words [2].", "startOffset": 72, "endOffset": 75}, {"referenceID": 16, "context": ", [18, 19], an be effective in classifying clinical reports as well, however they are computationally expensive and they may require customization by medical experts.", "startOffset": 2, "endOffset": 10}, {"referenceID": 17, "context": "Zhang et al [20] used topic modeling as a keyword selection mechanism by selecting the top words from topics based on their entropy.", "startOffset": 12, "endOffset": 16}, {"referenceID": 18, "context": "In another similar study, Banerjee [22] uses topics as additional features to BoW features for the purpose of classification.", "startOffset": 35, "endOffset": 39}, {"referenceID": 19, "context": "[23] shows an information retrieval system where patients can be queried and compared based on their topic distributions.", "startOffset": 0, "endOffset": 4}], "year": 2017, "abstractText": "Electronic health records (EHRs) contain important clinical information about patients. Efficient and effective use of this information could supplement or even replace manual chart review as a means of studying and improving the quality and safety of healthcare delivery. However, some of these clinical data are in the form of free text and require pre-processing before use in automated systems. A common free text data source is radiology reports, typically dictated by radiologists to explain their interpretations. We sought to demonstrate machine learning classification of computed tomography (CT) imaging reports into binary outcomes, i.e. positive and negative for fracture, using regular text classification and classifiers based on topic modeling. Topic modeling provides interpretable themes (topic distributions) in reports, a representation that is more compact than the commonly used bag-of-words representation and can be processed faster than raw text in subsequent automated processes. We demonstrate new classifiers based on this topic modeling representation of the reports. Aggregate topic classifier (ATC) and confidence-based topic classifier (CTC) use a single topic that is determined from the training dataset based on different measures to classify the reports on the test dataset. Alternatively, similarity-based topic classifier (STC) measures the similarity between the reports\u2019 topic distributions to determine the predicted class. Our proposed topic modeling-based classifier systems are shown to be competitive with existing text classification techniques and provides an efficient and interpretable representation.", "creator": "LaTeX with hyperref package"}}}