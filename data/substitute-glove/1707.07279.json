{"id": "1707.07279", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jul-2017", "title": "Using Argument-based Features to Predict and Analyse Review Helpfulness", "abstract": "We evaluation the communicating product appearances identification problem same except printed. We observe referring own evidence - actions discourse relations, because known as arguments, so already over produce nonfiction, there going hypothesise however probably argument - scientific studio, daily. g. also 2.1 of tactless sentences, full evidences - conclusions placement, or hard sharply of reliable nonfiction. To validate this causation, definitely manually initialize arguments from 110 courtyard edited, have investigate this risk of three combinations of characterization - industry features. Experiments moreover put, when was rather take through the argue - based rock, entire ohio - thus - its - art changeup various meant appreciate every well boost (took limits of F1) from 24. debuted \\% new revenue.", "histories": [["v1", "Sun, 23 Jul 2017 10:51:30 GMT  (195kb)", "http://arxiv.org/abs/1707.07279v1", "6 pages, EMNLP2017"]], "COMMENTS": "6 pages, EMNLP2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["haijing liu", "yang gao", "pin lv", "mengxue li", "shiqiang geng", "minglan li", "hao wang"], "accepted": true, "id": "1707.07279"}, "pdf": {"name": "1707.07279.pdf", "metadata": {"source": "CRF", "title": "Using Argument-based Features to Predict and Analyse Review Helpfulness", "authors": ["Haijing Liu", "Yang Gao", "Pin Lv", "Mengxue Li", "Shiqiang Geng", "Minglan Li", "Hao Wang"], "emails": ["haijing@iscas.ac.cn", "mengxue@iscas.ac.cn", "minglan2015@iscas.ac.cn", "gaoyang@iscas.ac.cn,", "lvpin@iscas.ac.cn,", "study@126.com", "cashenry@126.com"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 7.\n07 27\n9v 1\n[ cs\n.C L\n] 2\n3 Ju\nl 2 01\n7\ntification problem in this paper. We observe that the evidence-conclusion discourse relations, also known as arguments, often appear in product reviews, and we hypothesise that some argumentbased features, e.g. the percentage of argumentative sentences, the evidencesconclusions ratios, are good indicators of helpful reviews. To validate this hypothesis, we manually annotate arguments in 110 hotel reviews, and investigate the effectiveness of several combinations of argument-based features. Experiments suggest that, when being used together with the argument-based features, the state-of-the-art baseline features can enjoy a performance boost (in terms of F1) of 11.01% in average."}, {"heading": "1 Introduction", "text": "Product reviews have significant influences on potential customers\u2019 opinions and their purchase decisions (Chatterjee, 2001; Chen et al., 2004; Dellarocas et al., 2004). Instead of reading a long list of reviews, customers usually are only willing to view a handful of helpful reviews to make their purchase decisions. In other words, helpful reviews have even greater influences on the potential customers\u2019 decisionmaking processes and thus on the sales; as a result, the automatic identification of helpful reviews has received considerable research attentions in recent years (Kim et al., 2006; Liu et al., 2008; Mudambi, 2010; Xiong and Litman, 2014; Martin and Pu, 2014; Yang et al., 2015, 2016).\nExisting works on helpful reviews identification mostly focus on designing efficient fea-\ntures. Widely used features include external features, (e.g. date (Liu et al., 2008), product rating (Kim et al., 2006) and product type (Mudambi, 2010)) and intrinsic features (e.g. semantic dictionaries (Yang et al., 2015) and emotional dictionaries (Martin and Pu, 2014)). Compared to external features, intrinsic features can provide some insights and explanations for the prediction results, and support better cross-domain generalisation. In this work, we investigate a new form of intrinsic features: the argument features.\nAn argument is a basic unit people use to persuade their audiences to accept a particular state of affairs (Eckle-Kohler et al., 2015). An argument usually consists of a claim (also known as conclusion) and some premises (also known as evidences) offered in support of the claim. For example, consider the following review excerpt: \u201cThe staff were amazing, they went out of their way to help us\u201d; the texts before the comma constitute a claim, and the texts after the comma give a premise supporting the claim. Argumentation mining (Moens, 2013; Lippi and Torroni, 2016) receives growing research interests in various domains (Palau and Moens, 2009; Contractor et al., 2012; Park and Cardie, 2014; Madnani et al., 2012; Kirschner et al., 2015; Wachsmuth et al., 2014, 2015). Recent advances in automatic arguments identification (Stab and Gurevych, 2014), has stimulated the usage of argument features in multiple domains, e.g. essay scoring (Wachsmuth et al., 2016) and online forum comments ranking (Wei12 et al., 2016).\nThe motivation of this work is a hypothesis that, the helpfulness of a review is closely related to some argument-related features, e.g. the percentage of argumentative sentences, the average number of premises in each argument, etc. To validate our hypothesis, we manually annotate arguments in 110 hotel reviews so as to use these \u201cground\ntruth\u201d arguments to testify the effectiveness of argument-based features for detecting helpful hotel reviews. Empirical results suggest that, for four baseline feature sets we test, their performances can be improved, in average, by 11.01% in terms of F1-score and 10.40% in terms of AUC when they are used together with some argumentbased features. Furthermore, we use the effective argument-based features to give some insights into which product reviews are more helpful."}, {"heading": "2 Corpus", "text": "We use the Tripadvisor hotel reviews corpus built by (O\u2019Mahony and Smyth, 2010) to test the performance of our helpful reviews classifier. Each entry in this corpus includes the review texts, the number of people that have viewed this review (denoted by Y) and the number of people that think this review is helpful (denoted by X).\nWe randomly sample 110 hotel reviews from this corpus to annotate the \u201cground truth\u201d argument structures 1. In line with (Wachsmuth et al., 2015), we view each sub-sentence in the review as a clause and ask three annotators independently to annotate each clause as one of the following seven argument components:\nMajor Claim: a summary of the main opinion of a review. For instance, \u201cI have enjoyed the stay in the hotel\u201d, \u201cI am sad to say that i am very disappointed with this hotel\u201d;\nClaim: a subjective opinion on a certain aspect of a hotel. For example, \u201cThe staff was amazing\u201d, \u201cThe room is spacious\u201d;\nPremise: an objective reason/evidence supporting a claim. For instance, \u201cThe staff went out of their way to help us\u201d, it supports the first example claim above; \u201cWe had a sitting room as well as a balcony\u201d, it supports the second example claim above;\nPremise Supporting an Implicit Claim (PSIC): an objective reason/evidence that supporting an implicit claim, which does appear in review. For instance, \u201cjust five minutes\u2019 walk to the down town\u201d supports some implicit claims like \u201cthe location of the hotel is good\u201d, although this implicit claims has never appeared in the review;\nBackground: an objective description that does not give direct opinions but provides some background information. For example, \u201cWe checked\n1The annotated corpus can be obtained by contacting the first author\ninto this hotel at midnight\u201d, \u201cI stayed five nights at this hotel because i was attending a conference at the hotel\u201d;\nRecommendation: a positive or negative recommendation for the hotel. For instance, \u201cI would definitely come to this hotel again the next time I visit London\u201d, \u201cDo not come to this hotel if you look for some clean places to live\u201d;\nNon-argumentative: for all the other clauses. We use the Fleiss\u2019 kappa metric (Fleiss, 1971) to evaluate the quality of the obtained annotations, and the results are presented in Table 1. We can see that the lowest Kappa scores (for Premise) is still above 0.6, suggesting that the quality of the annotations are substantial (Landis and Koch, 1977); in other words, there exist little noises in the ground truth argument structures. We aggregate the annotations using majority voting."}, {"heading": "3 Features", "text": "In line with (Yang et al., 2015), we consider the helpfulness as an intrinsic characteristic of product reviews, and thus only consider the following four intrinsic features as our baseline features.\nStructural features (STR) (Kim et al., 2006; Xiong and Litman, 2014): we use the following structural features: total number of tokens, total number of sentences, average length of sentences, number of exclamation marks, and the percentage of question sentences.\nUnigram features (UGR) (Kim et al., 2006; Xiong and Litman, 2014): we remove all stopwords and non-frequent words (tf < 3) to build the unigram vocabulary. Each review is represented by the vocabulary with tf-idf weighting for each appeared term.\nEmotional features (GALC) (Martin and Pu, 2014): the Geneva Affect Label Coder (GALC) dictionary proposed by (Scherer, 2005) defines 36 emotion states distinguished by words. We build a real feature vector with the number of occurrences\nof each emotional word plus one additional dimension for the number of non-emotional words.\nSemantic features (INQUIRER) (Yang et al., 2015): the General Inquirer (INQUIRER) dictionary proposed by (Stone et al., 1962) maps each word to some semantic tags, e.g. word absurd is mapped to tags NEG and VICE; similar to the GALC features, the semantic features include the number of occurrences of each semantic tag."}, {"heading": "3.1 Argument-based Features", "text": "The argument-based features can have different granularity: for example, the number of argument components can be used as features, and the number of tokens (words) in the argument components can also be used as features. We consider four granularity of argument features, detailed as follows.\nComponent-level argument features. A natural feature that we believe to be useful is the ratio of different argument component numbers. For example, we may be interested in the ratio between the number of premises and that of claims; a high ratio suggests that there are more premises supporting each claim, indicating that the review gives many evidences. To generalise this component ratio feature, we propose component-combination ratio features: we compute the ratios between any two argument components combinations. For example, we may be interested in the ratio between the number of MajorClaim+Claim+Premise and that of Background+Non-argumentative. As there are 7 types of labels, the number of possible combinations is 27\u22121 = 127, and thus the possible number of combination ratio pairs is 127 \u00d7 126 = 16002. In other words, the component-level feature is a 16002-dimensional real vector.\nToken-level argument features. In a finergranularity, we consider the number of tokens in argument components to build features: for example, suppose a review has only two claims, one has 10 words and the other has 5 words; we may want to know the average number of words contained in each claim, the total number of words in claims, etc. In total, for each argument component type, we consider 5 types of token-level statistics: the total number of words in the given component type, the length (in terms of word) of the shortest/longest component of the given type, and the mean/variance of the number of words in\neach component of the given type. Thus, there are in total 7\u00d7 5 = 35 features to represent the tokenlevel statistics.\nIn addition, the ratio of some token-level statistics may also be of interests: for example, given a review, we may want to know the ratio between the number of words in Claims+MajorClaims and that in Premises. Thus, the combination ratio can also be applied here. We consider only the combination ratio for two statistics: the total number of words and the average number of words in each component-combination; hence, there are 16002 \u00d7 2 = 32004 dimensions for the combination ratio for the statistics. In total, there are 32004 + 35 = 32039 dimensions for the tokenlevel argument features.\nLetter-level argument features. In the finestgranularity, we consider the letter-level features, which may give some information the token-level features do not contain: for example, if a review has a big number of letters and a small number of words, it may suggests that many long and complex words are used in this review, which, in turn, may suggests that the linguistic complexity of the review is relative high and the review may gives some very professional opinions. Similar to the token-level features above, we design 5 types of statistics and their combination ratios. Thus, the dimension for the letter-level features is the same to that of the token-level features.\nPosition-level argument features. Another dimension to consider argument features is the positions of argument components: for example, if the major claims of a review are all at the very beginning, we may think that readers can more easily grasp the main idea of the review and, thus, the review is more likely to be helpful. For each component, we use a real number to represent its position: for example, if a review has 10 subsentences (i.e. clauses) in total and the first subsentence the component overlaps is the second sub-sentence, then the position for this component is 2/10 = 0.2. For each type of argument component, we may be interested in some statistics for its positions: for example, if a review has several premises, we may want to know the location of the earliest/latest appearance of premises, the average position of all premises and its variance, etc. Similar to the token- and letter-level features, we design the same number of features for positionlevel features."}, {"heading": "4 Experiments", "text": "Following (O\u2019Mahony and Smyth, 2010; Martin and Pu, 2014), we model the helpfulness prediction task as a classification problem; thus, we use accuracy, precision, recall, macro F1 and area under the curve (AUC) to as evaluation metrics. Similar to (O\u2019Mahony and Smyth, 2010), we consider a review as helpful if and only if at least 75% opinions for the review are positive, i.e. X/Y \u2265 0.75 (see X and Y in Sect. 2). For the features whose number of dimensions is more than 10k (i.e. the UGR features and argument-based features), to reduce their dimensions and to improve the performance, we only use the positive-information-gain features in these feature sets. In line with most existing works on helpfulness prediction (Martin and Pu, 2014; Yang et al., 2015), we use the LibSVM (Chang and Lin, 2011) as our classifier.\nThe performances of different features are presented in Table 2. Each number in the table is the average performance in 10-fold cross-validation tests. From the table we can see that, when being used together with the argument-based features, either of the four baseline features enjoys a performance boost in terms of all metrics we consider. To be more specific, in terms of accuracy, precision, recall, F1 and AUC, the average improvement for the baseline features are 4.33%, 10.30%, 4.32%, 11.01% and 10.40%, respectively. However, we observe that the precision of UGR+AF, although gives the second highest score among all feature combinations, is lower than that of UGR; we leave it for future work. Also, we notice that when using the argument-based features alone, its performance (in terms of Precision, F1 and AUC) is superior to those of STR, GALC and INQUIRER, and is only inferior to UGR. However, a major drawback of the UGR feature is\nits huge and document-dependent dimensionality, while the dimensionality of argument-based features is fixed, regardless of the size of the input documents. Moreover, the UGR features are sparse and problematic in online learning. To summarise, compared with the other state-of-theart features, argument-based features are effective in identifying helpful reviews, and can represent some complementary information that cannot be represented in other features."}, {"heading": "5 What Makes a Review Helpful ?", "text": "Argument-based features can not only improve the performance of review helpfulness identification, but also can be used to interpret what makes a review helpful. We analyse the information gain ranking of the argument-based features and find that, among all the positive-informationgain argument features, 36% are from the tokenlevel argument feature set, and 29% are from the letter-level argument feature set, suggesting that these two feature sets are most effective in identifying helpful reviews. Among all the tokenlevel argument features with positive information gain, 69% are ratios of sum of token number between component-combinations, and the remaining are ratios of the mean token numbers between component-combinations. We interpret this observation as follows: given a review, the larger number of tokens it contains, and the more likely the review is helpful. In fact, helpful reviews are tend to occur in those long reviews, which generally provide with more experiences and comments about the product being reviewed. Among all the letter-level argument features, around threequarters are ratios of the sum of the number of letters between component-combinations. This observation, again, suggests that the length of reviews plays an important role in the review helpfulness identification.\nMoreover, among all the argument-based features with positive information gain values, a quarter of features are the position-level argument feature. This is because the position of each argument component influences the logic flow of reviews, which, in turn, influences the readability, convincingness and helpfulness of the reviews. This information can hardly be represented by all the baseline features we considered, and we believe this explains why the performances of the baseline features are improved when being used together with the argument-based features. However, among all the argument-based features with positive information gain values, only 10% are the componentlevel argument feature. This indicates that compared to three finer-granularity argument features above, the component-level argument feature provides less useful information in review helpfulness identification."}, {"heading": "6 Conclusion and Future Work", "text": "In this work, we propose a novel set of intrinsic features of identifying helpful reviews, namely the argument-based features. We manually annotate 110 hotel reviews, and compare the performances of argument-based features with those of some state-of-the-art features. Empirical results suggest that, argument-based features include some complementary information that the other feature sets do not include; as a result, for each baseline feature, the performance (in terms of various metrics) of jointly using this feature and argumentbased features is higher than using this baseline feature alone. In addition, by analysing the effectiveness of different argument-based features, we give some insights into which reviews are more likely to be helpful, from an argumentation perspective.\nFor future work, an immediate next step is to explore the usage of automatically extracted arguments in helpful reviews identification: in this work, all argument-based features are based on manually annotated arguments; deeplearning based argument mining (Li et al., 2017; Eger et al., 2017) has produced some promising results recently, and we plan to investigate whether the automatically extracted arguments can be used to identify helpful reviews, and how the errors made in the argument extraction stage will influence the performance of helpful reviews identification. We also plan to investigate the effective-\nness of argument-based features in other domains."}, {"heading": "Acknowledgements", "text": "Yang Gao is supported by National Natural Science Foundation of China (NSFC) grant 61602453, and Hao Wang is supported by NSFC grant 61672501, 61402447 and 61502466."}], "references": [{"title": "Libsvm: a library for support vector machines", "author": ["Chih-ChungChang", "Chih-Jen Lin."], "venue": "ACM transactions on intelligent systems and technology (TIST), 2(3):27.", "citeRegEx": "Chih.ChungChang and Lin.,? 2011", "shortCiteRegEx": "Chih.ChungChang and Lin.", "year": 2011}, {"title": "Online reviews: Do consumers use them? ACR North American Advances", "author": ["Patrali Chatterjee"], "venue": null, "citeRegEx": "Chatterjee.,? \\Q2001\\E", "shortCiteRegEx": "Chatterjee.", "year": 2001}, {"title": "The impact of online recommendations and consumer feedback on sales", "author": ["Pei-Yu Chen", "Shin-yi Wu", "Jungsun Yoon."], "venue": "ICIS 2004 Proceedings, page 58.", "citeRegEx": "Chen et al\\.,? 2004", "shortCiteRegEx": "Chen et al\\.", "year": 2004}, {"title": "Using argumentative zones for extractive summarization of scientific articles", "author": ["Danish Contractor", "Yufan Guo", "Anna Korhonen."], "venue": "coling, volume 12, pages 663\u2013678.", "citeRegEx": "Contractor et al\\.,? 2012", "shortCiteRegEx": "Contractor et al\\.", "year": 2012}, {"title": "Exploring the value of online reviews to organizations: Implications for revenue forecasting and planning", "author": ["Chrysanthos Dellarocas", "Neveen Awad", "Xiaoquan Zhang."], "venue": "ICIS 2004 Proceedings, page 30.", "citeRegEx": "Dellarocas et al\\.,? 2004", "shortCiteRegEx": "Dellarocas et al\\.", "year": 2004}, {"title": "On the role of discourse markers for discriminating claims and premises in argumentative discourse", "author": ["Judith Eckle-Kohler", "Roland Kluge", "Iryna Gurevych."], "venue": "EMNLP, pages 2236\u20132242.", "citeRegEx": "Eckle.Kohler et al\\.,? 2015", "shortCiteRegEx": "Eckle.Kohler et al\\.", "year": 2015}, {"title": "Neural end-to-end learning for computational argumentation mining", "author": ["Steffen Eger", "Johannes Daxenberger", "Iryna Gurevych."], "venue": "arXiv preprint arXiv:1704.06104.", "citeRegEx": "Eger et al\\.,? 2017", "shortCiteRegEx": "Eger et al\\.", "year": 2017}, {"title": "Measuring nominal scale agreement among many raters", "author": ["Joseph L Fleiss."], "venue": "Psychological bulletin, 76(5):378.", "citeRegEx": "Fleiss.,? 1971", "shortCiteRegEx": "Fleiss.", "year": 1971}, {"title": "Automatically assessing review helpfulness", "author": ["Soo-Min Kim", "Patrick Pantel", "Tim Chklovski", "Marco Pennacchiotti."], "venue": "Proceedings of the 2006 Conference on empirical methods in natural language processing, pages 423\u2013430. Association for", "citeRegEx": "Kim et al\\.,? 2006", "shortCiteRegEx": "Kim et al\\.", "year": 2006}, {"title": "Linking the thoughts: Analysis of argumentation structures in scientific publications", "author": ["Christian Kirschner", "Judith Eckle-Kohler", "Iryna Gurevych."], "venue": "ArgMining@ HLT-NAACL, pages 1\u201311.", "citeRegEx": "Kirschner et al\\.,? 2015", "shortCiteRegEx": "Kirschner et al\\.", "year": 2015}, {"title": "The measurement of observer agreement for categorical data", "author": ["J Richard Landis", "Gary G Koch."], "venue": "biometrics, pages 159\u2013174.", "citeRegEx": "Landis and Koch.,? 1977", "shortCiteRegEx": "Landis and Koch.", "year": 1977}, {"title": "Joint rnn model for argument component boundary detection", "author": ["Minglan Li", "Yang Gao", "Hui Wen", "Yang Du", "Haijing Liu", "Hao Wang."], "venue": "arXiv preprint arXiv:1705.02131.", "citeRegEx": "Li et al\\.,? 2017", "shortCiteRegEx": "Li et al\\.", "year": 2017}, {"title": "Argumentation mining: State of the art and emerging trends", "author": ["Marco Lippi", "Paolo Torroni."], "venue": "ACM Transactions on Internet Technology (TOIT), 16(2):10.", "citeRegEx": "Lippi and Torroni.,? 2016", "shortCiteRegEx": "Lippi and Torroni.", "year": 2016}, {"title": "Modeling and predicting the helpfulness of online reviews", "author": ["Yang Liu", "Xiangji Huang", "Aijun An", "Xiaohui Yu."], "venue": "Data mining, 2008. ICDM\u201908. Eighth IEEE international conference on, pages 443\u2013452. IEEE.", "citeRegEx": "Liu et al\\.,? 2008", "shortCiteRegEx": "Liu et al\\.", "year": 2008}, {"title": "Identifying high-level organizational elements in argumentative discourse", "author": ["Nitin Madnani", "Michael Heilman", "Joel Tetreault", "Martin Chodorow."], "venue": "Proceedings of the 2012 Conference of the North American Chapter of the Association for Computa-", "citeRegEx": "Madnani et al\\.,? 2012", "shortCiteRegEx": "Madnani et al\\.", "year": 2012}, {"title": "Prediction of helpful reviews using emotions extraction", "author": ["Lionel Martin", "Pearl Pu."], "venue": "Proceedings of the 28th AAAI Conference on Artificial Intelligence (AAAI-14), EPFL-CONF-210749.", "citeRegEx": "Martin and Pu.,? 2014", "shortCiteRegEx": "Martin and Pu.", "year": 2014}, {"title": "Argumentation mining: Where are we now, where do we want to be and how do we get there? In Post-Proceedings of the 4th and 5th Workshops of the Forum for Information Retrieval Evaluation, page 2", "author": ["Marie-Francine Moens."], "venue": "ACM.", "citeRegEx": "Moens.,? 2013", "shortCiteRegEx": "Moens.", "year": 2013}, {"title": "What makes a helpful online review? astudy of customer reviews on amazon", "author": ["Susan M Mudambi."], "venue": "com. MIS Quarterly, 34(1):185\u2013200.", "citeRegEx": "Mudambi.,? 2010", "shortCiteRegEx": "Mudambi.", "year": 2010}, {"title": "A classification-based review recommender", "author": ["Michael P O\u2019Mahony", "Barry Smyth"], "venue": "Knowledge-Based Systems,", "citeRegEx": "O.Mahony and Smyth.,? \\Q2010\\E", "shortCiteRegEx": "O.Mahony and Smyth.", "year": 2010}, {"title": "Argumentation mining: the detection, classification and structure of arguments in text", "author": ["Raquel Mochales Palau", "Marie-Francine Moens."], "venue": "Proceedings of the 12th international conference on artificial intelligence and law, pages 98\u2013107. ACM.", "citeRegEx": "Palau and Moens.,? 2009", "shortCiteRegEx": "Palau and Moens.", "year": 2009}, {"title": "Identifying appropriate support for propositions in online user comments", "author": ["Joonsuk Park", "Claire Cardie."], "venue": "ArgMining@ ACL, pages 29\u201338.", "citeRegEx": "Park and Cardie.,? 2014", "shortCiteRegEx": "Park and Cardie.", "year": 2014}, {"title": "What are emotions? and how can they be measured", "author": ["Klaus R Scherer"], "venue": "Social science information,", "citeRegEx": "Scherer.,? \\Q2005\\E", "shortCiteRegEx": "Scherer.", "year": 2005}, {"title": "Identifying argumentative discourse structures in persuasive essays", "author": ["Christian Stab", "Iryna Gurevych."], "venue": "EMNLP, pages 46\u201356.", "citeRegEx": "Stab and Gurevych.,? 2014", "shortCiteRegEx": "Stab and Gurevych.", "year": 2014}, {"title": "The general inquirer: A computer system for content analysis and retrieval based on the sentence as a unit of information", "author": ["Philip J Stone", "Robert F Bales", "J Zvi Namenwirth", "Daniel M Ogilvie."], "venue": "Behavioral Science, 7(4):484\u2013498.", "citeRegEx": "Stone et al\\.,? 1962", "shortCiteRegEx": "Stone et al\\.", "year": 1962}, {"title": "Using argument mining to assess the argumentation quality of essays", "author": ["Henning Wachsmuth", "Khalid Al Khatib", "Benno Stein."], "venue": "COLING, pages 1680\u20131691.", "citeRegEx": "Wachsmuth et al\\.,? 2016", "shortCiteRegEx": "Wachsmuth et al\\.", "year": 2016}, {"title": "Sentiment flow-a general model of web review argumentation", "author": ["Henning Wachsmuth", "Johannes Kiesel", "Benno Stein."], "venue": "EMNLP, pages 601\u2013611.", "citeRegEx": "Wachsmuth et al\\.,? 2015", "shortCiteRegEx": "Wachsmuth et al\\.", "year": 2015}, {"title": "Modeling review argumentation for robust sentiment analysis", "author": ["HenningWachsmuth", "Martin Trenkmann", "Benno Stein", "Gregor Engels."], "venue": "COLING, pages 553\u2013564.", "citeRegEx": "HenningWachsmuth et al\\.,? 2014", "shortCiteRegEx": "HenningWachsmuth et al\\.", "year": 2014}, {"title": "Is this post persuasive? ranking argumentative comments in the online forum", "author": ["Zhongyu Wei", "Yang Liu", "Yi Li"], "venue": "In The 54th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Wei12 et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wei12 et al\\.", "year": 2016}, {"title": "Empirical analysis of exploiting review helpfulness for extractive summarization of online reviews", "author": ["Wenting Xiong", "Diane J Litman."], "venue": "COLING, pages 1985\u20131995.", "citeRegEx": "Xiong and Litman.,? 2014", "shortCiteRegEx": "Xiong and Litman.", "year": 2014}, {"title": "Aspect-based helpfulness prediction for online product reviews", "author": ["Yinfei Yang", "Cen Chen", "Forrest Sheng Bao."], "venue": "Tools with Artificial Intelligence (ICTAI), 2016 IEEE 28th International Conference on, pages 836\u2013843. IEEE.", "citeRegEx": "Yang et al\\.,? 2016", "shortCiteRegEx": "Yang et al\\.", "year": 2016}, {"title": "Semantic analysis and helpfulness prediction of text for online product reviews", "author": ["Yinfei Yang", "Yaowei Yan", "Minghui Qiu", "Forrest Sheng Bao."], "venue": "ACL (2), pages 38\u201344.", "citeRegEx": "Yang et al\\.,? 2015", "shortCiteRegEx": "Yang et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 1, "context": "Product reviews have significant influences on potential customers\u2019 opinions and their purchase decisions (Chatterjee, 2001; Chen et al., 2004; Dellarocas et al., 2004).", "startOffset": 106, "endOffset": 168}, {"referenceID": 2, "context": "Product reviews have significant influences on potential customers\u2019 opinions and their purchase decisions (Chatterjee, 2001; Chen et al., 2004; Dellarocas et al., 2004).", "startOffset": 106, "endOffset": 168}, {"referenceID": 4, "context": "Product reviews have significant influences on potential customers\u2019 opinions and their purchase decisions (Chatterjee, 2001; Chen et al., 2004; Dellarocas et al., 2004).", "startOffset": 106, "endOffset": 168}, {"referenceID": 8, "context": "In other words, helpful reviews have even greater influences on the potential customers\u2019 decisionmaking processes and thus on the sales; as a result, the automatic identification of helpful reviews has received considerable research attentions in recent years (Kim et al., 2006; Liu et al., 2008; Mudambi, 2010; Xiong and Litman, 2014; Martin and Pu, 2014; Yang et al., 2015, 2016).", "startOffset": 260, "endOffset": 381}, {"referenceID": 13, "context": "In other words, helpful reviews have even greater influences on the potential customers\u2019 decisionmaking processes and thus on the sales; as a result, the automatic identification of helpful reviews has received considerable research attentions in recent years (Kim et al., 2006; Liu et al., 2008; Mudambi, 2010; Xiong and Litman, 2014; Martin and Pu, 2014; Yang et al., 2015, 2016).", "startOffset": 260, "endOffset": 381}, {"referenceID": 17, "context": "In other words, helpful reviews have even greater influences on the potential customers\u2019 decisionmaking processes and thus on the sales; as a result, the automatic identification of helpful reviews has received considerable research attentions in recent years (Kim et al., 2006; Liu et al., 2008; Mudambi, 2010; Xiong and Litman, 2014; Martin and Pu, 2014; Yang et al., 2015, 2016).", "startOffset": 260, "endOffset": 381}, {"referenceID": 28, "context": "In other words, helpful reviews have even greater influences on the potential customers\u2019 decisionmaking processes and thus on the sales; as a result, the automatic identification of helpful reviews has received considerable research attentions in recent years (Kim et al., 2006; Liu et al., 2008; Mudambi, 2010; Xiong and Litman, 2014; Martin and Pu, 2014; Yang et al., 2015, 2016).", "startOffset": 260, "endOffset": 381}, {"referenceID": 15, "context": "In other words, helpful reviews have even greater influences on the potential customers\u2019 decisionmaking processes and thus on the sales; as a result, the automatic identification of helpful reviews has received considerable research attentions in recent years (Kim et al., 2006; Liu et al., 2008; Mudambi, 2010; Xiong and Litman, 2014; Martin and Pu, 2014; Yang et al., 2015, 2016).", "startOffset": 260, "endOffset": 381}, {"referenceID": 13, "context": "date (Liu et al., 2008), product rating (Kim et al.", "startOffset": 5, "endOffset": 23}, {"referenceID": 8, "context": ", 2008), product rating (Kim et al., 2006) and product type (Mudambi, 2010)) and intrinsic features (e.", "startOffset": 24, "endOffset": 42}, {"referenceID": 17, "context": ", 2006) and product type (Mudambi, 2010)) and intrinsic features (e.", "startOffset": 25, "endOffset": 40}, {"referenceID": 30, "context": "semantic dictionaries (Yang et al., 2015) and emotional dictionaries (Martin and Pu, 2014)).", "startOffset": 22, "endOffset": 41}, {"referenceID": 15, "context": ", 2015) and emotional dictionaries (Martin and Pu, 2014)).", "startOffset": 35, "endOffset": 56}, {"referenceID": 5, "context": "An argument is a basic unit people use to persuade their audiences to accept a particular state of affairs (Eckle-Kohler et al., 2015).", "startOffset": 107, "endOffset": 134}, {"referenceID": 16, "context": "Argumentation mining (Moens, 2013; Lippi and Torroni, 2016) receives growing research interests in various domains (Palau and Moens, 2009; Contractor et al.", "startOffset": 21, "endOffset": 59}, {"referenceID": 12, "context": "Argumentation mining (Moens, 2013; Lippi and Torroni, 2016) receives growing research interests in various domains (Palau and Moens, 2009; Contractor et al.", "startOffset": 21, "endOffset": 59}, {"referenceID": 19, "context": "Argumentation mining (Moens, 2013; Lippi and Torroni, 2016) receives growing research interests in various domains (Palau and Moens, 2009; Contractor et al., 2012; Park and Cardie, 2014; Madnani et al., 2012; Kirschner et al., 2015; Wachsmuth et al., 2014, 2015).", "startOffset": 115, "endOffset": 262}, {"referenceID": 3, "context": "Argumentation mining (Moens, 2013; Lippi and Torroni, 2016) receives growing research interests in various domains (Palau and Moens, 2009; Contractor et al., 2012; Park and Cardie, 2014; Madnani et al., 2012; Kirschner et al., 2015; Wachsmuth et al., 2014, 2015).", "startOffset": 115, "endOffset": 262}, {"referenceID": 20, "context": "Argumentation mining (Moens, 2013; Lippi and Torroni, 2016) receives growing research interests in various domains (Palau and Moens, 2009; Contractor et al., 2012; Park and Cardie, 2014; Madnani et al., 2012; Kirschner et al., 2015; Wachsmuth et al., 2014, 2015).", "startOffset": 115, "endOffset": 262}, {"referenceID": 14, "context": "Argumentation mining (Moens, 2013; Lippi and Torroni, 2016) receives growing research interests in various domains (Palau and Moens, 2009; Contractor et al., 2012; Park and Cardie, 2014; Madnani et al., 2012; Kirschner et al., 2015; Wachsmuth et al., 2014, 2015).", "startOffset": 115, "endOffset": 262}, {"referenceID": 9, "context": "Argumentation mining (Moens, 2013; Lippi and Torroni, 2016) receives growing research interests in various domains (Palau and Moens, 2009; Contractor et al., 2012; Park and Cardie, 2014; Madnani et al., 2012; Kirschner et al., 2015; Wachsmuth et al., 2014, 2015).", "startOffset": 115, "endOffset": 262}, {"referenceID": 22, "context": "Recent advances in automatic arguments identification (Stab and Gurevych, 2014), has stimulated the usage of argument features in multiple domains, e.", "startOffset": 54, "endOffset": 79}, {"referenceID": 24, "context": "essay scoring (Wachsmuth et al., 2016) and online forum comments ranking (Wei12 et al.", "startOffset": 14, "endOffset": 38}, {"referenceID": 27, "context": ", 2016) and online forum comments ranking (Wei12 et al., 2016).", "startOffset": 42, "endOffset": 62}, {"referenceID": 18, "context": "We use the Tripadvisor hotel reviews corpus built by (O\u2019Mahony and Smyth, 2010) to test the performance of our helpful reviews classifier.", "startOffset": 53, "endOffset": 79}, {"referenceID": 25, "context": "In line with (Wachsmuth et al., 2015), we view each sub-sentence in the review as a clause and ask three annotators independently to annotate each clause as one of the following seven argument components:", "startOffset": 13, "endOffset": 37}, {"referenceID": 7, "context": "We use the Fleiss\u2019 kappa metric (Fleiss, 1971) to evaluate the quality of the obtained annotations, and the results are presented in Table 1.", "startOffset": 32, "endOffset": 46}, {"referenceID": 10, "context": "6, suggesting that the quality of the annotations are substantial (Landis and Koch, 1977); in other words, there exist little noises in the ground truth argument structures.", "startOffset": 66, "endOffset": 89}, {"referenceID": 30, "context": "In line with (Yang et al., 2015), we consider the helpfulness as an intrinsic characteristic of product reviews, and thus only consider the following four intrinsic features as our baseline features.", "startOffset": 13, "endOffset": 32}, {"referenceID": 8, "context": "Structural features (STR) (Kim et al., 2006; Xiong and Litman, 2014): we use the following", "startOffset": 26, "endOffset": 68}, {"referenceID": 28, "context": "Structural features (STR) (Kim et al., 2006; Xiong and Litman, 2014): we use the following", "startOffset": 26, "endOffset": 68}, {"referenceID": 8, "context": "Unigram features (UGR) (Kim et al., 2006; Xiong and Litman, 2014): we remove all stopwords and non-frequent words (tf < 3) to build the unigram vocabulary.", "startOffset": 23, "endOffset": 65}, {"referenceID": 28, "context": "Unigram features (UGR) (Kim et al., 2006; Xiong and Litman, 2014): we remove all stopwords and non-frequent words (tf < 3) to build the unigram vocabulary.", "startOffset": 23, "endOffset": 65}, {"referenceID": 15, "context": "Emotional features (GALC) (Martin and Pu, 2014): the Geneva Affect Label Coder (GALC) dictionary proposed by (Scherer, 2005) defines 36 emotion states distinguished by words.", "startOffset": 26, "endOffset": 47}, {"referenceID": 21, "context": "Emotional features (GALC) (Martin and Pu, 2014): the Geneva Affect Label Coder (GALC) dictionary proposed by (Scherer, 2005) defines 36 emotion states distinguished by words.", "startOffset": 109, "endOffset": 124}, {"referenceID": 30, "context": "Semantic features (INQUIRER) (Yang et al., 2015): the General Inquirer (INQUIRER) dictionary proposed by (Stone et al.", "startOffset": 29, "endOffset": 48}, {"referenceID": 23, "context": ", 2015): the General Inquirer (INQUIRER) dictionary proposed by (Stone et al., 1962) maps each word to some semantic tags, e.", "startOffset": 64, "endOffset": 84}, {"referenceID": 18, "context": "Following (O\u2019Mahony and Smyth, 2010; Martin and Pu, 2014), we model the helpfulness prediction task as a classification problem; thus, we use accuracy, precision, recall, macro F1 and area under the curve (AUC) to as evaluation metrics.", "startOffset": 10, "endOffset": 57}, {"referenceID": 15, "context": "Following (O\u2019Mahony and Smyth, 2010; Martin and Pu, 2014), we model the helpfulness prediction task as a classification problem; thus, we use accuracy, precision, recall, macro F1 and area under the curve (AUC) to as evaluation metrics.", "startOffset": 10, "endOffset": 57}, {"referenceID": 18, "context": "Similar to (O\u2019Mahony and Smyth, 2010), we consider a review as helpful if and only if at least 75% opinions for the review are positive, i.", "startOffset": 11, "endOffset": 37}, {"referenceID": 15, "context": "In line with most existing works on helpfulness prediction (Martin and Pu, 2014; Yang et al., 2015), we use the LibSVM (Chang and Lin, 2011) as our classifier.", "startOffset": 59, "endOffset": 99}, {"referenceID": 30, "context": "In line with most existing works on helpfulness prediction (Martin and Pu, 2014; Yang et al., 2015), we use the LibSVM (Chang and Lin, 2011) as our classifier.", "startOffset": 59, "endOffset": 99}, {"referenceID": 11, "context": "tion: in this work, all argument-based features are based on manually annotated arguments; deeplearning based argument mining (Li et al., 2017; Eger et al., 2017) has produced some promising results recently, and we plan to investigate whether the automatically extracted arguments can be used to identify helpful reviews, and how the errors", "startOffset": 126, "endOffset": 162}, {"referenceID": 6, "context": "tion: in this work, all argument-based features are based on manually annotated arguments; deeplearning based argument mining (Li et al., 2017; Eger et al., 2017) has produced some promising results recently, and we plan to investigate whether the automatically extracted arguments can be used to identify helpful reviews, and how the errors", "startOffset": 126, "endOffset": 162}], "year": 2017, "abstractText": "We study the helpful product reviews identification problem in this paper. We observe that the evidence-conclusion discourse relations, also known as arguments, often appear in product reviews, and we hypothesise that some argumentbased features, e.g. the percentage of argumentative sentences, the evidencesconclusions ratios, are good indicators of helpful reviews. To validate this hypothesis, we manually annotate arguments in 110 hotel reviews, and investigate the effectiveness of several combinations of argument-based features. Experiments suggest that, when being used together with the argument-based features, the state-of-the-art baseline features can enjoy a performance boost (in terms of F1) of 11.01% in average.", "creator": "LaTeX with hyperref package"}}}