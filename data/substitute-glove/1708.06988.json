{"id": "1708.06988", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-May-2017", "title": "Paving the Roadway for Safety of Automated Vehicles: An Empirical Study on Testing Challenges", "abstract": "The use has the inland it electronically vehicles is record speed and promises be skill. However, short one seen included major stipulates kiosks car, we be also seen accidents. Test basic for so, conditionally automated (e. b. , out highways) and turnstiles vehicles always not exists yet made wo lab already laymen followed each aspects. For except, increase level procedures do not suffice no fully automated workers, which are supposed made nothing easily before charge for seen drunk preparation and though no worker as giving rest put. This copy presents current challenges another testing after functionality and problems of electronic carriers derived early conducting experience groups two transcripts, 26 counterparts from 25 domestic having put suggests related give testing infineon damage - related topics. We provide an glossary of beginning country - much - first included testing activity safety segment came well as potential being needs even be briefed in has future be restore require same automated vehicles. The similar potential unclear kept three interviews up focus forming, destined by textbook on this political none related giving 10) disk process part simulation, 2) emergency, reliability, through quality, 3) circuitry taken switches characteristics, 90) provide change complexity three more of deciding similar, then 5) handover of ensure divided the driver and called targets.", "histories": [["v1", "Tue, 9 May 2017 10:09:18 GMT  (572kb,D)", "http://arxiv.org/abs/1708.06988v1", "8 pages"]], "COMMENTS": "8 pages", "reviews": [], "SUBJECTS": "cs.SE cs.AI cs.RO", "authors": ["alessia knauss", "jan schr\\\"oder", "christian berger", "henrik eriksson"], "accepted": false, "id": "1708.06988"}, "pdf": {"name": "1708.06988.pdf", "metadata": {"source": "CRF", "title": "Paving the Roadway for Safety of Automated Vehicles: An Empirical Study on Testing Challenges", "authors": ["Alessia Knauss", "Jan Schr\u00f6der", "Christian Berger", "Henrik Eriksson"], "emails": ["alessia.knauss@chalmers.se", "jan.schroder}@gu.se", "henrik.eriksson@sp.se"], "sections": [{"heading": null, "text": "I. INTRODUCTION\nToday\u2019s technological advancements in the automotive domain bring more and more automation to our vehicles. The size of vehicle software is growing exponentially, while the safety has also to increase to allow for driving without a driver as a back up. Cases like Toyota\u2019s unintended acceleration [1] show that already trivial mistakes can cause severe fatalities. Furthermore, the recent introduction of conditionally automated driving has also resulted in several accidents [2]\u2013[4].\nThese examples show that testing needs to cover a broad spectrum of unforeseeable situations and characteristics for automated vehicles where the driver is not monitoring the driving activity any more and cannot serve as a fall back option. Standardized test protocols, such as EuroNCAP, exist to systematically test features aiming to support the driver with safety functionality to avoid or mitigate accidents. However, such standards do not exist for automated driving. In this paper, we investigate the following research question:\n*This work was supported by Vinnova grant 2014-06229. 1Alessia Knauss is with the Department of Computer Science and Engineering, Chalmers University of Technology, Gothenburg, Sweden alessia.knauss@chalmers.se\n2Jan Schr\u00f6der and Christian Berger are with the Department of Computer Science and Engineering, University of Gothenburg, Sweden {christian.berger, jan.schroder}@gu.se\n3 Henrik Eriksson is with the Department of Electronics, RISE Research Institutes of Sweden, Bor\u00e5s, Sweden henrik.eriksson@sp.se\nRQ: What are the challenges that have to be addressed in order to test (conditionally) automated vehicles?\nBased on focus groups with practitioners from Sweden as well as interviews with practitioners and researchers from Sweden, Germany, the US, Netherlands, and China, we systematically gather and discuss testing challenges that need to be overcome in the near future to ensure safety of increasingly automated vehicles. The 26 participants are from eight different companies (e.g., five of them premium automotive OEMs), seven research institutes and universities, and one proving ground. We have presented an excerpt of the identified challenges for the software engineering community in [5]. In this paper, we analyze and identify the gap between current state-of-the-practice and future needs for testing of increasingly automated vehicles, highlight and explain all identified areas where research and development are urgent and most beneficial. Additionally, the identified areas are validated against open literature which of today is quite limited.\nThe paper is structured as follows: In Section II we provide background information and discuss related work. Section III outlines our research methodology. We present our results on the state-of-the-practice of safety-related aspects in Section IV and on challenges in testing automated vehicles in Section V. In Section VI, we depict threats to validity and conclude our paper in Section VII."}, {"heading": "II. BACKGROUND AND RELATED WORK", "text": ""}, {"heading": "A. Background", "text": "A number of active safety systems has been developed to avoid or mitigate the consequences of common accident scenarios such as: rear-end, on-coming, and run-off road. To find representative scenarios and define viable test methods, accident data has been studied. To perform the resulting rating tests, an advanced driving robot is needed in the test vehicle to achieve repeatability and the necessary precision and accuracy. Additionally, a soft target having its own propulsion system will act as sensor stimulus for the function under test [6].\nIn specific use cases, such as traffic jams or highway driving, lateral and longitudinal functionality are combined to reach a higher level of automation by simultaneous control of steering and acceleration/deceleration. To be able to discuss the different challenges at different levels of automation ranging from no to full automation, different standardization bodies have defined a limited number of levels and their meaning. In this paper we use the definition of automation levels proposed by the Society of Automotive Engineers (SAE) [7]. We define automated driving as SAE levels 3-5.\nar X\niv :1\n70 8.\n06 98\n8v 1\n[ cs\n.S E\n] 9\nM ay\n2 01\n7"}, {"heading": "B. Related Work:", "text": "The success of automated road vehicles depends on several aspects; testing, verification, validation, and certification being some of them [8]\u2013[13]. Existing work indicates that relevant test scenarios and systematic evaluation approaches need to be defined for the assessment of automated vehicles. Furthermore, since field tests become unviable due to the large number of kilometers to be driven [12], [14], the majority of the testing must be performed using simulations or virtual test driving [15], whose results are validated on proving grounds or in field tests. Virtual testing can also contribute to identify a further relevant test scenarios [16], and the number of tests to perform can be reduced using combinatorial testing [17]. Test tracks need to complement testing with orchestrating several automated actors involved in a scenario [18]. In highly automated vehicles, the hand-over [19] between driver and vehicle and vice versa becomes crucial [8] in order to avoid issues such as mode confusion and unfair transitions [20]."}, {"heading": "III. RESEARCH METHODOLOGY", "text": "In our exploratory empirical investigation we used two different instruments of data collection: First degree and third degree data sources. First degree included focus groups and interviews [21] (Section III-A), while third degree included studying existing research publications (Section III-B) related to the studied topic."}, {"heading": "A. Focus Groups and Interviews", "text": "First, we used focus groups to enable a rich discussion and a broad understanding of the studied topic, before focusing on specific details. The interviews aimed at understanding the topics in more detail.\n1) Participants: Due to the sensitive topic studied in this paper, many participants were concerned taking part in this study and share their insights. Hence, to maximize the response rate, we used convenience sampling [21] and invited only our contacts in the area of active safety testing from industry and academia. Participants from academia were chosen to have a close collaboration with industry, and being involved in industry projects related to automated vehicles.\nFocus groups: First, we conducted four focus groups with eleven participants from Sweden between September 7th, 2015 to November 25th, 2015. Focus group 1 included five engineers and one manager with up to 15 years experience in safety testing. Focus group 2 consisted of one manager and one senior researcher with 19 and 12 years experience in automotive safety. Focus group 3 included two engineers and one manager with up to 14 years experience, and focus group 4 one manager with over 30 years experience in automotive safety. The last focus group could also be classified as interview \u2013 as the rest of the participants canceled their participation. The focus groups included representatives from one supplier, one proving ground for active safety testing and related researcher, and two automotive OEMs.\nInterviews: We conducted 15 (semi-)structured interviews with participants from five different countries. Interviews were conducted to include each participant\u2019s view individually"}, {"heading": "ID Country Position Experience Research", "text": "in our study and took place between May 23rd, 2016 and October 24th, 2016. Table I depicts the details of our interview participants: country, position, and years of experience in an area related to automotive safety. Participants are split into research (i.e., four participants currently employed in research institutes and three at universities) and industry (i.e., seven participants from automotive OEMs and one from an automotive supplier), sorted based on years of experience.\nThe response rate for the interviews was 60%. We have approached 25 possible participants, eleven from Germany, six from Sweden, six from US, one from China, and one from Netherlands. We were able to conduct 15 interviews. Furthermore, due to data concerns of the participants, we present the results anonymously, do not share the transcripts, and do not describe the employment details of the participants, but only present their position and years of expertise.\n2) Data Collection: Each focus group and interview contained two parts, part 1) focusing on the state-of-thepractice of testing active safety systems, and part 2) on future trends. The interview lengths was 45 minutes, the focus groups 60 minutes in lengths to allow for enriched discussions. Four interviews were conducted in person, the rest took place on Skype or phone.\nDue to the exploratory nature of the study, we only used a few open-ended questions to not restrict the participants going into one specific direction. The major question used for part 1) state-of-the-practice was \u201cHow do you test active safety systems?\u201d, while for part 2) we used \u201cWhat are the future trends on vehicle automation (looking at SAE Levels 3-5)? How will testing have to change to address these future trends topics?\u201d. Part 1) and 2) contained the same sub-questions:\n\u2022 What are the stakeholders of testing active safety systems/automated vehicles? \u2022 What are the quality criteria for successfully testing active safety systems/automated vehicles? \u2022 What are the processes, methods, and tools involved in\ntesting of active safety systems/automated vehicles? Each focus group and interview was conducted by two researchers. The first author had always the role of a moderator, asking questions and giving directions to the participants to explore the topic under study. The second researcher was responsible for taking notes and was alternating either the second or third author or Hang Yin, another researcher from a similar research field.\n3) Data Analysis: To analyze the collected data and derive our findings, we applied techniques recommended for empirical research methods [21]: We transferred the notes from both the focus groups and the interviews into a list of over 1000 separate statements consisting of 1-3 sentences that logically belong together. Hence, the content of the focus groups was handled with the same weight as one interview due to the fact that we could not track back the contribution of each participant in the focus groups. The individual results and further details on the focus groups (e.g., results from applying word frequency analysis on the notes) can be found in Knauss et al. [22].\nFor the list of statements, we applied coding starting from statements provided by the four focus groups, and continuing with the statements from the interviews. First we assigned low-level codes and later allocated them to respective highlevel clusters. We assigned topics to these clusters and iterated once again to make sure that the codes are assigned properly. We present the topics with example statements in Section IV for state-of-the-practice and Section V-A for future trends."}, {"heading": "B. Analysis of Challenges in Related Research Publications", "text": "At the beginning of our study in August 2015 there were hardly any research publications about systematic testing for autonomously driving vehicles targeting commercial applications. This initiated our exploratory research method using participants views. While we were conducting our study several related papers have been published. Hence, the analysis of related literature is considered as a final step, comparing our results to their results. We identified ten papers that are considered to be the most relevant ones for testing of automated vehicles [8]- [17]. We compare whether and which of the challenges we identified from our interviews and focus groups are presented in these ten publications. We present these results in Section V-B."}, {"heading": "IV. RESULTS: STATE-OF-THE-PRACTICE OF TESTING ACTIVE SAFETY SYSTEMS", "text": "The following results are based on the focus groups and interviews. They are meant to provide the necessary information on the stakeholders, current quality criteria, processes, methods, and tools to understand the main contribution of the paper regarding challenges of testing automated vehicles.\nThe stakeholders of testing active safety systems mentioned by the participants of this study sorted by priority are: OEMs and their different subgroups (e.g., developers, feature owners, project managers, testers), suppliers, Government and organizations for test methods/catalogs definition/legislative organizations, customers, certification bodies running different\ntests, proving grounds, others like researchers, insurance companies and journalists.\nThe identified processes and methods are: \u2022 Development processes following for example the V-\nmodel, reaching from requirements elicitation, to test definition, and implementation of active safety functions. Testing during development reaches from testing of lower level separate components to full vehicle testing. This includes software, but also hardware-related testing: electronic control unit (ECU) testing, testing of functionality, model-in-the-loop, software-in-the-loop, hardware-in-theloop, and vehicle-in-the-loop testing, etc. as well as integration tests on the test track. Agile methodologies are also identified by the participants as a commonly used development practice, for which contract-based design is used where contracts are defined between the components and can be tested against. \u2022 Proving ground testing plays an important role in active safety testing (e.g., used for release testing). However, OEMs try to minimize the testing on the proving ground as it is costly. For release testing, certain scenarios are tested for, which are currently derived from analyzing accident data and finding the most common accident patterns. \u2022 Instead, simulation and virtual reality testing are used before going to the proving ground to make sure the functions work under different conditions. Again, simulation and virtual reality are used as a means to test the identified scenarios from accident data. Data from real test drives are used to simulate driving scenarios. \u2022 Certification testing based on norms like EuroNCAP. \u2022 Finally, the vehicles are running on public roads \u2013\ncurrently these test drives are a means to collect real data to be used for testing in simulations rather than used as a testing technique.\nThe identified quality criteria (i.e., criteria that are used to determine whether a test is successful) span different levels of development related testing including: concrete quality attributes, use case testing, testing of sensor related aspects, and testing whether certain scenarios are fulfilled. If an OEM follows the V-model, there are certain tests that are part of the formal process and are derived from the requirements for verification and validation. For testing of the final vehicle, collision avoidance and criteria in predefined (certification) tests represent quality criteria. An active safety system is supposed to actively avoid accidents or mitigate the consequences thereof. Hence, collision avoidance or the remaining velocity during a crash are one of the mentioned quality criteria. For certification testing, quality criteria are exactly defined (e.g., in EuroNCAP, ISO 26262 certification).\nThe tools in-use identified by the participants are: \u2022 Related to proving ground testing: Driving robots, test\ntargets (e.g., soft targets) used to simulate vehicles or other targets (e.g., pedestrians) as well as the target carriers, cameras or eye trackers (e.g., to measure the driver behavior), reference positioning system, rapid\nprototyping tools, data logging and collection tools, and automatic reporting tools. \u2022 Development tools: Requirements management tools, risk estimation tools, HMI development tools, HIL, scripting tools, IDE, code generation, databases, validation and verification tools, sensor interface replacement tools. \u2022 Modeling and simulators: Simplified models of vehicles and traffic sets, as well as modeling of accident scenarios are needed. Furthermore, sensor models (including noise of sensors like rain and fog) have to be created to simulate the sensor input during simulation testing. \u2022 Data related tools: Sensor fusion tools, data collection tools (e.g., CAN bus data in vehicles) and labeling of data tools, databases and analysis of logged data. \u2022 A few tools to automate testing tasks were mentioned like test creation and analysis of results."}, {"heading": "V. RESULTS: CHALLENGES OF TESTING AUTOMATED VEHICLES", "text": "A. Identified Challenges in Focus Groups and Interviews\nA summary of challenges when testing automated vehicles is presented in Fig. 1 based on the content of the four focus groups and the 15 interviews. The challenges are sorted based on the amount of participants discussed the corresponding challenge. Figure 2 depicts the challenges with their distribution of participants from research and industry from the interviews. We describe each of the challenges in detail:\nVirtual testing and simulation \u2013 increasingly important: Because of the vast amount of testing that is required for automated vehicles and the high costs for practical testing, virtual testing and simulation gain increased importance as indicated by the participants. The advantages of virtual testing are\n\u2022 efficient testing, as it can support parallel testing or during day and night, which a proving ground cannot support. Hence, testing the vehicle for the required millions of kilometers \u201ccan be reached over a couple of days\u201d.\n\u2022 allows to recreate complex traffic scenarios using real traffic data. It is difficult to recreate scenarios in exactly the same way on a proving ground without simplifying the scenarios. Hence, simulation testing allows to test with more data and different conditions, considering different weather, climate, and driving conditions in different areas. \u2022 supports testing of human-related aspects. Simulation and virtual reality allow for a safe testing environment, compared to proving ground or real life testing, especially considering that \u201cpeople [might] use the system differently than expected?\u201d \u2022 possible to combine virtual reality and simulation with field testing. This augmented reality can be used to test complex traffic scenarios, using the real data communication between the vehicles and the infrastructure.\nDespite the advantages of simulation and virtual reality testing, there are many challenges to be addressed:\n\u2022 Can certifications be based on simulations or virtual reality? The legal aspects of using simulations as a means to achieve certifications need to be explored by the testing authorities. \u2022 If testing in simulation and real environments is combined (i.e., mixed reality testing), a specific infrastructure is required. \u2022 Better simulation tools regarding test efficiency. \u2022 Virtual vehicles and accurate sensor models. \u2022 Benchmark scenarios for simulations. \u2022 A simulation environment relies on real-world data\ncollected from real traffic. For each scenario the right data set needs to be identified and field data needs to be collected. \u2022 Automatic labeling of data is needed to allow the application of artificial intelligence.\nScenario complexity and many test cases \u2013 necessary to test for: At the moment, complex scenarios with multiple test objects cannot be tested at the proving ground, but will become important for automated vehicles. \u201cComplexity un-\nexpectedly high\u201d: As automated vehicles will go everywhere and have to be tested that they are safe in every environment, not only the complexity of the scenarios but also the variety of test cases to test for will have to increase. \u201cAlmost impossible to think about all possible traffic scenarios.\u201d If not all test cases are possible to test for at the proving ground, virtual reality and simulation are suggested as one possible solution. Then the tests can run in parallel and can run non-stop. More data, kilometers, and testing different conditions as well as considering different weather, climate, and driving conditions in different areas is necessary to consider during testing to guarantee safety in all possible conditions. Furthermore, machine learning will be necessary to cope with the data.\nChange of responsibility \u2013 handover increases nonfunctional aspects testing: An active safety system is only supporting the driver. For automated vehicles there is a shift from driver in charge to vehicle in charge where the vehicle has to be fully available at all times, making right decisions and making sure the passengers are safe. Many challenges arise due to this shift.\nFor conditionally automated vehicles, testing includes scenarios where the vehicle hands over the driving task to the driver, but also the driver might want the responsibility back: \u201chow to test an automated vehicle with test people sitting inside the car and the vehicle might \u2018go bananas\u2019? \u201d. In cases where the vehicle cannot handle the driving task (e.g., due to failures in the vehicle), it needs to be able to give back the responsibility to the driver: \u201cTesting that the human can take over in case the vehicle requests to\u201d. One solution might be that a vehicle should always be able to go in safe mode, in case the driver cannot take over. Testing for this criteria on \u201cDoes a car go to safe mode?\u201d is crucial.\nWith the change of responsibility due to increased vehicle automation there is a need to consider a broader range of testing non-functional properties. While for the lower levels 3-4 the testing of driver awareness is important, for full automation car-sickness is one of the interviewee\u2019s concerns. Similarly, in lower levels of automation the vehicle should postpone its action to as late as possible to give the driver the chance to react. In fully automated vehicles the vehicle reaction (e.g. braking) is enabled as early as possible to support driver comfort (e.g. non-functional testing). In an automated vehicle you have to trust the system and feel safe as your safety depends on the automated vehicle. Based on the interviews, testing for the safety feeling poses a challenge. User-friendliness and robustness of functions are other nonfunctional requirements to consider testing for.\nSafety, reliability, and quality \u2013 increasingly important: There are different aspects on how automated vehicles will make driving safer, e.g. through a centralized speed control on highways, preventing cars from speeding. Traffic jams will decrease, due to central control. Despite the advantages that a central instance will bring, each of the vehicles itself must be safe. People that are supposed to use automated vehicles expect vehicles to not be involved in accidents: \u201cThere will be zero-failure acceptance: customers want to have bullet-proof cars\u201d. However, other opinions are that \u201cIt does not have to\nbe perfect. It should be better than humans, but how good does it have to be to be better than humans?\u201d Regulations should define how safe safe enough is: \u201cThe question is: is 100 life safe enough if 2 are killed?\u201d Higher safety standards and stricter validation & verification are needed. Certification will play a major role. Legal aspects focus on defining when a certain quality is reached: \u201cHow do you make sure that I do not miss an object in front of me?\u201d\nQuality has to increase, while it is still impossible to test the vehicles in all possible conditions. Reliability and accountability are also mentioned as major criteria for automated vehicles. Concerning testing of automated vehicles, the testing on proving grounds should be safe in respect to test equipment and processes, especially when testing fully automated vehicles which might behave in unexpected ways.\nField and proving ground tests \u2013 have their limitations: For Level 4 and 5, there will be even more sensors and communication of vehicles. This requires new equipment on proving grounds, the targets should be remote controlled individually from one central instance to ensure that certain predefined situations are guaranteed, and new test methods in respect to automation of test processes should be developed: \u201cEverything will be similar but much harder\u201d. Data logging from many entities, test scenarios that are less predictable, interactions with other vehicles, altering weather and environmental conditions are challenging topics mentioned for proving ground testing.\nAs EuroNCAP will not be sufficient for automated vehicles, more complex scenarios will be used for Level 4-5 vehicles. It will be less deterministic, needs to cover more kilometers, consider more data, different conditions, weather, and climate. Limitations of proving grounds are: limited roads, limited space, light conditions, not possible to test all scenarios. Certain aspects might be tested though continuous experimentation. Recorded real world traffic data can be collected with this method to also work offline with this data. However, continuous experimentation has its limitations (e.g. privacy aspects). Hence, the proposed solution is to test certain aspects, especially early phases, on the test track, and otherwise move to virtual testing or real world testing.\nTool chains \u2013 integration of different testing techniques necessary: New, well-defined, and established test processes are required for automated vehicles. The manual testing established for non-automated vehicles will require an increase of software engineers if the same procedures will be applied to automated vehicles. To counteract this costly aspect, (semi-)automation of test processes as well as the use of cheaper testing techniques (e.g., simulation testing) than real-life testing is needed. One example that was mentioned was support to automatically identifying scenarios for major real-world events.\nFor the increasing levels of automation, scenarios are becoming more complex. For full automation the costs of testing all functionality on the proving ground are too high. It seems crucial to test certain functionality beforehand. Furthermore, in automated vehicles not only the triggering of the functionality needs to be tested. Additionally, it has\nto be investigated whether a certain functionality is not triggered when it should not, monitored over a recommended distance [14].\nFully automated vehicles will change their behavior at runtime. Real-world testing will be inevitable in these cases. As not all requirements are known when developing an automated system and features will be added after the vehicle is delivered, real-world testing will allow continuous software engineering. Proving ground testing will then be used at development time.\nCommunication (e.g., vehicle-to-infrastructure, vehicleto-vehicle) \u2013 support necessary to ensure availability: Communication between everything, and the infrastructure to support this communication is crucial for future automated vehicles. The infrastructure has to provide interfaces for automated vehicles: \u201cit\u2019s about understanding each others intentions/states\u201d and testing whether correct messages are sent. IT companies supporting this communication will be key players in this ecosystem. Availability \u2013 a major characteristic of automated vehicles, will be supported through redundant communication, and could be enabled by vehicle-to-vehicle and vehicle-to-infrastructure communication.\nData and data formats \u2013 are becoming increasingly important: For automated vehicles it is necessary to use data from real-driving in different conditions \u2013 not only very specific predefined scenarios as is the state-of-the-practice for active safety systems. The collection, analysis, labeling, and providing data in a systematic and efficient way is a crucial point for testing of automated vehicles. Predefined data formats are necessary to reuse data for different tools. Furthermore, the amount of data that is collected for every drive considering the amount of drives we need for later reuse and analysis represents a big data problem. Hence, data providers that focus on providing data in a systematic way and serve with input data together with databases, but also provide some kind of automation of the test evaluations were mentioned as a new type of stakeholders.\nAnother important aspect concerns the data from real test drives and on how to transfer the huge amount of data in an efficient and secure way (e.g., V2V, test drives). Testing on whether the data that a vehicle received from another entity (e.g., parking provider) is correct and the vehicle could trust this entity is necessary to implement in automated vehicles.\nSensors and their models: In non-automated driving the driver is the instance that monitors everything and reacts to certain situations. In automated vehicles, the vehicle itself must \u201csee everything\u201d and is not supposed to ever fail. Hence, topics like sensor availability, performance, validation, and redundancy mechanisms are important. Questions arise like: How do the sensors perform? What is the field of view for the sensors? Are there redundant mechanisms implemented?\nTo answer these questions, lots of data from real traffic is needed. Further sensors and better sensors with dedicated tool chains are needed to be able to simulate all maneuvers. Sensor settings have to be recalibrated efficiently, sensor data has to be compared to ground truth data, concerning accurate positioning, time, and synchronization of vehicle data.\nDuring simulation and virtual reality testing certain sensors\nneed to be simulated. Sensor models are used for this purpose. These models are supposed to correctly replace real sensors to run on real computers in real time and should represent the real environment. Hence, these models should also model faulty behavior: \u201cHow detailed a world model has to be is difficult to say.\u201d\nStandards and certifications: To guarantee robustness of automated vehicles, the definition and introduction of quality criteria, regulations, standards, and certifications are required. Participants mentioned that new insurance companies and policy makers might be introduced to deal with this. An approach similar to the star system (e.g., EuroNCAP) for the current safety systems is also needed for automated vehicles for each of the Levels 3-5. Other options to explore for certification include virtual testing or testing in real traffic. Furthermore, it is unclear how the certification of system functionality that is realized through machine learning algorithms will be achieved, which might result in potential re-certification.\nTest automation \u2013 required to increase efficiency of testing: Artificial Intelligence applied on big data is one promising strategy to deal with the complexity of automated vehicles and especially with their testing. With increased automation levels the amount of testing required to guarantee safety has to be expanded. Test automation will support efficient testing. Examples for test automation mentioned by the study participants include:\n\u2022 Automated data analysis applied for different problems where patterns need to be found in big data. For example, new processes are needed to automatically extract test cases from real-world events. \u2022 Automated data collection and attribute labeling. \u2022 Automated testing on proving grounds. \u2022 Automated testing integrated into fully automated vehi-\ncles to guarantee safety at runtime.\nDevelopment processes \u2013 flexibility necessary: Not all requirements are defined from the beginning in automated vehicles. Requirements need to be added while the vehicle is developed as well as updated after the vehicle is delivered. The development processes need to be adjusted to allow for a more flexible approach. During the development of the vehicle the ability to move more efficiently between the different development activities (e.g., in the V-model) is needed. Experts assess that the life cycle will become shorter. Accordingly, the processes should allow for these shorter iterations. Thus, it is not clear how suitable the V-model will remain for this kind of development. Current processes might partially remain V-like, while other parts might need different approaches. However, OEMs will only focus on sub-processes to handle the complexity of a fully automated vehicle. To support the full process of developing an automated vehicle, an increased number of software engineers is needed, which might be difficult to employ by a single OEM. Furthermore, test-driven approaches will gain importance, requiring to start testing at the beginning of the life cycle. This supports efficient processes, in which one get maximum amount of\nresults with least amount of effort. Agile methodologies seem to provide the advantage of having testing in focus and allow for an increased quality with permanent testing activities.\nDue to the importance of real data in developing certain functionality, continuous software engineering, especially continuous experimentation will gain increased importance. During continuous experimentation, disabled functions are delivered with the vehicle that collect run-time data. However, there are some concerns with this method that have to be solved in order for this method to be acceptable: 1) the privacy concerns, and 2) because the actual actuators are disabled, it is not certain that a required feature would have triggered and hence cannot be used as a reliable testing technique. \u201cTesting is not supposed to ever stop\u201d to make sure that the changes in the system behavior are safe. As one of the major changes with fully automated vehicles is that the driver is not involved in the driving task and will not be required to monitor the driving of the vehicle.\nTesting of AI/Adaptation \u2013 needs to be considered: As automated vehicles will be used in unobserved environments, the development of features needs to consider and will rely on data collected at runtime and will even use artificial intelligence to support system functionality. With these techniques, automated vehicles will continuously learn and gain new knowledge. At certain points they will adapt their behavior, also known as self-adaptive capability. Hence, automated vehicles will not always behave deterministic, as we expect them to. During testing, automated vehicles might e.g. learn what is right and what is wrong and pass a test without problems next time. This behavior, however, might only be triggered in a similar environment \u2013 in this case the test environment, and not achieve the same results in a similar but different environment. Questions remain on how to test and validate (self-)adaptive behavior. Testing simple scenarios will not be sufficient. Complex scenarios which are less deterministic having more degrees of freedom are needed. Furthermore, the testing cannot stop after the vehicle is delivered to the customers. The vehicle has to be tested\nfor learning effects. The current state-of-the-practice does not cover testing of machine learning and artificial intelligent techniques; novel processes, techniques, and tools are required to support this kind of testing."}, {"heading": "B. Priorities of Challenges enriched by Literature", "text": "The results of analysing whether and how many recent publications contain challenges we identified is illustrated in Table II. The conclusion from the comparison is that all challenges identified in this paper are covered in at least one of the other papers. Virtual testing and simulation is the most common challenge in the literature and in our study. Similarly, development processes and testing of artificial intelligence/self-adaptation are the least common challenges. There are however a few discrepancies: sensor and sensor modeling as well as test automation are more common in literature than in our study. Contrary, V2X communication is a more common challenge in our study than in literature. Table II summarizes these results through an adjusted ranking, based on the average of both results: our study results and challenges covered in the 10 studied publications."}, {"heading": "VI. THREATS TO VALIDITY", "text": "The presented challenges are not necessarily related to new research areas, neither are they meant as an exhaustive representation of all existing challenges. Our work rather aims at matching the industrial and academic view to highlight important gaps. For example, to our surprise, the topic of security issues was not discussed but represents usually an important challenge. For some challenges presented even commercial approaches exist already but seem to have weaknesses. Furthermore, we acknowledge that we only focused on a few stakeholder groups. With this, we purposefully did not cover all stakeholders of this ecosystem. For example, we could have included policy makers but focused specifically on the three stakeholder groups (i.e., OEMs, suppliers, and researchers), as the topic is already very broad and we would risk to loose our focus by including even further stakeholder groups.\nOur data collection is based on four focus groups and 15 interviews. This amount might be considered too limited to draw conclusions from. However, due to the sensitivity of the data around automated vehicles, participants, especially from the premium manufacturers, are cautious to participate in this kind of studies. Our results mostly include participants in management positions and hence expected to have a good overview of their discipline. Furthermore, our results indicate a saturation for the identified challenges. We reached an agreement between at least 3 participants on each of the 13 identified challenges after conducting the focus groups and 6 interviews. After analyzing all collected data, we have at least an agreement of 7 participants for each challenge. Hence, we are confident that including further participants in the study would not have changed the results to a large extent; if at all, then just shifting the weights of the identified challenges. Another mitigation strategy that we applied was to additionally analyze related work for these challenges, which again confirmed our results, as all challenges identified by us could also be found in the studies published in the last year.\nThe data was analyzed by the first author and could introduce some biases to the results. We have taken a sample of the first five interviews, resembling 20% of the entire statements from the focus groups and interviews. This sample was analyzed in terms of assigning codes to the content by the second author. Codes matching all 13 challenges have been identified, some on a lower level of abstraction. Additionally, the second author identified 2 additional topics.\nAnother bias could be related to researchers taking notes instead of using transcripts. Due to the sensitivity of our research topic, we tried to mitigate the risk of participants not attending due to audio recording and transcribing the interviews afterwards. Hence, we decided to take notes during the interviews. Our mitigation strategy to not introduce biases from the person taking notes was to have three different researchers involved in taking the notes. Hence, this should even out preassumptions or directions for a favorable topic."}, {"heading": "VII. CONCLUSION AND FUTURE WORK", "text": "We have presented an empirical study on the challenges of testing automated vehicles. We have compared our results to the challenges identified in literature in 2016, as this topic starts to attract research attention. The major challenges identified are related to 1) virtual testing and simulation, 2) safety, reliability, and quality, 3) sensors and their models, 4) required scenarios complexity and amount of test cases, and 5) handover between driver and vehicle and shift of the responsibility to the vehicle.\nFuture work should extend this study to include participants from further countries, stakeholder groups, and focus on addressing the presented challenges."}, {"heading": "ACKNOWLEDGMENTS", "text": "We are deeply indebted to all participants of our study and Dr. Hang Yin for notes taking during several interviews."}], "references": [{"title": "A case study of toyota unintended acceleration and software safety", "author": ["P. Koopman"], "venue": "September 2014. [Online]. Available: https: //users.ece.cmu.edu/~koopman/pubs/koopman14_toyota_ua_slides.pdf", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "Google Self-Driving Car Crash Report", "author": ["The Verge"], "venue": "2016, last access September 15th, 2016. [Online]. Available: http://www.theverge.com/ 2016/2/29/11134344/google-self-driving-car-crash-report", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2016}, {"title": "Tesla Self-driving Car \u2013 Death during driving in Autopilot", "author": ["The Guardian"], "venue": "2016, last access September 15th, 2016. [Online]. Available: https://www.theguardian.com/technology/2016/jun/ 30/tesla-autopilot-death-self-driving-car-elon-musk", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2016}, {"title": "nuTonomy halts vehicle trials after accident at one-north", "author": ["Channel NewsAsia"], "venue": "2016, last access October 25th, 2016. [Online]. Available: http://www.channelnewsasia.com/news/singapore/ nutonomy-halts-vehicle-trials-after-accident-at-one-north/3219314. html", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "Softwarerelated challenges of testing automated vehicles", "author": ["A. Knauss", "J. Schroeder", "C. Berger", "H. Eriksson"], "venue": "Proceedings of the International Conference on Software Engineering (ICSE), 2017.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2017}, {"title": "Test methods for consumer protection and legislation for ADAS", "author": ["P. Seiniger", "A. Weitzel"], "venue": "Handbook of Driver Assistance Systems: Basic Information, Components and Systems for Active Safety and Comfort, pp. 213\u2013230, 2016.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2016}, {"title": "Taxonomy and definitions for terms related to on-road motor vehicle automated driving systems", "author": ["SAE", "J3016"], "venue": "2014.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Challenges and approaches for testing of highly automated vehicles", "author": ["H.-P. Sch\u00f6ner"], "venue": "Energy Consumption and Autonomous Driving. Springer, 2016, pp. 101\u2013109.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2016}, {"title": "Technical evaluation and impact assessment of automated driving", "author": ["F. Fahrenkrog"], "venue": "Road Vehicle Automation 3. Springer, 2016, pp. 237\u2013246.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2016}, {"title": "Validation and verification of automated road vehicles", "author": ["V. Agaram"], "venue": "Road Vehicle Automation 3. Springer, 2016, pp. 201\u2013210.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2016}, {"title": "Testing of highly automated driving functions", "author": ["J. Mazzega"], "venue": "ATZ worldwide, vol. 118, no. 10, pp. 44\u201348, 2016.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2016}, {"title": "The release of autonomous vehicles", "author": ["W. Wachenfeld", "H. Winner"], "venue": "Autonomous Driving. Springer, 2016, pp. 425\u2013449.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2016}, {"title": "Validation of highly automated safe and secure systems", "author": ["M. Paulweber"], "venue": "Automated Driving. Springer, 2017, pp. 437\u2013450.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2017}, {"title": "Driving to safety: How many miles of driving would it take to demonstrate autonomous vehicle reliability?", "author": ["N. Kalra", "S.M. Paddock"], "venue": "Transportation Research Part A: Policy and Practice,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2016}, {"title": "Continuous development of highly automated driving functions with vehicle-in-the-loop using the example of Euro NCAP scenarios", "author": ["R. Pfeffer", "T. Leichsenring"], "venue": "Simulation and Testing for Vehicle Technology. Springer, 2016, pp. 33\u201342.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2016}, {"title": "From simulation data to test cases for fully automated driving and ADAS", "author": ["C. Sippl"], "venue": "IFIP International Conference on Testing Software and Systems. Springer, 2016, pp. 191\u2013206.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2016}, {"title": "Testing autonomous and highly configurable systems: Challenges and feasible solutions", "author": ["F. Wotawa"], "venue": "Automated Driving. Springer, 2017, pp. 519\u2013532.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2017}, {"title": "Testing with coordinated automated vehicles", "author": ["H.-P. Sch\u00f6ner", "W. Hurich"], "venue": "Handbook of Driver Assistance Systems: Basic Information, Components and Systems for Active Safety and Comfort, pp. 261\u2013276, 2016.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2016}, {"title": "Handover issues in autonomous driving: A literature review", "author": ["P. Morgan"], "venue": "2016.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2016}, {"title": "Safe transitions of responsibility in highly automated driving", "author": ["R. Johansson"], "venue": "Proceedings of The Ninth International Conference on Dependability, DEPEND 2016. IARIA, 2016, pp. 21\u201327.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2016}, {"title": "Towards State-of-the-Art and Future Trends in Testing of Active Safety Systems", "author": ["A. Knauss"], "venue": "Proceedings of International Workshop on Software Engineering for Smart Cyber-Physical Systems (SEsCPS\u201916), 2016, pp. 36\u201342.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "Cases like Toyota\u2019s unintended acceleration [1] show that already trivial mistakes can cause severe fatalities.", "startOffset": 44, "endOffset": 47}, {"referenceID": 1, "context": "Furthermore, the recent introduction of conditionally automated driving has also resulted in several accidents [2]\u2013[4].", "startOffset": 111, "endOffset": 114}, {"referenceID": 3, "context": "Furthermore, the recent introduction of conditionally automated driving has also resulted in several accidents [2]\u2013[4].", "startOffset": 115, "endOffset": 118}, {"referenceID": 4, "context": "We have presented an excerpt of the identified challenges for the software engineering community in [5].", "startOffset": 100, "endOffset": 103}, {"referenceID": 5, "context": "Additionally, a soft target having its own propulsion system will act as sensor stimulus for the function under test [6].", "startOffset": 117, "endOffset": 120}, {"referenceID": 6, "context": "levels proposed by the Society of Automotive Engineers (SAE) [7].", "startOffset": 61, "endOffset": 64}, {"referenceID": 7, "context": "The success of automated road vehicles depends on several aspects; testing, verification, validation, and certification being some of them [8]\u2013[13].", "startOffset": 139, "endOffset": 142}, {"referenceID": 12, "context": "The success of automated road vehicles depends on several aspects; testing, verification, validation, and certification being some of them [8]\u2013[13].", "startOffset": 143, "endOffset": 147}, {"referenceID": 11, "context": "Furthermore, since field tests become unviable due to the large number of kilometers to be driven [12], [14], the majority of the testing must be performed using simulations or virtual test driving [15], whose results are validated on proving grounds or in field tests.", "startOffset": 98, "endOffset": 102}, {"referenceID": 13, "context": "Furthermore, since field tests become unviable due to the large number of kilometers to be driven [12], [14], the majority of the testing must be performed using simulations or virtual test driving [15], whose results are validated on proving grounds or in field tests.", "startOffset": 104, "endOffset": 108}, {"referenceID": 14, "context": "Furthermore, since field tests become unviable due to the large number of kilometers to be driven [12], [14], the majority of the testing must be performed using simulations or virtual test driving [15], whose results are validated on proving grounds or in field tests.", "startOffset": 198, "endOffset": 202}, {"referenceID": 15, "context": "Virtual testing can also contribute to identify a further relevant test scenarios [16], and the number of tests to perform can be reduced using combinatorial testing [17].", "startOffset": 82, "endOffset": 86}, {"referenceID": 16, "context": "Virtual testing can also contribute to identify a further relevant test scenarios [16], and the number of tests to perform can be reduced using combinatorial testing [17].", "startOffset": 166, "endOffset": 170}, {"referenceID": 17, "context": "Test tracks need to complement testing with orchestrating several automated actors involved in a scenario [18].", "startOffset": 106, "endOffset": 110}, {"referenceID": 18, "context": "In highly automated vehicles, the hand-over [19] between driver and vehicle and vice versa becomes crucial [8] in order to avoid issues such as mode confusion and unfair transitions [20].", "startOffset": 44, "endOffset": 48}, {"referenceID": 7, "context": "In highly automated vehicles, the hand-over [19] between driver and vehicle and vice versa becomes crucial [8] in order to avoid issues such as mode confusion and unfair transitions [20].", "startOffset": 107, "endOffset": 110}, {"referenceID": 19, "context": "In highly automated vehicles, the hand-over [19] between driver and vehicle and vice versa becomes crucial [8] in order to avoid issues such as mode confusion and unfair transitions [20].", "startOffset": 182, "endOffset": 186}, {"referenceID": 20, "context": "[22].", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "We identified ten papers that are considered to be the most relevant ones for testing of automated vehicles [8]- [17].", "startOffset": 108, "endOffset": 111}, {"referenceID": 16, "context": "We identified ten papers that are considered to be the most relevant ones for testing of automated vehicles [8]- [17].", "startOffset": 113, "endOffset": 117}, {"referenceID": 4, "context": "Overview of all identified challenges and their distribution [5] \u2013 percentage of participants that mentioned the topic in black and percentage of how many of the notes contained that topic in white.", "startOffset": 61, "endOffset": 64}, {"referenceID": 13, "context": "triggered when it should not, monitored over a recommended distance [14].", "startOffset": 68, "endOffset": 72}, {"referenceID": 7, "context": "Virtual testing and simulation [8]\u2013[13], [15]\u2013[17]", "startOffset": 31, "endOffset": 34}, {"referenceID": 12, "context": "Virtual testing and simulation [8]\u2013[13], [15]\u2013[17]", "startOffset": 35, "endOffset": 39}, {"referenceID": 14, "context": "Virtual testing and simulation [8]\u2013[13], [15]\u2013[17]", "startOffset": 41, "endOffset": 45}, {"referenceID": 16, "context": "Virtual testing and simulation [8]\u2013[13], [15]\u2013[17]", "startOffset": 46, "endOffset": 50}, {"referenceID": 7, "context": "Safety, reliability, and quality [8], [10]\u2013[14], [17]", "startOffset": 33, "endOffset": 36}, {"referenceID": 9, "context": "Safety, reliability, and quality [8], [10]\u2013[14], [17]", "startOffset": 38, "endOffset": 42}, {"referenceID": 13, "context": "Safety, reliability, and quality [8], [10]\u2013[14], [17]", "startOffset": 43, "endOffset": 47}, {"referenceID": 16, "context": "Safety, reliability, and quality [8], [10]\u2013[14], [17]", "startOffset": 49, "endOffset": 53}, {"referenceID": 7, "context": "Sensors and their models [8], [10]\u2013[13], [15]", "startOffset": 25, "endOffset": 28}, {"referenceID": 9, "context": "Sensors and their models [8], [10]\u2013[13], [15]", "startOffset": 30, "endOffset": 34}, {"referenceID": 12, "context": "Sensors and their models [8], [10]\u2013[13], [15]", "startOffset": 35, "endOffset": 39}, {"referenceID": 14, "context": "Sensors and their models [8], [10]\u2013[13], [15]", "startOffset": 41, "endOffset": 45}, {"referenceID": 9, "context": "Scenario complexity [10], [12], [15], [16]", "startOffset": 20, "endOffset": 24}, {"referenceID": 11, "context": "Scenario complexity [10], [12], [15], [16]", "startOffset": 26, "endOffset": 30}, {"referenceID": 14, "context": "Scenario complexity [10], [12], [15], [16]", "startOffset": 32, "endOffset": 36}, {"referenceID": 15, "context": "Scenario complexity [10], [12], [15], [16]", "startOffset": 38, "endOffset": 42}, {"referenceID": 7, "context": "Handover/change of responsibility [8]\u2013[11]", "startOffset": 34, "endOffset": 37}, {"referenceID": 10, "context": "Handover/change of responsibility [8]\u2013[11]", "startOffset": 38, "endOffset": 42}, {"referenceID": 8, "context": "Field and proving ground tests [9]\u2013[11]", "startOffset": 31, "endOffset": 34}, {"referenceID": 10, "context": "Field and proving ground tests [9]\u2013[11]", "startOffset": 35, "endOffset": 39}, {"referenceID": 11, "context": "Toolchain integration [12], [13], [15]", "startOffset": 22, "endOffset": 26}, {"referenceID": 12, "context": "Toolchain integration [12], [13], [15]", "startOffset": 28, "endOffset": 32}, {"referenceID": 14, "context": "Toolchain integration [12], [13], [15]", "startOffset": 34, "endOffset": 38}, {"referenceID": 8, "context": "Test automation [9], [10], [15], [17]", "startOffset": 16, "endOffset": 19}, {"referenceID": 9, "context": "Test automation [9], [10], [15], [17]", "startOffset": 21, "endOffset": 25}, {"referenceID": 14, "context": "Test automation [9], [10], [15], [17]", "startOffset": 27, "endOffset": 31}, {"referenceID": 16, "context": "Test automation [9], [10], [15], [17]", "startOffset": 33, "endOffset": 37}, {"referenceID": 7, "context": "Standards and certification [8], [10], [13]", "startOffset": 28, "endOffset": 31}, {"referenceID": 9, "context": "Standards and certification [8], [10], [13]", "startOffset": 33, "endOffset": 37}, {"referenceID": 12, "context": "Standards and certification [8], [10], [13]", "startOffset": 39, "endOffset": 43}, {"referenceID": 12, "context": ", V2I) [13]", "startOffset": 7, "endOffset": 11}, {"referenceID": 12, "context": "Data and data formats [13]", "startOffset": 22, "endOffset": 26}, {"referenceID": 14, "context": "Development processes [15]", "startOffset": 22, "endOffset": 26}, {"referenceID": 16, "context": "Test of AI/self-adaptation [17]", "startOffset": 27, "endOffset": 31}], "year": 2017, "abstractText": "The technology in the area of automated vehicles is gaining speed and promises many advantages. However, with the recent introduction of conditionally automated driving, we have also seen accidents. Test protocols for both, conditionally automated (e.g., on highways) and automated vehicles do not exist yet and leave researchers and practitioners with different challenges. For instance, current test procedures do not suffice for fully automated vehicles, which are supposed to be completely in charge for the driving task and have no driver as a back up. This paper presents current challenges of testing the functionality and safety of automated vehicles derived from conducting focus groups and interviews with 26 participants from five countries having a background related to testing automotive safety-related topics. We provide an overview of the state-of-practice of testing active safety features as well as challenges that needs to be addressed in the future to ensure safety for automated vehicles. The major challenges identified through the interviews and focus groups, enriched by literature on this topic are related to 1) virtual testing and simulation, 2) safety, reliability, and quality, 3) sensors and sensor models, 4) required scenario complexity and amount of test cases, and 5) handover of responsibility between the driver and the vehicle.", "creator": "LaTeX with hyperref package"}}}