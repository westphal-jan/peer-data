{"id": "1708.08484", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Aug-2017", "title": "Joint Syntacto-Discourse Parsing and the Syntacto-Discourse Treebank", "abstract": "Discourse fingerings an between been poorly as just nothing - be though opinion by constituency cannot burden bootstrapping. Most efforts late same problem themselves cauterizing quite yet after - immediately - before, integrated, had come purely - original: keep mean crown - standard code segmentations (Elementary Discourse Units ), have cannot external parsers because dialectal background. In time paper supposed propose place first ended - to - before aspects br2 that sponsored parses in be syntax both rooted levels, given well as similar 1985 syntacto - rooted treebank previous seamlessly through Penn Treebank with the RST Treebank. Built \u2014 find concern two - an mp parser, this discussions syntacto - theory parser any no preprocessing regret (describe become accentuation meaning feature extraction ), trade-off own senate - instance - the - art end - allow - end philosophic parsing superiority.", "histories": [["v1", "Mon, 28 Aug 2017 18:57:50 GMT  (60kb,D)", "http://arxiv.org/abs/1708.08484v1", "Accepted at EMNLP 2017"]], "COMMENTS": "Accepted at EMNLP 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["kai zhao", "liang huang 0001"], "accepted": true, "id": "1708.08484"}, "pdf": {"name": "1708.08484.pdf", "metadata": {"source": "CRF", "title": "Joint Syntacto-Discourse Parsing and the Syntacto-Discourse Treebank", "authors": ["Kai Zhao", "Liang Huang"], "emails": ["liang.huang.sh}@gmail.com"], "sections": [{"heading": "1 Introduction", "text": "Distinguishing the semantic relations between segments in a document can be greatly beneficial to many high-level NLP tasks, such as summarization (Louis et al., 2010; Yoshida et al., 2014), sentiment analysis (Voll and Taboada, 2007; Somasundaran et al., 2009; Bhatia et al., 2015), question answering (Ferrucci et al., 2010; Jansen et al., 2014), and textual quality evaluation (Tetreault et al., 2013; Li and Jurafsky, 2016).\nThere has been a variety of research on discourse parsing (Marcu, 2000a; Soricut and Marcu, 2003; Pardo and Nunes, 2008; Hernault et al.,\n\u2217 The source code and the joint treebank are available at https://github.com/kaayy/josydipa.\n\u2020 Current address: Google Inc., New York, NY, USA.\n2010; da Cunha et al., 2012; Joty et al., 2013; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a,b; Heilman and Sagae, 2015; Wang et al., 2017). But most of them suffer from the following limitations:\n1. pipelined rather than end-to-end: they assume pre-segmented discourse, and worse yet, use gold-standard segmentations, except Hernault et al. (2010);\n2. not self-contained: they rely on external syntactic parsers and pretrained word vectors;\n3. complicated: they design sophisticated features, including those from parse-trees.\nWe argue for the first time that discourse parsing should be viewed as an extension of, and be performed in conjunction with, constituency parsing. We propose the first joint syntacto-discourse treebank, by unifying constituency and discourse tree representations. Based on this, we propose the first end-to-end incremental parser that jointly parses at both constituency and discourse levels. Our algorithm builds up on the span-based parser (Cross and Huang, 2016); it employs the strong generalization power of bi-directional LSTMs, and parses efficiently and robustly with an extremely simple span-based feature set that does not use any tree structure information.\nWe make the following contributions:\n1. We develop a combined representation of constituency and discourse trees to facilitate parsing at both levels without explicit conversion mechanism. Using this representation, we build and release a joint treebank based on the Penn Treebank (Marcus et al., 1993) and RST Treebank (Marcu, 2000a,b) (Section 2).\n2. We propose a novel joint parser that parses at both constituency and discourse levels. Our\nar X\niv :1\n70 8.\n08 48\n4v 1\n[ cs\n.C L\n] 2\n8 A\nug 2\n01 7\nparser performs discourse parsing in an endto-end manner, which greatly reduces the efforts required in preprocessing the text for segmentation and feature extraction, and, to our best knowledge, is the first end-to-end discourse parser in literature (Section 3).\n3. Even though it simultaneously performs constituency parsing, our parser does not use any explicit syntactic feature, nor does it need any binarization of discourse trees, thanks to the powerful span-based framework of Cross and Huang (2016) (Section 3).\n4. Empirically, our end-to-end parser outperforms the existing pipelined discourse parsing efforts. When the gold EDUs are provided, our parser is also competitive to other existing approaches with sophisticated features (Section 4)."}, {"heading": "2 Combined Representation & Treebank", "text": "We first briefly review the discourse structures in Rhetorical Structure Theory (Mann and Thompson, 1988), and then discuss how to unify discourse and constituency trees, which gives rise to our syntacto-discourse treebank PTB-RST."}, {"heading": "2.1 Review: RST Discourse Structures", "text": "In an RST discourse tree, there are two types of branchings. Most of the internal tree nodes are\nbinary branching, with one nucleus child containing the core semantic meaning of the current node, and one satellite child semantically decorating the nucleus. Like dependency labels, there is a relation annotated between each satellite-nucleus pair, such as \u201cBackground\u201d or \u201cPurpose\u201d. Figure 1(a) shows an example RST tree. There are also nonbinary-branching internal nodes whose children are conjunctions, e.g., a \u201cList\u201d of semantically similar EDUs (which are all nucleus nodes); see Figure 2(a) for an example."}, {"heading": "2.2 Syntacto-Discourse Representation", "text": "It is widely recognized that lower-level lexical and syntactic information can greatly help determining both the boundaries of the EDUs (i.e., discourse segmentation) (Bach et al., 2012) as well as the semantic relations between EDUs (Soricut and Marcu, 2003; Hernault et al., 2010; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a; Heilman and Sagae, 2015). While these previous approaches rely on pre-trained tools to provide both EDU segmentation and intra-EDU syntactic parse trees, we instead propose to directly determine the low-level segmentations, the syntactic parses, and the highlevel discourse parses using a single joint parser. This parser is trained on the combined trees of constituency and discourse structures.\nWe first convert an RST tree to a format similar\n\u25e6 \u2022\nand ASA Ltd. jumped 358 to 49 5 8 .\n\u2022\nBattle Mountain Gold climbed 34 to 16 3 4 ;\n\u2022\nHecla Mining rose 58 to 14;\n\u2022\nThe metals sector outgained other industry groups.\nElaboration\nList\nto those constituency trees in the Penn Treebank (Marcus et al., 1993). For each binary branching node with a nucleus child and a satellite child, we use the relation as the label of the converted parent node. The nucleus/satellite relation, along with the direction (either\u2190 or\u2192, pointing from satellite to nucleus) is then used as the label. For example, at the top level in Figure 2, we convert\n\u25e6\n. . .\n\u2022\n. . .\nElaboration\nto\n\u2190Elaboration\n. . .. . .\nFor a conjunctive branch (e.g. \u201cList\u201d), we simply use the relation as the label of the converted node.\nAfter converting an RST tree into the constituency tree format, we then replace each leaf node (i.e., EDU) with the corresponding syntactic (sub)tree from PTB. Given that the sentences in the RST Treebank (Marcu, 2000b) is a subset of that of PTB, we can always find the corresponding constituency subtrees for each EDU leaf node. In most cases, each EDU corresponds to one single (sub)tree in PTB, since the discourse boundaries generally do not conflict with constituencies. In other cases, one EDU node may correspond to multiple subtrees in PTB, and for these EDUs we use the lowest common ancestor of those subtrees in the PTB as the label of that EDU in the converted tree. E.g., if C\u2013D is one EDU in the PTB tree A\nDCB\nit might be converted to Purpose\u2192\nA\nDC\nB\nif the relation annonated in RST is B Purpose\u2212\u2192 C\u2013D.\nFigures 1\u20132 are two examples of discourse trees and their combined syntacto-discourse trees."}, {"heading": "2.3 Joint PTB-RST Treebank", "text": "Using the conversion strategy described above we build the first joint syntacto-discourse treebank\nbased on the Penn Treebank and RST Treebank. This PTB-RST treebank is released as a set of tools to generate the joint trees given Penn Treebank and RST Treebank data. During the alignment between the RST trees and the PTB trees, we only keep the common parts of the two trees.\nWe follow the standard training/testing split of the RST Treebank. In the training set, there are 347 joint trees with a total of 17,837 tokens, and the lengths of the discourses range from 30 to 2,199 tokens. In the test set, there are 38 joint trees with a total of 4,819 tokens, and the lengths vary from 45 to 2,607. Figure 3 shows the distribution of the discourse lengths over the whole dataset, which on average is about 2x of PTB sentence length, but longest ones are about 10x the longest lengths in the Treebank."}, {"heading": "3 Joint Syntacto-Discourse Parsing", "text": "Given the combined syntacto-discourse treebank, we now propose a joint parser that can perform end-to-end discourse segmentation and parsing."}, {"heading": "3.1 Extending Span-based Parsing", "text": "As mentioned above, the input sequences are substantially longer than PTB parsing, so we choose linear-time parsing, by adapting a popular greedy constituency parser, the span-based constituency parser of Cross and Huang (2016).\nAs in span-based parsing, at each step, we maintain a a stack of spans. Notice that in conventional incremental parsing, the stack stores the subtrees\n1\n1\n1\n1\n1\n1\ncomb \u3008... iSome text and the symbol or scaled\n1\nkSome text and the symbol or scaled\n1\nj\u3009 : (c, t) \u3008... iSome text and the symbol or scaled\n1\nk j\u3009 : (c+ sccomb(i, k, j), t)\nlabelX \u3008... iSome text and the symbol or scaled\n1\nk j\u3009 : (c, t) \u3008... iSome text and the symbol or scaled\n1\nj\u3009 : (c+ sc labelX (i, k, j), t \u222a {iXj})\nnolabel \u3008... iSome text and the symbol or scaled\n1\nk j\u3009 : (c, t) \u3008... iSome text and the symbol or scaled\n1\nj\u3009 : (c+ scnolabel(i, k, j), t)\nFigure 4: Deductive system for joint syntactic and discourse parsing. scsh(\u00b7, \u00b7), sccomb(\u00b7, \u00b7, \u00b7), sc labelX (\u00b7, \u00b7, \u00b7), and scnolabel(\u00b7, \u00b7, \u00b7) are scoring functions evaluated in the neural network.\nconstructed so far, but in span-based constituency parsing, the stack only stores the boundaries of subtrees, which are just a list of indices ...iSome text and the symbol or scaled\n1\nkSome text and the symbol or scaled\n1\nj . In other words, quite shockingly, no tree structure is represented anywhere in the parser. Please refer Cross and Huang (2016) for details.\nSimilar to span-based constituency parsing, we alternate between structural (either shift or combine) and label (labelX or nolabel) actions in an odd-even fashion. But different from Cross and Huang (2016), after a structural action, we choose to keep the last branching point k, i.e., iSom text nd the symbol or scaled\n1\nk j\n(mostly for combine, but also trivially for shift). This is because in our parsing mechanism, the discourse relation between two EDUs is actually determined after the previous combine action. We need to keep the splitting point to clearly find the spans of the two EDUs to determine their relations. This midpoint k disappears after a label action; therefore we can use the shape of the last span on the stack (whether it contains the split point, i.e., iSome text and the symbol or scaled\n1\nk j or iSome text and the symbol or scaled\n1\nj) to determine the parity of the step and thus no longer need to carry the step z in the state as in Cross and Huang (2016).\nThe nolabel action makes the binarization of the discourse/constituency tree unnecessary, because nolabel actually combines the top two spans on the stack \u03c3 into one span, but without annotating the new span a label. This greatly simplifies the preprocessing and post-processing efforts needed."}, {"heading": "3.2 Recurrent Neural Models and Training", "text": "The scoring functions in the deductive system (Figure 4) are calculated by an underlying neural model, which is similar to the bi-directional LSTM model in Cross and Huang (2016) that evaluates based on span boundary features. Again, it is important to note that no discourse or syntactic tree structures are represented in the features.\nDuring the decoding time, a document is firstl passed into a two-layer bi-directional LSTM model, then the outputs at each text position of the two layers of the bi-directional LSTMs are concatenated as the positional features. The spans at each parsing step can be represented as the feature vectors at the boundaries. The span features are then passed into fully connected networks with softmax to calculate the likelihood of performing the corresponding action or marking the corresponding label.\nWe use the \u201ctraining with exploration\u201d strategy (Goldberg and Nivre, 2013) and the dynamic oracle mechanism described in Cross and Huang (2016) to make sure the model can handle unseen parsing configurations properly."}, {"heading": "4 Empirical Results", "text": "We use the treebank described in Section 2 for empirical evaluation. We randomly choose 30 documents from the training set as the development set.\nWe tune the hyperparameters of the neural model on the development set. For most of the hyperparameters we settle with the same values suggested by Cross and Huang (2016). To alleviate the overfitting problem for training on the relative small RST Treebank, we use a dropout of 0.5.\nOne particular hyperparameter is that we use a value \u03b2 to balance the chances between training following the exploration (i.e., the best action chosen by the neural model) and following the correct path provided by the dynamic oracle. We find that \u03b2 = 0.8, i.e., following the dynamic oracle with a probability of 0.8, achieves the best performance. One explanation for this high chance to follow the oracle is that, since our combined trees are signif-\nicantly larger than the constituency trees in Penn Treebank, lower \u03b2 makes the parsing easily divert into wrong trails that are difficult to learn from.\nSince our parser essentially performs both constituency parsing task and discourse parsing task. We also evaluate the performances on sentence constituency level and discourse level separately. The result is shown in Table 1. Note that in constituency level, the accuracy is not directly comparable with the accuracy reported in Cross and Huang (2016), since: a) our parser is trained on a much smaller dataset (RST Treebank is about 1/6 of Penn Treebank); b) the parser is trained to optimize the discourse-level accuracy.\nTable 2 shows that, in the perspective of endto-end discourse parsing, our parser first outperforms the state-of-the-art segmentator of Bach et al. (2012), and furthermore, in end-to-end parsing, the superiority of our parser is more pronounced comparing to the previously best parser of Hernault et al. (2010).\nOn the other hand, the majority of the conventional discourse parsers are not end-to-end: they rely on gold EDU segmentations and pre-trained tools like Stanford parsers to generate features. We perform an experiment to compare the per-\nformance of our parser with them given the gold EDU segments (Table 3). Note that most of these parsers do not handle multi-branching discourse nodes and are trained and evaluated on binarized discourse trees (Feng and Hirst, 2014; Li et al., 2014a,b; Ji and Eisenstein, 2014; Heilman and Sagae, 2015), so their performances are actually not directly comparable to the results we reported."}, {"heading": "5 Conclusion", "text": "We have presented a neural-based incremental parser that can jointly parse at both constituency and discourse levels. To our best knowledge, this is the first end-to-end parser for discourse parsing task. Our parser achieves the state-of-the-art performance in end-to-end parsing, and unlike previous approaches, needs little pre-processing effort."}, {"heading": "Acknowledgments", "text": "We thank the anonymous reviewers for helpful comments. We are also grateful to Mingbo Ma, James Cross, and Dezhong Deng for suggestions. This work is supported in part by NSF IIS-1656051, DARPA N66001-17-2-4030 (XAI), a Google Faculty Research Award, and HP."}], "references": [{"title": "A reranking model for discourse segmentation using subtree features", "author": ["Ngo Xuan Bach", "Nguyen Le Minh", "Akira Shimazu."], "venue": "Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 160\u2013168. Asso-", "citeRegEx": "Bach et al\\.,? 2012", "shortCiteRegEx": "Bach et al\\.", "year": 2012}, {"title": "Better document-level sentiment analysis from rst discourse parsing", "author": ["Parminder Bhatia", "Yangfeng Ji", "Jacob Eisenstein."], "venue": "arXiv preprint arXiv:1509.01599.", "citeRegEx": "Bhatia et al\\.,? 2015", "shortCiteRegEx": "Bhatia et al\\.", "year": 2015}, {"title": "Incremental parsing with minimal features using bi-directional lstm", "author": ["James Cross", "Liang Huang."], "venue": "arXiv preprint arXiv:1606.06406.", "citeRegEx": "Cross and Huang.,? 2016", "shortCiteRegEx": "Cross and Huang.", "year": 2016}, {"title": "A symbolic approach for automatic detection of nuclearity and rhetorical relations among intra-sentence discourse segments in spanish", "author": ["Iria da Cunha", "Eric SanJuan", "Juan-Manuel TorresMoreno", "M Teresa Cabr\u00e9", "Gerardo Sierra."], "venue": "In-", "citeRegEx": "Cunha et al\\.,? 2012", "shortCiteRegEx": "Cunha et al\\.", "year": 2012}, {"title": "A lineartime bottom-up discourse parser with constraints and post-editing", "author": ["Vanessa Wei Feng", "Graeme Hirst."], "venue": "ACL (1), pages 511\u2013521.", "citeRegEx": "Feng and Hirst.,? 2014", "shortCiteRegEx": "Feng and Hirst.", "year": 2014}, {"title": "Building watson: An overview of the deepqa project", "author": ["David Ferrucci", "Eric Brown", "Jennifer Chu-Carroll", "James Fan", "David Gondek", "Aditya A Kalyanpur", "Adam Lally", "J William Murdock", "Eric Nyberg", "John Prager"], "venue": "AI magazine,", "citeRegEx": "Ferrucci et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ferrucci et al\\.", "year": 2010}, {"title": "Training deterministic parsers with non-deterministic oracles", "author": ["Yoav Goldberg", "Joakim Nivre."], "venue": "Transactions of the association for Computational Linguistics, 1:403\u2013414.", "citeRegEx": "Goldberg and Nivre.,? 2013", "shortCiteRegEx": "Goldberg and Nivre.", "year": 2013}, {"title": "Fast rhetorical structure theory discourse parsing", "author": ["Michael Heilman", "Kenji Sagae."], "venue": "arXiv preprint arXiv:1505.02425.", "citeRegEx": "Heilman and Sagae.,? 2015", "shortCiteRegEx": "Heilman and Sagae.", "year": 2015}, {"title": "Hilda: a discourse parser using support vector machine classification", "author": ["Hugo Hernault", "Helmut Prendinger", "David A DuVerle", "Mitsuru Ishizuka", "Tim Paek."], "venue": "Dialogue and Discourse, 1(3):1\u201333.", "citeRegEx": "Hernault et al\\.,? 2010", "shortCiteRegEx": "Hernault et al\\.", "year": 2010}, {"title": "Discourse complements lexical semantics for nonfactoid answer reranking", "author": ["Peter Jansen", "Mihai Surdeanu", "Peter Clark."], "venue": "ACL (1), pages 977\u2013 986.", "citeRegEx": "Jansen et al\\.,? 2014", "shortCiteRegEx": "Jansen et al\\.", "year": 2014}, {"title": "Representation learning for text-level discourse parsing", "author": ["Yangfeng Ji", "Jacob Eisenstein."], "venue": "ACL (1), pages 13\u201324.", "citeRegEx": "Ji and Eisenstein.,? 2014", "shortCiteRegEx": "Ji and Eisenstein.", "year": 2014}, {"title": "Discriminative reranking of discourse parses using tree kernels", "author": ["Shafiq Joty", "Alessandro Moschitti."], "venue": "a) A, 4(5):6.", "citeRegEx": "Joty and Moschitti.,? 2014", "shortCiteRegEx": "Joty and Moschitti.", "year": 2014}, {"title": "Combining intra-and multisentential rhetorical parsing for document-level discourse analysis", "author": ["Shafiq R Joty", "Giuseppe Carenini", "Raymond T Ng", "Yashar Mehdad."], "venue": "ACL (1), pages 486\u2013496.", "citeRegEx": "Joty et al\\.,? 2013", "shortCiteRegEx": "Joty et al\\.", "year": 2013}, {"title": "Neural net models for open-domain discourse coherence", "author": ["Jiwei Li", "Dan Jurafsky."], "venue": "arXiv preprint arXiv:1606.01545.", "citeRegEx": "Li and Jurafsky.,? 2016", "shortCiteRegEx": "Li and Jurafsky.", "year": 2016}, {"title": "Recursive deep models for discourse parsing", "author": ["Jiwei Li", "Rumeng Li", "Eduard H Hovy."], "venue": "EMNLP, pages 2061\u20132069.", "citeRegEx": "Li et al\\.,? 2014a", "shortCiteRegEx": "Li et al\\.", "year": 2014}, {"title": "Text-level discourse dependency parsing", "author": ["Sujian Li", "Liang Wang", "Ziqiang Cao", "Wenjie Li."], "venue": "ACL (1), pages 25\u201335.", "citeRegEx": "Li et al\\.,? 2014b", "shortCiteRegEx": "Li et al\\.", "year": 2014}, {"title": "Discourse indicators for content selection in summarization", "author": ["Annie Louis", "Aravind Joshi", "Ani Nenkova."], "venue": "Proceedings of the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 147\u2013156. Association for Computa-", "citeRegEx": "Louis et al\\.,? 2010", "shortCiteRegEx": "Louis et al\\.", "year": 2010}, {"title": "Rhetorical structure theory: Toward a functional theory of text organization", "author": ["William C Mann", "Sandra A Thompson."], "venue": "Text-Interdisciplinary Journal for the Study of Discourse, 8(3):243\u2013281.", "citeRegEx": "Mann and Thompson.,? 1988", "shortCiteRegEx": "Mann and Thompson.", "year": 1988}, {"title": "The rhetorical parsing of unrestricted texts: A surface-based approach", "author": ["Daniel Marcu."], "venue": "Computational linguistics, 26(3):395\u2013448.", "citeRegEx": "Marcu.,? 2000a", "shortCiteRegEx": "Marcu.", "year": 2000}, {"title": "The theory and practice of discourse parsing and summarization", "author": ["Daniel Marcu."], "venue": "MIT press.", "citeRegEx": "Marcu.,? 2000b", "shortCiteRegEx": "Marcu.", "year": 2000}, {"title": "Building a large annotated corpus of english: The penn treebank", "author": ["Mitchell P Marcus", "Mary Ann Marcinkiewicz", "Beatrice Santorini."], "venue": "Computational linguistics, 19(2):313\u2013330.", "citeRegEx": "Marcus et al\\.,? 1993", "shortCiteRegEx": "Marcus et al\\.", "year": 1993}, {"title": "On the development and evaluation of a brazilian portuguese discourse parser", "author": ["Thiago Alexandre Salgueiro Pardo", "Maria das Gra\u00e7as Volpe Nunes."], "venue": "Revista de Inform\u00e1tica Te\u00f3rica e Aplicada, 15(2):43\u201364.", "citeRegEx": "Pardo and Nunes.,? 2008", "shortCiteRegEx": "Pardo and Nunes.", "year": 2008}, {"title": "Supervised and unsupervised methods in employing discourse relations for improving opinion polarity classification", "author": ["Swapna Somasundaran", "Galileo Namata", "Janyce Wiebe", "Lise Getoor."], "venue": "Proceedings of the 2009 Conference on Empirical", "citeRegEx": "Somasundaran et al\\.,? 2009", "shortCiteRegEx": "Somasundaran et al\\.", "year": 2009}, {"title": "Sentence level discourse parsing using syntactic and lexical information", "author": ["Radu Soricut", "Daniel Marcu."], "venue": "Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language", "citeRegEx": "Soricut and Marcu.,? 2003", "shortCiteRegEx": "Soricut and Marcu.", "year": 2003}, {"title": "Holistic discourse coherence annotation for noisy essay writing", "author": ["ETS Tetreault"], "venue": null, "citeRegEx": "Tetreault,? \\Q2013\\E", "shortCiteRegEx": "Tetreault", "year": 2013}, {"title": "Not all words are created equal: Extracting semantic orientation as a function of adjective relevance", "author": ["Kimberly Voll", "Maite Taboada."], "venue": "Australasian Joint Conference on Artificial Intelligence, pages 337\u2013346. Springer.", "citeRegEx": "Voll and Taboada.,? 2007", "shortCiteRegEx": "Voll and Taboada.", "year": 2007}, {"title": "A two-stage parsing method for text-level discourse analysis", "author": ["Yizhong Wang", "Sujian Li", "Houfeng Wang."], "venue": "Proceedings of ACL.", "citeRegEx": "Wang et al\\.,? 2017", "shortCiteRegEx": "Wang et al\\.", "year": 2017}, {"title": "Dependency-based discourse parser for single-document summarization", "author": ["Yasuhisa Yoshida", "Jun Suzuki", "Tsutomu Hirao", "Masaaki Nagata."], "venue": "EMNLP, pages 1834\u20131839. Citeseer.", "citeRegEx": "Yoshida et al\\.,? 2014", "shortCiteRegEx": "Yoshida et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 16, "context": "Distinguishing the semantic relations between segments in a document can be greatly beneficial to many high-level NLP tasks, such as summarization (Louis et al., 2010; Yoshida et al., 2014), sentiment analysis (Voll and Taboada, 2007; Somasundaran et al.", "startOffset": 147, "endOffset": 189}, {"referenceID": 27, "context": "Distinguishing the semantic relations between segments in a document can be greatly beneficial to many high-level NLP tasks, such as summarization (Louis et al., 2010; Yoshida et al., 2014), sentiment analysis (Voll and Taboada, 2007; Somasundaran et al.", "startOffset": 147, "endOffset": 189}, {"referenceID": 25, "context": ", 2014), sentiment analysis (Voll and Taboada, 2007; Somasundaran et al., 2009; Bhatia et al., 2015), question answering (Ferrucci et al.", "startOffset": 28, "endOffset": 100}, {"referenceID": 22, "context": ", 2014), sentiment analysis (Voll and Taboada, 2007; Somasundaran et al., 2009; Bhatia et al., 2015), question answering (Ferrucci et al.", "startOffset": 28, "endOffset": 100}, {"referenceID": 1, "context": ", 2014), sentiment analysis (Voll and Taboada, 2007; Somasundaran et al., 2009; Bhatia et al., 2015), question answering (Ferrucci et al.", "startOffset": 28, "endOffset": 100}, {"referenceID": 5, "context": ", 2015), question answering (Ferrucci et al., 2010; Jansen et al., 2014), and textual quality evaluation (Tetreault et al.", "startOffset": 28, "endOffset": 72}, {"referenceID": 9, "context": ", 2015), question answering (Ferrucci et al., 2010; Jansen et al., 2014), and textual quality evaluation (Tetreault et al.", "startOffset": 28, "endOffset": 72}, {"referenceID": 13, "context": ", 2014), and textual quality evaluation (Tetreault et al., 2013; Li and Jurafsky, 2016).", "startOffset": 40, "endOffset": 87}, {"referenceID": 18, "context": "There has been a variety of research on discourse parsing (Marcu, 2000a; Soricut and Marcu, 2003; Pardo and Nunes, 2008; Hernault et al., \u2217 The source code and the joint treebank are available at https://github.com/kaayy/josydipa. \u2020 Current address: Google Inc., New York, NY, USA. 2010; da Cunha et al., 2012; Joty et al., 2013; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a,b; Heilman and Sagae, 2015; Wang et al., 2017).", "startOffset": 58, "endOffset": 466}, {"referenceID": 23, "context": "There has been a variety of research on discourse parsing (Marcu, 2000a; Soricut and Marcu, 2003; Pardo and Nunes, 2008; Hernault et al., \u2217 The source code and the joint treebank are available at https://github.com/kaayy/josydipa. \u2020 Current address: Google Inc., New York, NY, USA. 2010; da Cunha et al., 2012; Joty et al., 2013; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a,b; Heilman and Sagae, 2015; Wang et al., 2017).", "startOffset": 58, "endOffset": 466}, {"referenceID": 21, "context": "There has been a variety of research on discourse parsing (Marcu, 2000a; Soricut and Marcu, 2003; Pardo and Nunes, 2008; Hernault et al., \u2217 The source code and the joint treebank are available at https://github.com/kaayy/josydipa. \u2020 Current address: Google Inc., New York, NY, USA. 2010; da Cunha et al., 2012; Joty et al., 2013; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a,b; Heilman and Sagae, 2015; Wang et al., 2017).", "startOffset": 58, "endOffset": 466}, {"referenceID": 12, "context": "There has been a variety of research on discourse parsing (Marcu, 2000a; Soricut and Marcu, 2003; Pardo and Nunes, 2008; Hernault et al., \u2217 The source code and the joint treebank are available at https://github.com/kaayy/josydipa. \u2020 Current address: Google Inc., New York, NY, USA. 2010; da Cunha et al., 2012; Joty et al., 2013; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a,b; Heilman and Sagae, 2015; Wang et al., 2017).", "startOffset": 58, "endOffset": 466}, {"referenceID": 11, "context": "There has been a variety of research on discourse parsing (Marcu, 2000a; Soricut and Marcu, 2003; Pardo and Nunes, 2008; Hernault et al., \u2217 The source code and the joint treebank are available at https://github.com/kaayy/josydipa. \u2020 Current address: Google Inc., New York, NY, USA. 2010; da Cunha et al., 2012; Joty et al., 2013; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a,b; Heilman and Sagae, 2015; Wang et al., 2017).", "startOffset": 58, "endOffset": 466}, {"referenceID": 4, "context": "There has been a variety of research on discourse parsing (Marcu, 2000a; Soricut and Marcu, 2003; Pardo and Nunes, 2008; Hernault et al., \u2217 The source code and the joint treebank are available at https://github.com/kaayy/josydipa. \u2020 Current address: Google Inc., New York, NY, USA. 2010; da Cunha et al., 2012; Joty et al., 2013; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a,b; Heilman and Sagae, 2015; Wang et al., 2017).", "startOffset": 58, "endOffset": 466}, {"referenceID": 10, "context": "There has been a variety of research on discourse parsing (Marcu, 2000a; Soricut and Marcu, 2003; Pardo and Nunes, 2008; Hernault et al., \u2217 The source code and the joint treebank are available at https://github.com/kaayy/josydipa. \u2020 Current address: Google Inc., New York, NY, USA. 2010; da Cunha et al., 2012; Joty et al., 2013; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a,b; Heilman and Sagae, 2015; Wang et al., 2017).", "startOffset": 58, "endOffset": 466}, {"referenceID": 7, "context": "There has been a variety of research on discourse parsing (Marcu, 2000a; Soricut and Marcu, 2003; Pardo and Nunes, 2008; Hernault et al., \u2217 The source code and the joint treebank are available at https://github.com/kaayy/josydipa. \u2020 Current address: Google Inc., New York, NY, USA. 2010; da Cunha et al., 2012; Joty et al., 2013; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a,b; Heilman and Sagae, 2015; Wang et al., 2017).", "startOffset": 58, "endOffset": 466}, {"referenceID": 26, "context": "There has been a variety of research on discourse parsing (Marcu, 2000a; Soricut and Marcu, 2003; Pardo and Nunes, 2008; Hernault et al., \u2217 The source code and the joint treebank are available at https://github.com/kaayy/josydipa. \u2020 Current address: Google Inc., New York, NY, USA. 2010; da Cunha et al., 2012; Joty et al., 2013; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a,b; Heilman and Sagae, 2015; Wang et al., 2017).", "startOffset": 58, "endOffset": 466}, {"referenceID": 1, "context": ", 2009; Bhatia et al., 2015), question answering (Ferrucci et al., 2010; Jansen et al., 2014), and textual quality evaluation (Tetreault et al., 2013; Li and Jurafsky, 2016). There has been a variety of research on discourse parsing (Marcu, 2000a; Soricut and Marcu, 2003; Pardo and Nunes, 2008; Hernault et al., \u2217 The source code and the joint treebank are available at https://github.com/kaayy/josydipa. \u2020 Current address: Google Inc., New York, NY, USA. 2010; da Cunha et al., 2012; Joty et al., 2013; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a,b; Heilman and Sagae, 2015; Wang et al., 2017). But most of them suffer from the following limitations: 1. pipelined rather than end-to-end: they assume pre-segmented discourse, and worse yet, use gold-standard segmentations, except Hernault et al. (2010);", "startOffset": 8, "endOffset": 851}, {"referenceID": 2, "context": "Our algorithm builds up on the span-based parser (Cross and Huang, 2016); it employs the strong generalization power of bi-directional LSTMs, and parses efficiently and robustly with an extremely simple span-based feature set that does not use any tree structure information.", "startOffset": 49, "endOffset": 72}, {"referenceID": 20, "context": "Using this representation, we build and release a joint treebank based on the Penn Treebank (Marcus et al., 1993) and RST Treebank (Marcu, 2000a,b) (Section 2).", "startOffset": 92, "endOffset": 113}, {"referenceID": 19, "context": "(a) A discourse tree with 3 EDUs (\u2022: nucleas; \u25e6: satellite) in the RST treebank (Marcu, 2000b)", "startOffset": 80, "endOffset": 94}, {"referenceID": 2, "context": "Even though it simultaneously performs constituency parsing, our parser does not use any explicit syntactic feature, nor does it need any binarization of discourse trees, thanks to the powerful span-based framework of Cross and Huang (2016) (Section 3).", "startOffset": 218, "endOffset": 241}, {"referenceID": 17, "context": "We first briefly review the discourse structures in Rhetorical Structure Theory (Mann and Thompson, 1988), and then discuss how to unify discourse and constituency trees, which gives rise to our syntacto-discourse treebank PTB-RST.", "startOffset": 80, "endOffset": 105}, {"referenceID": 0, "context": ", discourse segmentation) (Bach et al., 2012) as well as the semantic relations between EDUs (Soricut and Marcu, 2003; Hernault et al.", "startOffset": 26, "endOffset": 45}, {"referenceID": 23, "context": ", 2012) as well as the semantic relations between EDUs (Soricut and Marcu, 2003; Hernault et al., 2010; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a; Heilman and Sagae, 2015).", "startOffset": 55, "endOffset": 219}, {"referenceID": 8, "context": ", 2012) as well as the semantic relations between EDUs (Soricut and Marcu, 2003; Hernault et al., 2010; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a; Heilman and Sagae, 2015).", "startOffset": 55, "endOffset": 219}, {"referenceID": 11, "context": ", 2012) as well as the semantic relations between EDUs (Soricut and Marcu, 2003; Hernault et al., 2010; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a; Heilman and Sagae, 2015).", "startOffset": 55, "endOffset": 219}, {"referenceID": 4, "context": ", 2012) as well as the semantic relations between EDUs (Soricut and Marcu, 2003; Hernault et al., 2010; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a; Heilman and Sagae, 2015).", "startOffset": 55, "endOffset": 219}, {"referenceID": 10, "context": ", 2012) as well as the semantic relations between EDUs (Soricut and Marcu, 2003; Hernault et al., 2010; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a; Heilman and Sagae, 2015).", "startOffset": 55, "endOffset": 219}, {"referenceID": 14, "context": ", 2012) as well as the semantic relations between EDUs (Soricut and Marcu, 2003; Hernault et al., 2010; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a; Heilman and Sagae, 2015).", "startOffset": 55, "endOffset": 219}, {"referenceID": 7, "context": ", 2012) as well as the semantic relations between EDUs (Soricut and Marcu, 2003; Hernault et al., 2010; Joty and Moschitti, 2014; Feng and Hirst, 2014; Ji and Eisenstein, 2014; Li et al., 2014a; Heilman and Sagae, 2015).", "startOffset": 55, "endOffset": 219}, {"referenceID": 20, "context": "to those constituency trees in the Penn Treebank (Marcus et al., 1993).", "startOffset": 49, "endOffset": 70}, {"referenceID": 19, "context": "Given that the sentences in the RST Treebank (Marcu, 2000b) is a subset of that of PTB, we can always find the corresponding constituency subtrees for each EDU leaf node.", "startOffset": 45, "endOffset": 59}, {"referenceID": 2, "context": "1 Extending Span-based Parsing As mentioned above, the input sequences are substantially longer than PTB parsing, so we choose linear-time parsing, by adapting a popular greedy constituency parser, the span-based constituency parser of Cross and Huang (2016). As in span-based parsing, at each step, we maintain a a stack of spans.", "startOffset": 236, "endOffset": 259}, {"referenceID": 2, "context": "Please refer Cross and Huang (2016) for details.", "startOffset": 13, "endOffset": 36}, {"referenceID": 2, "context": "But different from Cross and Huang (2016), after a structural action, we choose to keep the last branching point k, i.", "startOffset": 19, "endOffset": 42}, {"referenceID": 2, "context": "1 j) to determine the parity of the step and thus no longer need to carry the step z in the state as in Cross and Huang (2016).", "startOffset": 104, "endOffset": 127}, {"referenceID": 6, "context": "We use the \u201ctraining with exploration\u201d strategy (Goldberg and Nivre, 2013) and the dynamic oracle mechanism described in Cross and Huang (2016) to make sure the model can handle unseen parsing configurations properly.", "startOffset": 48, "endOffset": 74}, {"referenceID": 2, "context": "2 Recurrent Neural Models and Training The scoring functions in the deductive system (Figure 4) are calculated by an underlying neural model, which is similar to the bi-directional LSTM model in Cross and Huang (2016) that evaluates based on span boundary features.", "startOffset": 195, "endOffset": 218}, {"referenceID": 2, "context": "2 Recurrent Neural Models and Training The scoring functions in the deductive system (Figure 4) are calculated by an underlying neural model, which is similar to the bi-directional LSTM model in Cross and Huang (2016) that evaluates based on span boundary features. Again, it is important to note that no discourse or syntactic tree structures are represented in the features. During the decoding time, a document is firstl passed into a two-layer bi-directional LSTM model, then the outputs at each text position of the two layers of the bi-directional LSTMs are concatenated as the positional features. The spans at each parsing step can be represented as the feature vectors at the boundaries. The span features are then passed into fully connected networks with softmax to calculate the likelihood of performing the corresponding action or marking the corresponding label. We use the \u201ctraining with exploration\u201d strategy (Goldberg and Nivre, 2013) and the dynamic oracle mechanism described in Cross and Huang (2016) to make sure the model can handle unseen parsing configurations properly.", "startOffset": 195, "endOffset": 1021}, {"referenceID": 2, "context": "For most of the hyperparameters we settle with the same values suggested by Cross and Huang (2016). To alleviate the overfitting problem for training on the relative small RST Treebank, we use a dropout of 0.", "startOffset": 76, "endOffset": 99}, {"referenceID": 0, "context": "segmentation structure +nuclearity +relation Bach et al. (2012) segmentation only Stanford 95.", "startOffset": 45, "endOffset": 64}, {"referenceID": 0, "context": "segmentation structure +nuclearity +relation Bach et al. (2012) segmentation only Stanford 95.1 Hernault et al. (2010) end-to-end pipeline Penn Treebank 94.", "startOffset": 45, "endOffset": 119}, {"referenceID": 10, "context": "syntactic feats structure +nuclearity +relation human annotation (Ji and Eisenstein, 2014) 88.", "startOffset": 65, "endOffset": 90}, {"referenceID": 6, "context": "sparse Hernault et al. (2010) Penn Treebank 83.", "startOffset": 7, "endOffset": 30}, {"referenceID": 6, "context": "sparse Hernault et al. (2010) Penn Treebank 83.0 68.4 54.8 Joty et al. (2013) Charniak (retrained) 82.", "startOffset": 7, "endOffset": 78}, {"referenceID": 6, "context": "sparse Hernault et al. (2010) Penn Treebank 83.0 68.4 54.8 Joty et al. (2013) Charniak (retrained) 82.7 68.4 55.7 Joty and Moschitti (2014) Charniak (retrained) 57.", "startOffset": 7, "endOffset": 140}, {"referenceID": 4, "context": "3 Feng and Hirst (2014) Stanford 85.", "startOffset": 2, "endOffset": 24}, {"referenceID": 4, "context": "3 Feng and Hirst (2014) Stanford 85.7 71.0 58.2 Heilman and Sagae (2015) ZPar (retraied) 83.", "startOffset": 2, "endOffset": 73}, {"referenceID": 4, "context": "3 Feng and Hirst (2014) Stanford 85.7 71.0 58.2 Heilman and Sagae (2015) ZPar (retraied) 83.5 68.1 55.1 Wang et al. (2017) Stanford 86.", "startOffset": 2, "endOffset": 123}, {"referenceID": 13, "context": "neural Li et al. (2014a) Stanford 82.", "startOffset": 7, "endOffset": 25}, {"referenceID": 10, "context": "6 Ji and Eisenstein (2014) MALT 80.", "startOffset": 2, "endOffset": 27}, {"referenceID": 4, "context": "Note that most of these parsers do not handle multi-branching discourse nodes and are trained and evaluated on binarized discourse trees (Feng and Hirst, 2014; Li et al., 2014a,b; Ji and Eisenstein, 2014; Heilman and Sagae, 2015), so their performances are actually not directly comparable to the results we reported.", "startOffset": 137, "endOffset": 229}, {"referenceID": 10, "context": "Note that most of these parsers do not handle multi-branching discourse nodes and are trained and evaluated on binarized discourse trees (Feng and Hirst, 2014; Li et al., 2014a,b; Ji and Eisenstein, 2014; Heilman and Sagae, 2015), so their performances are actually not directly comparable to the results we reported.", "startOffset": 137, "endOffset": 229}, {"referenceID": 7, "context": "Note that most of these parsers do not handle multi-branching discourse nodes and are trained and evaluated on binarized discourse trees (Feng and Hirst, 2014; Li et al., 2014a,b; Ji and Eisenstein, 2014; Heilman and Sagae, 2015), so their performances are actually not directly comparable to the results we reported.", "startOffset": 137, "endOffset": 229}, {"referenceID": 1, "context": "Note that in constituency level, the accuracy is not directly comparable with the accuracy reported in Cross and Huang (2016), since: a) our parser is trained on a much smaller dataset (RST Treebank is about 1/6 of Penn Treebank); b) the parser is trained to optimize the discourse-level accuracy.", "startOffset": 103, "endOffset": 126}, {"referenceID": 0, "context": "Table 2 shows that, in the perspective of endto-end discourse parsing, our parser first outperforms the state-of-the-art segmentator of Bach et al. (2012), and furthermore, in end-to-end parsing, the superiority of our parser is more pronounced comparing to the previously best parser of Hernault et al.", "startOffset": 136, "endOffset": 155}, {"referenceID": 0, "context": "Table 2 shows that, in the perspective of endto-end discourse parsing, our parser first outperforms the state-of-the-art segmentator of Bach et al. (2012), and furthermore, in end-to-end parsing, the superiority of our parser is more pronounced comparing to the previously best parser of Hernault et al. (2010). On the other hand, the majority of the conventional discourse parsers are not end-to-end: they rely on gold EDU segmentations and pre-trained tools like Stanford parsers to generate features.", "startOffset": 136, "endOffset": 311}], "year": 2017, "abstractText": "Discourse parsing has long been treated as a stand-alone problem independent from constituency or dependency parsing. Most attempts at this problem are pipelined rather than end-to-end, sophisticated, and not self-contained: they assume goldstandard text segmentations (Elementary Discourse Units), and use external parsers for syntactic features. In this paper we propose the first end-to-end discourse parser that jointly parses in both syntax and discourse levels, as well as the first syntacto-discourse treebank by integrating the Penn Treebank with the RST Treebank. Built upon our recent span-based constituency parser, this joint syntactodiscourse parser requires no preprocessing whatsoever (such as segmentation or feature extraction), achieves the state-of-theart end-to-end discourse parsing accuracy.", "creator": "LaTeX with hyperref package"}}}