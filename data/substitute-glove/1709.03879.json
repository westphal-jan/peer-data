{"id": "1709.03879", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Sep-2017", "title": "Ultimate Intelligence Part III: Measures of Intelligence, Perception and Intelligent Agents", "abstract": "We propose that operator valve serves created known efficiency model of perception. We thinking very already reduce universal rob models then airtel coil. We propose a universal reduction of operator induction fitness, included appears does little can some used for set reinforcement practical modeled several making homeostasis (self - preserving) manager operating down its. power establishes. We movie indeed full actions thus the equilibrium suspect whatever be explained by the convenience stochastic model.", "histories": [["v1", "Fri, 8 Sep 2017 17:45:30 GMT  (14kb)", "http://arxiv.org/abs/1709.03879v1", "Third installation of the Ultimate Intelligence series. Submitted to AGI-2017. arXiv admin note: text overlap witharXiv:1504.03303"]], "COMMENTS": "Third installation of the Ultimate Intelligence series. Submitted to AGI-2017. arXiv admin note: text overlap witharXiv:1504.03303", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["eray \\\"ozkural"], "accepted": false, "id": "1709.03879"}, "pdf": {"name": "1709.03879.pdf", "metadata": {"source": "CRF", "title": "Ultimate Intelligence Part III: Measures of Intelligence, Perception and Intelligent Agents", "authors": ["Eray \u00d6zkural"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n70 9.\n03 87\n9v 1\n[ cs\n.A I]\n8 S\nep 2\n01 7\n\u201cWir mu\u0308ssen wissen \u2013 wir werden wissen!\u201d\n\u2014 David Hilbert"}, {"heading": "1 Introduction", "text": "The ultimate intelligence research program is inspired by Seth Lloyd\u2019s work on the ultimate physical limits to computation [15]. We investigate the ultimate physical limits and conditions of intelligence. This is the third installation of the paper series, the first two parts proposed new physical complexity measures, priors and limits of inductive inference [18,17].\nWe frame the question of ultimate limits of intelligence in a general physical setting, for this we provide a general definition of an intelligent system and a physical performance criterion, which as anticipated turns out to be a relation of physical quantities and information, the latter of which we had conceptually reduced to physics with minimum machine volume complexity in [18]."}, {"heading": "2 Notation and Background", "text": ""}, {"heading": "2.1 Universal Induction", "text": "Let us recall Solomonoff\u2019s universal distribution [21]. Let U be a universal computer which runs programs with a prefix-free encoding like LISP; y = U(x) denotes that the output of program x on U is y where x and y are bit strings. 1Any unspecified variable or function is assumed to be represented as a bit string.\n1 A prefix-free code is a set of codes in which no code is a prefix of another. A computer file uses a prefix-free code, ending with an EOF symbol, thus, most reasonable programming languages are prefix-free.\n|x| denotes the length of a bit-string x. f(\u00b7) refers to function f rather than its application.\nThe algorithmic probability that a bit string x \u2208 {0, 1}+ is generated by a random program \u03c0 \u2208 {0, 1}+ of U is:\nPU (x) = \u2211\nU(\u03c0)\u2208x(0|1)\u2217\u2227\u03c0\u2208{0,1}+\n2\u2212|\u03c0| (1)\nwhich conforms to Kolmogorov\u2019s axioms [13]. PU (x) considers any continuation of x, taking into account non-terminating programs.2 PU is also called the universal prior for it may be used as the prior in Bayesian inference, for any data can be encoded as a bit string. We also give the basic definitions of Algorithmic Information Theory (AIT) [14], where the algorithmic entropy, or complexity of a bit string x \u2208 {0, 1}+ is\nHU (x) = min({|\u03c0| | U(\u03c0) = x}) H \u2217 U (x) = \u2212 log2 PU (x) (2)\nWe use some variables in overloaded fashion in the paper, e.g., \u03c0 might be a program, a policy, or a physical mechanism depending on the context."}, {"heading": "2.2 Operator induction", "text": "Operator induction is a general form of supervised machine learning where we learn a stochastic map from n question and answer pairs D = {(qi, ai)} sampled from a (computable) stochastic source \u00b5. Operator induction can be solved by finding in available time a set of operators Oj(\u00b7|\u00b7), each a conditional probability density function (cpdf), such that the following goodness of fit is maximized\n\u03a8 = \u2211\nj\n\u03c8jn (3)\nfor a stochastic source \u00b5 where each term in the summation is the contribution of a model:\n\u03c8jn = 2 \u2212|(Oj(\u00b7|\u00b7)|\nn \u220f\ni=1\nOj(ai|qi). (4)\nqi and ai are question/answer pairs in the input dataset drawn from \u00b5, and O j is a computable cpdf in Equation 4. We can use the found m operators to predict unseen data with a mixture model [24]\nPU (an+1|qn+1) =\nm \u2211\nj=1\n\u03c8jnO j(an+1|qn+1) (5)\nThe goodness of fit in this case strikes a balance between high a priori probability and reproduction of data like in minimum message length (MML) method [27,26], yet uses a universal mixture like in sequence induction. The convergence theorem for operator induction was proven in [23] using Hutter\u2019s extension to arbitrary alphabet, and it bounds total error by HU (\u00b5) ln 2 similarly to sequence induction. 2 We used the regular expression notation in language theory."}, {"heading": "2.3 Set induction", "text": "Set induction generalizes unsupervised machine learning where we learn a probability density function (pdf) from a set of n bitstrings D = {d1, d2, ..., dn} sampled from a stochastic source \u00b5. We can then inductively infer new members to be added to the set with:\nP (dn+1) = PU (D \u222a dn+1)\nPU (D) (6)\nSet induction is clearly a restricted case of operator induction where we set Qi\u2019s to null string. Set induction is a universal form of clustering, and it perfectly models perception. If we apply set induction over a large set of 2D pictures of a room, it will give us a 3D representation of it necessarily. If we apply it to physical sensor data, it will infer the physical theory \u2013 perfectly general, with infinite domains \u2013 that explains the data, perception is merely a specific case of scientific theory inference in this case, though set induction works both with deterministic and non-deterministic problems."}, {"heading": "2.4 Universal measures of intelligence", "text": "There is much literature on the subject of defining a measure of intelligence. Hutter has defined an intelligence order relation in the context of his universal reinforcement learning (RL) model AIXI [8], which suggests that intelligence corresponds to the set of problems an agent can solve. Also notable is the universal intelligence measure [10,11], which is again based on the AIXI model. Their universal intelligence measure is based on the following philosophical definition compiled from their review of definitions of intelligence in the AI literature.\nDefinition 1 (Legg & Hutter). Intelligence measures an agent\u2019s ability to achieve goals in a wide range of environments.\nIt implies that intelligence requires an autonomous goal-following agent. The intelligence measure of [10] is defined as\n\u03a5 (\u03c0) = \u2211\n\u00b5\u2208E\n2\u2212HU (\u00b5)V \u03c0\u00b5 (7)\nwhere \u00b5 is a computable reward bounded environment, And V \u03c0\u00b5 is the expected sum of future rewards in the total interaction sequence of agent \u03c0. V \u03c0\u00b5 = E\u00b5,\u03c0 [ \u2211\u221e t=1 \u03b3\ntrt], where rt is the instantaneous reward at time t generated from the interaction between the agent \u03c0 and the environment \u00b5, and \u03b3t is the time discount factor."}, {"heading": "2.5 The free energy principle.", "text": "In Asimov\u2019s story titled \u201cThe Last Question\u201d, the task of life is identified as overcoming the second law of thermodynamics, however futile. Variational free energy essentially measures predictive error, and it was introduced by Feynmann to\naddress difficult path integral problems in quantum physics. In thermodynamic free energy, energies are negative log probabilities like entropy. The free energy principle states that any system must minimize its free energy to maintain its order. An adaptive system that tends to minimize average surprise (entropy) will tend to survive longer. A biological organism can be modelled as an adaptive system that has an implicit probabilistic model of the environment, and the variational free energy puts an upper bound on the surprise, thus minimizing free energy will improve the chances of survival. The divergence between the pdf of environment and an arbitrary pdf encoded by its own mechanism is minimized in Friston\u2019s model [9]. It has been shown in detail that the free energy principle adequately models a self-preserving agent in a stochastic dynamical system [6,9], which we can interpret as an environment with computable pdf. An active agent may be defined in the formalism of stochastic dynamical systems, by partitioning the physical states X of the environment into X = E \u00d7 S \u00d7A\u00d7 \u039b where e \u2208 E is an external state, s \u2208 S is a sensory state, a \u2208 A an active state, and \u03bb \u2208 \u039b is an internal state. Self-preservation is defined by the Markov blanket S \u00d7 A, the removal of which partitions X into external states E and internal states \u039b that influence each other only through sensory and action states. E influences sensations S, which in turn influence internal states \u039b, resulting in the choice of action signals S, which impact E, forming the feedback loop of the adaptive system. The system states x \u2208 X evolve according to the stochastic equation:\nx\u0307(t) = f(x) + \u03c9 (8)\nx(0) = x0 (9)\nf(x) =\n\n   \nfe(e, s, a)\nfs(e, s, a)\nfa(s, a, \u03bb)\nf\u03bb(s, a, \u03bb)\n\n   \n(10)\nwhere f(x) is the flow of system states and it is decomposed into flows over the sets in the system partition, explicitly showing the dependencies among state sets; \u03c9 models fluctuations. Friston formalizes the self-preservation (homeostasis) problem as finding an internal dynamics that minimizes the uncertainty (Shannon entropy) of the external states, and shows a solution based on the principle of least action [9] wherein minimizing free energy is synonymous with minimizing the entropy of the external states (principle of least action), which subsequently corresponds to active inference. We have space for only some key results from the rather involved mathematical theory. p(s, f |m) is the generative pdf that generates sensorium s and fictive (hidden) states f \u2208 F from probabilistic model m, and q(f |\u03bb) is the recognition pdf that predicts hidden states F in the world given internal state. Generative pdf factorizes as p(s, f |m) = p(s|f,m)p(f |m). Free energy is defined as energy minus entropy\nF (s, \u03bb) = Eq[\u2212 ln p(s, f |m)]\u2212H(q(f |\u03bb)) (11)\nwhich can be subjectively computed by the system. Free energy is also equal to surprise plus divergence between recognition and generative pdf\u2019s.\nF (s, \u03bb) = Eq[\u2212 ln p(s, f |m)] +DKL(q(f |\u03bb)||p(f |s,m)) (12)\nMinimizing divergence minimizes free energy, internal states \u03bb may be optimized to minimize predictive error using Equation 12, and surprise is invariant with respect to \u03bb. Free energy may be formulated as complexity plus accuracy of recognition, as well.\nF (s, \u03bb) = Eq[\u2212 ln p(s, a|f,m)] +DKL(q(f |\u03bb)||p(f,m)) (13)\nIn this case, we may choose an action that changes sensations to reduce predictive error. Only the first term is a function of action signals. Minimization of free energy turns out to be equivalent to the information bottleneck principle of Tishby [9,25]. The information bottleneck method is equivalent to the pioneering work of Ashby, which is simple enough to state here [3,2]:\nSB = I(\u03bb;F )\u2212 I(S;\u03bb) (14)\nwhere the first term is the mutual information between internal and hidden states, and the second term is the mutual information between sensory states and internal states. Both terms are expanded using conditional entropy, and then two terms in the middle are eliminated because they are not relevant to the optimization problem \u2013 we do not know the hidden variables in H(\u03bb|F ) and H(S) is constant.\nSB = H(\u03bb) \u2212H(\u03bb|F )\u2212H(S) +H(S|\u03bb) (15) S\u2217B = H(\u03bb) +H(S|\u03bb) (16)\nMinimizing S\u2217B Equation 16 thus minimizes the sum of the entropy of internal states and the entropy required to encode sensory states given internal states. In other words, it strikes an optimal balance between model complexity H(\u03bb), and model accuracy H(S|\u03bb). Friston further shows that Equation 16 directly derives from the free energy principle, closing potential loopholes in the theory. Please see [5] for a comprehensive application of the free energy principle to agents and learning. Note also that the bulk of the theory assumes the ergodic hypothesis."}, {"heading": "3 Perception as General Intelligence", "text": "Since we are chiefly interested in stochastic problems in the physical world, we propose a straightforward informal definition of intelligence:\nDefinition 2. Intelligence measures the capability of a mechanism to solve prediction problems.\nMechanism is any physical machine as usual, see [4] which suggests likewise. Therefore, a general formulation of Solomonoff induction, operator induction, might serve as a model of general intelligence, as well [24]. Recall that operator induction can infer any physically plausible cpdf, thus its approximation can solve any classical supervised machine learning problem. The only slight issue with Equation 7 might be that it seems to exclude classical AI systems that are not agents, e.g., expert systems, machine learning tools, knowledge representation systems, search and planning algorithms, and so forth, which are somewhat more naturally encompassed by our informal definition."}, {"heading": "3.1 Is operator induction adequate?", "text": "A question naturally arises as to whether operator induction can adequately solve every prediction problem we require in AI. There are two strong objections to operator induction that we know of. It is argued that in a dynamic environment, as in a physical environment, we must use an active agent model so that we can account for changes in the environment, as in the space-time embedded agent [16] which also provides an agent-based intelligence measure. This objection may be answered by the simple solution that each decision of an active intelligent system may be considered a separate induction problem. The second objection is that the basic Solomonoff induction can only predict the next bit, but not the expected cumulative reward, which its extensions can solve. We counter this objection by stating that we can reduce an agent model to a perception and action-planning problem as in OOPS-RL [20]. In OOPS-RL, the perception module searches for the best world-model given the history of sensory input and actions in allotted time using OOPS, and the planning module searches for the best control program using the world-model of the perception module to determine the action sequence that maximizes cumulative reward likewise. OOPS has a generalized Levin Search [12] which may be tweaked to solve either prediction or optimization problems. Hutter has also observed that standard sequence induction does not readily address optimization problems [8]. However, Solomonoff induction is still complete in the sense of Turing, and can infer any computable cpdf; and when the extension to Solomonoff induction is applied to sequence prediction, it does not yield a better error bound, which seems like a conundrum. On the other hand, Levin Search with a proper universal probability density function (pdf) of programs can be modified to solve induction problems (sequence, set, operator, and sequence prediction with arbitrary loss), inversion problems (computer science problems in P and NP), and optimization problems [23]. The planning module of OOPS-RL likewise requires us to write such an optimization program. In that sense, AIXI implies yet another variation of Levin Search for solving a particular universal optimization problem, however, it also has the unique advantage that formal transformations between AIXI problem and many important problems including function minimization and strategic games have been shown [8]. Nevertheless, the discussion in [23] is rather brief. Also see [1] for a discussion of universal optimization.\nProposition 1. A discrete-time universal RL model may be reduced to operator induction.\nMore formally, the perceptual task of an RL agent would be inferring from a history the cumulative rewards in the future, without loss of generality. Let the chronology C be a sequence of sensory, reward, and action data C = [(s1, r1, a1), (s2, r2, a2), . . . , (sn, rn, an)] where Ci accesses ith element, and Ci:j accesses the subsequence [Ci, Ci+1, . . . , Cj ]. Let rc be the cumulative reward function where rc(C, i, j) = \u2211k\u2264j\nk=i rk. After observing (sn, rn, an), we construct dataset Dc as follows. For every unique (i, j) pair such that 1 < i \u2264 j \u2264 n, we concatenate history tuples C1:(i\u22121), and we form a question string that also includes the next\naction, i and j, q = [(s1, r1, a1), (s2, r2, a2), . . . , (s(i\u22121), r(i\u22121), a(i\u22121))], ai, i, j, and an answer string which is the cumulative reward a = rc(C, i, j). Solving the operator induction problem for this dataset DC will yield a cpdf which predicts cumulative rewards in the future. After that, choosing the next action is a simple matter of maximizing r(C1:n, ai, n+ 1, \u03bb) where \u03bb is the planning horizon. The reduction causes quadratic blow-up in the number of data items. Our somewhat cumbersome reduction suggests that all of the intelligence here comes from operator induction, surely an argmax function, or a summation of rewards does not provide it, but rather it builds constraints into the task. In other words, we interpret that the intelligence in an agent model is provided by inductive inference, rather than an additional application of decision theory."}, {"heading": "4 Physical Quantification of Intelligence", "text": "Definition 1 corresponds to any kind of reinforcement-learning or goal-following agent in AI literature quite well, and can be adapted to solve other kinds of problems. The unsupervised, active inference agent approach is proposed instead of reinforcement learning approach in [7], and the authors argue that they did not need to invoke the notion of reward, value or utility. The authors in particular claim that they could solve the mountain-car problem by the free-energy formulation of perception. We thus propose a perceptual intelligence measure."}, {"heading": "4.1 Universal measure of perception fitness", "text": "Note that operator induction is considered to be insufficient to describe universal agents such as AIXI, because basic sequence induction is inappropriate for modelling optimization problems [8]. However, a modified Levin search procedure can solve such optimization problems as in finding an optimal control program [20]. In OOPS-RL, the perception module searches for the best world-model given the history of sensory input and actions in allotted time using OOPS, and the planning module searches for the best control program using the world-model of the perception module to determine the control program that maximizes cumulative reward likewise. In this paper, we consider the perception module of such a generic agent which must produce a world-model, given sensory input.\nWe can use the intelligence measure Equation 7 in a physical theory of intelligence, however it contains terms like utility that do not have physical units (i.e., we would be preferring a more reductive definition). We therefore attempt to obtain such a measure using the more benign goodness-of-fit (Equation 3). Let the universal measure of the fitness of operator induction be defined as\n\u03a5O(\u03c0) = \u2211\n\u00b5\u2208S\n2\u2212HU (\u00b5)\u03a8(\u00b5, \u03c0) (17)\nwhere S is the set of possible stochastic sources in the observable universe U and \u03c0 is a physical mechanism, and \u03a8 is relative to a stochastic source \u00b5 and a\nphysical mechanism (computer) \u03c0. This would be maximum if we assume that operator induction were solved exactly by an oracle machine.\nNote that HU (\u00b5) is finite; \u03a8(\u00b5, \u03c0) is likewise bounded by the amount of computation \u03c0 will spend on approximating operator induction."}, {"heading": "4.2 Application to homeostasis agent", "text": "In a presentation to Friston\u2019s group in January 2015, we noted that the minimization of S\u2217B is identical to Minimum Message Length principle, which can be further refined as\nS \u2032B = H \u2217(\u039b) +H\u2217(S|\u039b) (18)\nusing Solomonoff\u2019s entropy formulation that takes the negative logarithm of algorithmic probability [22]. In the unsupervised agent context, solving this minimization problem corresponds to inferring an optimal behavioral policy as \u039b constitutes internal dynamics which may be modeled as a non-terminating program. We could directly apply induction to minimize KL divergence, as well. Note the correspondence to operator induction.\nTheorem 1. Minimizing the free energy is equivalent to solving the operator induction problem for (\u03bb, s) pairs where qi \u2208 \u039b and ai \u2208 S.\nProof. Observe that minimizing Equation 16 corresponds to picking maximum \u03c8jn since in entropy form,\n\u2212 log2(\u03c8 j n) = \u2212 log2(2 \u2212|Oj(\u00b7|\u00b7)|)\u2212 log2(\nn \u220f\ni=1\nOj(si|\u03bbi))\n= |Oj(\u00b7|\u00b7)| \u2212\nn \u2211\ni=1\nlog2(O j(ai|qi)) = |O j(\u00b7|\u00b7)|+H(Oj(ai|qi)).\nWe define a non-redundant selection of \u03c8jn\u2019s, |O j(\u00b7|\u00b7)| = HU (O j(\u00b7|\u00b7)), e.g., we pick only the shortest programs that produce the same cpdf, otherwise the entropy form would diverge. Minimizing Equation 18 is exactly operator induction, even though the questions are programs, the ensemble here is of all programs and all sensory state, program pairs in space-time. \u2211\n|Oj(\u00b7|\u00b7)| = H\u2217(\u039b) and \u2211\nH(Oj(ai|qi)) = H \u2217(S|\u039b). Note that this merely establishes model equiva-\nlence, we have not yet explained how it is to be computed in detail.\nProposition 2. By the above theorem, Equation 17 measures the goodness of fit for a given homeostasis agent mechanism, for all possible environments.\nThe mechanism \u03c0 that maximizes \u03a8(\u00b5, \u03c0) achieves less error with respect to a source (which may be taken to correspond to the whole random dynamical system in the framework of free energy principle), while \u03a5O(\u03c0) normalizes \u03a8(\u00b5, \u03c0) with respect to a random dynamical system. It holds for the same reasons Legg\u2019s\nmeasure holds, which are not discussed due to space limits in the present paper. We prefer the unsupervised homeostasis agent among the two agent models we discussed because it provides an exceptionally elegant and reductionist model of autonomous behavior, that has been rigorously formulated physically. Note that this agent is conceptually related to the survival property of RL agents discussed in [19]."}, {"heading": "4.3 Discussion", "text": "The unsupervised model still achieves exploration and curiosity, because it would stochastically sample and navigate the environment to reduce predictive errors. While we either optimize perceptual models or choose an action that would befit expectations, it might be possible to express the optimal adaptive agent policy in a general optimization framework. A more in-depth analysis of the unsupervised agent will be presented in a subsequent publication. A more general reductive definition of intelligence should also be researched. These developments could eventually help unify AGI theory."}], "references": [{"title": "Can we measure the difficulty of an optimization problem", "author": ["T. Alpcan", "T. Everitt", "M. Hutter"], "venue": "IEEE Information Theory Workshop,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Principles of the self-organizing system", "author": ["W.R. Ashby"], "venue": "v. Foerster, H., Zopf, G.W. (eds.) Principles of Self-Organization: Transactions of the University of Illinois Symposium, pp. 255\u2013278. Pergamon, London", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1962}, {"title": "Principles of the self-organizing dynamic system", "author": ["W. Ashby"], "venue": "The Journal of General Psychology 37(2), 125\u2013128", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1947}, {"title": "Artificial General Intelligence: 4th International Conference, AGI", "author": ["D.L. Dowe", "J. Hern\u00e1ndez-Orallo", "P.K. Das"], "venue": "Proceedings, chap. Compression and Intelligence: Social Environments and Communication,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Active inference and learning", "author": ["K. Friston", "T. FitzGerald", "F. Rigoli", "P. Schwartenbeck", "J. ODoherty", "G. Pezzulo"], "venue": "Neuroscience and Biobehavioral Reviews", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2016}, {"title": "A free energy principle for the brain", "author": ["K. Friston", "J. Kilner", "L. Harrison"], "venue": "Journal of Physiology-Paris 100(13),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2006}, {"title": "Reinforcement learning or active inference", "author": ["K.J. Friston", "J. Daunizeau", "S.J. Kiebel"], "venue": "PLOS ONE 4(7),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "Universal algorithmic intelligence: A mathematical top\u2192down approach", "author": ["M. Hutter"], "venue": "Goertzel, B., Pennachin, C. (eds.) Artificial General Intelligence, pp. 227\u2013290. Cognitive Technologies, Springer, Berlin", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2007}, {"title": "A free energy principle for biological systems", "author": ["F. Karl"], "venue": "Entropy 14(11),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "Universal intelligence: A definition of machine intelligence", "author": ["S. Legg", "M. Hutter"], "venue": "Minds Mach. 17(4), 391\u2013444", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "An approximation of the universal intelligence measure", "author": ["S. Legg", "J. Veness"], "venue": "Algorithmic Probability and Friends. Bayesian Prediction and Artificial Intelligence, Lecture Notes in Computer Science, vol. 7070, pp. 236\u2013249. Springer Berlin Heidelberg", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Universal problems of full search", "author": ["L. Levin"], "venue": "Problems of Information Transmission 9(3), 256\u2013266", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1973}, {"title": "Some theorems on the algorithmic approach to probability theory and information theory", "author": ["L.A. Levin"], "venue": "CoRR abs/1009.5894", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "An Introduction to Kolmogorov Complexity and Its Applications", "author": ["M. Li", "P.M. Vitanyi"], "venue": "Springer Publishing Company, Incorporated, 3 edn.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2008}, {"title": "Ultimate physical limits to computation", "author": ["S. Lloyd"], "venue": "Nature406", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2000}, {"title": "Space-time embedded intelligence", "author": ["L. Orseau", "M. Ring"], "venue": "Artificial General Intelligence, Lecture Notes in Computer Science,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2012}, {"title": "Ultimate Intelligence Part II: Physical Measure and Complexity of Intelligence", "author": ["E. \u00d6zkural"], "venue": "ArXiv e-prints", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Ultimate intelligence part I: physical completeness and objectivity of induction", "author": ["E. \u00d6zkural"], "venue": "Artificial General Intelligence - 8th International Conference,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Delusion, survival, and intelligent agents", "author": ["M. Ring", "L. Orseau"], "venue": "Artificial General Intelligence, pp. 11\u201320. Springer Berlin Heidelberg", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2011}, {"title": "Optimal ordered problem solver", "author": ["J. Schmidhuber"], "venue": "Machine Learning 54, 211\u2013256", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2004}, {"title": "A formal theory of inductive inference, part i", "author": ["R.J. Solomonoff"], "venue": "Information and Control 7(1), 1\u201322", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1964}, {"title": "Complexity-based induction systems: Comparisons and convergence theorems", "author": ["R.J. Solomonoff"], "venue": "IEEE Trans. on Information Theory IT-24(4), 422\u2013432", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1978}, {"title": "Progress in incremental machine learning", "author": ["R.J. Solomonoff"], "venue": "Tech. Rep. IDSIA-1603, IDSIA, Lugano, Switzerland", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2003}, {"title": "Three kinds of probabilistic induction: Universal distributions and convergence theorems", "author": ["R.J. Solomonoff"], "venue": "The Computer Journal 51(5), 566\u2013570", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2008}, {"title": "The information bottleneck method", "author": ["N. Tishby", "F.C. Pereira", "W. Bialek"], "venue": "ArXiv Physics e-prints", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2000}, {"title": "Minimum message length and kolmogorov complexity", "author": ["C.S. Wallace", "D.L. Dowe"], "venue": "The Computer Journal 42(4),", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1999}, {"title": "A information measure for classification", "author": ["C.S. Wallace", "D.M. Boulton"], "venue": "Computer Journal 11(2), 185\u2013194", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1968}], "referenceMentions": [{"referenceID": 14, "context": "The ultimate intelligence research program is inspired by Seth Lloyd\u2019s work on the ultimate physical limits to computation [15].", "startOffset": 123, "endOffset": 127}, {"referenceID": 17, "context": "This is the third installation of the paper series, the first two parts proposed new physical complexity measures, priors and limits of inductive inference [18,17].", "startOffset": 156, "endOffset": 163}, {"referenceID": 16, "context": "This is the third installation of the paper series, the first two parts proposed new physical complexity measures, priors and limits of inductive inference [18,17].", "startOffset": 156, "endOffset": 163}, {"referenceID": 17, "context": "We frame the question of ultimate limits of intelligence in a general physical setting, for this we provide a general definition of an intelligent system and a physical performance criterion, which as anticipated turns out to be a relation of physical quantities and information, the latter of which we had conceptually reduced to physics with minimum machine volume complexity in [18].", "startOffset": 381, "endOffset": 385}, {"referenceID": 20, "context": "Let us recall Solomonoff\u2019s universal distribution [21].", "startOffset": 50, "endOffset": 54}, {"referenceID": 12, "context": "which conforms to Kolmogorov\u2019s axioms [13].", "startOffset": 38, "endOffset": 42}, {"referenceID": 13, "context": "We also give the basic definitions of Algorithmic Information Theory (AIT) [14], where the algorithmic entropy, or complexity of a bit string x \u2208 {0, 1} is HU (x) = min({|\u03c0| | U(\u03c0) = x}) H \u2217 U (x) = \u2212 log2 PU (x) (2) We use some variables in overloaded fashion in the paper, e.", "startOffset": 75, "endOffset": 79}, {"referenceID": 23, "context": "We can use the found m operators to predict unseen data with a mixture model [24]", "startOffset": 77, "endOffset": 81}, {"referenceID": 26, "context": "The goodness of fit in this case strikes a balance between high a priori probability and reproduction of data like in minimum message length (MML) method [27,26], yet uses a universal mixture like in sequence induction.", "startOffset": 154, "endOffset": 161}, {"referenceID": 25, "context": "The goodness of fit in this case strikes a balance between high a priori probability and reproduction of data like in minimum message length (MML) method [27,26], yet uses a universal mixture like in sequence induction.", "startOffset": 154, "endOffset": 161}, {"referenceID": 22, "context": "The convergence theorem for operator induction was proven in [23] using Hutter\u2019s extension to arbitrary alphabet, and it bounds total error by HU (\u03bc) ln 2 similarly to sequence induction.", "startOffset": 61, "endOffset": 65}, {"referenceID": 7, "context": "Hutter has defined an intelligence order relation in the context of his universal reinforcement learning (RL) model AIXI [8], which suggests that intelligence corresponds to the set of problems an agent can solve.", "startOffset": 121, "endOffset": 124}, {"referenceID": 9, "context": "Also notable is the universal intelligence measure [10,11], which is again based on the AIXI model.", "startOffset": 51, "endOffset": 58}, {"referenceID": 10, "context": "Also notable is the universal intelligence measure [10,11], which is again based on the AIXI model.", "startOffset": 51, "endOffset": 58}, {"referenceID": 9, "context": "The intelligence measure of [10] is defined as", "startOffset": 28, "endOffset": 32}, {"referenceID": 8, "context": "The divergence between the pdf of environment and an arbitrary pdf encoded by its own mechanism is minimized in Friston\u2019s model [9].", "startOffset": 128, "endOffset": 131}, {"referenceID": 5, "context": "It has been shown in detail that the free energy principle adequately models a self-preserving agent in a stochastic dynamical system [6,9], which we can interpret as an environment with computable pdf.", "startOffset": 134, "endOffset": 139}, {"referenceID": 8, "context": "It has been shown in detail that the free energy principle adequately models a self-preserving agent in a stochastic dynamical system [6,9], which we can interpret as an environment with computable pdf.", "startOffset": 134, "endOffset": 139}, {"referenceID": 8, "context": "Friston formalizes the self-preservation (homeostasis) problem as finding an internal dynamics that minimizes the uncertainty (Shannon entropy) of the external states, and shows a solution based on the principle of least action [9] wherein minimizing free energy is synonymous with minimizing the entropy of the external states (principle of least action), which subsequently corresponds to active inference.", "startOffset": 228, "endOffset": 231}, {"referenceID": 8, "context": "Minimization of free energy turns out to be equivalent to the information bottleneck principle of Tishby [9,25].", "startOffset": 105, "endOffset": 111}, {"referenceID": 24, "context": "Minimization of free energy turns out to be equivalent to the information bottleneck principle of Tishby [9,25].", "startOffset": 105, "endOffset": 111}, {"referenceID": 2, "context": "The information bottleneck method is equivalent to the pioneering work of Ashby, which is simple enough to state here [3,2]: SB = I(\u03bb;F )\u2212 I(S;\u03bb) (14)", "startOffset": 118, "endOffset": 123}, {"referenceID": 1, "context": "The information bottleneck method is equivalent to the pioneering work of Ashby, which is simple enough to state here [3,2]: SB = I(\u03bb;F )\u2212 I(S;\u03bb) (14)", "startOffset": 118, "endOffset": 123}, {"referenceID": 4, "context": "Please see [5] for a comprehensive application of the free energy principle to agents and learning.", "startOffset": 11, "endOffset": 14}, {"referenceID": 3, "context": "Mechanism is any physical machine as usual, see [4] which suggests likewise.", "startOffset": 48, "endOffset": 51}, {"referenceID": 23, "context": "Therefore, a general formulation of Solomonoff induction, operator induction, might serve as a model of general intelligence, as well [24].", "startOffset": 134, "endOffset": 138}, {"referenceID": 15, "context": "It is argued that in a dynamic environment, as in a physical environment, we must use an active agent model so that we can account for changes in the environment, as in the space-time embedded agent [16] which also provides an agent-based intelligence measure.", "startOffset": 199, "endOffset": 203}, {"referenceID": 19, "context": "We counter this objection by stating that we can reduce an agent model to a perception and action-planning problem as in OOPS-RL [20].", "startOffset": 129, "endOffset": 133}, {"referenceID": 11, "context": "OOPS has a generalized Levin Search [12] which may be tweaked to solve either prediction or optimization problems.", "startOffset": 36, "endOffset": 40}, {"referenceID": 7, "context": "Hutter has also observed that standard sequence induction does not readily address optimization problems [8].", "startOffset": 105, "endOffset": 108}, {"referenceID": 22, "context": "On the other hand, Levin Search with a proper universal probability density function (pdf) of programs can be modified to solve induction problems (sequence, set, operator, and sequence prediction with arbitrary loss), inversion problems (computer science problems in P and NP), and optimization problems [23].", "startOffset": 305, "endOffset": 309}, {"referenceID": 7, "context": "In that sense, AIXI implies yet another variation of Levin Search for solving a particular universal optimization problem, however, it also has the unique advantage that formal transformations between AIXI problem and many important problems including function minimization and strategic games have been shown [8].", "startOffset": 310, "endOffset": 313}, {"referenceID": 22, "context": "Nevertheless, the discussion in [23] is rather brief.", "startOffset": 32, "endOffset": 36}, {"referenceID": 0, "context": "Also see [1] for a discussion of universal optimization.", "startOffset": 9, "endOffset": 12}, {"referenceID": 6, "context": "The unsupervised, active inference agent approach is proposed instead of reinforcement learning approach in [7], and the authors argue that they did not need to invoke the notion of reward, value or utility.", "startOffset": 108, "endOffset": 111}, {"referenceID": 7, "context": "Note that operator induction is considered to be insufficient to describe universal agents such as AIXI, because basic sequence induction is inappropriate for modelling optimization problems [8].", "startOffset": 191, "endOffset": 194}, {"referenceID": 19, "context": "However, a modified Levin search procedure can solve such optimization problems as in finding an optimal control program [20].", "startOffset": 121, "endOffset": 125}, {"referenceID": 21, "context": "using Solomonoff\u2019s entropy formulation that takes the negative logarithm of algorithmic probability [22].", "startOffset": 100, "endOffset": 104}, {"referenceID": 18, "context": "Note that this agent is conceptually related to the survival property of RL agents discussed in [19].", "startOffset": 96, "endOffset": 100}], "year": 2017, "abstractText": "We propose that operator induction serves as an adequate model of perception. We explain how to reduce universal agent models to operator induction. We propose a universal measure of operator induction fitness, and show how it can be used in a reinforcement learning model and a homeostasis (self-preserving) agent based on the free energy principle. We show that the action of the homeostasis agent can be explained by the operator induction model. \u201cWir m\u00fcssen wissen \u2013 wir werden wissen!\u201d", "creator": "LaTeX with hyperref package"}}}